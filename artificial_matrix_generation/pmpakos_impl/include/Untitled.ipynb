{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94c5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cc5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "# from multiprocessing import shared_memory\n",
    "# from multiprocessing import Process, Array\n",
    "\n",
    "from contextlib import closing\n",
    "import logging\n",
    "\n",
    "import scipy\n",
    "# info = mp.get_logger().info\n",
    "\n",
    "# prefix = \"/various/pmpakos/SpMV-Research/artificial_matrix_generation/pmpakos_impl/generated_matrices/\"\n",
    "prefix = \"/mnt/various/SpMV-Research/artificial_matrix_generation/pmpakos_impl/generated_matrices/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701bda71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11879 \tmain loop 2.84476 \tcol_ind merging 0.12861 \tshared_arr 0.00111 \t-> total: 2.97448\n",
      "11878 \tmain loop 2.94286 \tcol_ind merging 0.13791 \tshared_arr 0.00127 \t-> total: 3.08203\n",
      "synthetic_161000_161000_563436_avg4_std0.64_diagonal_0.005_n14.mtx \t 161000 161000 563436 (0.0022%)\t 7.062 MB (64-bit precision) in 3.415 seconds \t [4-8]\n",
      ">>>> synthetic_161000_161000_563436_avg4_std0.64_diagonal_0.005_n14.mtx [4-8] 3.4996024844720495 0.7016040829316588 0.004856695999382742 0.002397281462778195 1329.8798200174872 6013.496761853367\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################################################################\n",
    "def find_class(mem_footprint, low_mb_list, high_mb_list):\n",
    "    for i in range(len(low_mb_list)):\n",
    "        if(mem_footprint>=low_mb_list[i] and mem_footprint<=high_mb_list[i]):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# The shared array pointer is a global variable so that it can be accessed by the child processes. It consists of 3 tuples of (pointer, dtype, shape).\n",
    "def _init(shared_col_ind_, shared_bw_, shared_sc_):\n",
    "    global shared_col_ind\n",
    "    shared_col_ind = shared_col_ind_\n",
    "    global shared_bw\n",
    "    shared_bw = shared_bw_\n",
    "    global shared_sc\n",
    "    shared_sc = shared_sc_\n",
    "\n",
    "# Get a NumPy array from a shared memory buffer, with a given dtype and shape. No copy is involved, the array reflects the underlying shared buffer.\n",
    "def shared_to_numpy(shared_arr, dtype, shape):\n",
    "    return np.frombuffer(shared_arr, dtype=dtype).reshape(shape)\n",
    "\n",
    "def create_shared_array(dtype, shape):\n",
    "    # Create a new shared array. Return the shared array pointer, and a NumPy array view to it. \n",
    "    # Note that the buffer values are not initialized.\n",
    "    dtype = np.dtype(dtype)\n",
    "    cdtype = np.ctypeslib.as_ctypes_type(dtype)       # Get a ctype type from the NumPy dtype.\n",
    "    shared_arr = mp.RawArray(cdtype, sum(shape))      # Create the RawArray instance.\n",
    "    arr = shared_to_numpy(shared_arr, dtype, shape)   # Get a NumPy array view.\n",
    "    return shared_arr, arr\n",
    "\n",
    "def parallel_function(workload_augmented):\n",
    "    a=time.time()\n",
    "    index_range, nnz_range, partial_snd, nr_cols, placement, d_f, seed = workload_augmented\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    i0, i1 = index_range\n",
    "    random.seed(seed+i0)\n",
    "    l0, l1 = nnz_range\n",
    "\n",
    "    offset = i0\n",
    "    partial_col_ind_list  = []\n",
    "    partial_bw = np.zeros((i1-i0,))\n",
    "    partial_sc = np.zeros((i1-i0,))\n",
    "    if(placement==\"random\"):\n",
    "        for row in range(i0, i1):\n",
    "            random.seed(seed+row)\n",
    "            row_nonzeros = partial_snd[row-offset]\n",
    "            if(row_nonzeros>0):\n",
    "                local_col_ind = np.sort(random.sample(range(1,nr_cols+1), row_nonzeros))\n",
    "                partial_col_ind_list.append(local_col_ind)\n",
    "                partial_bw[row-offset] = (local_col_ind[-1]-local_col_ind[0]+1)/nr_cols\n",
    "                partial_sc[row-offset] = row_nonzeros/partial_bw[row-offset]\n",
    "    elif(placement==\"diagonal\"):\n",
    "        # d_f : diagonal factor must be smaller than 1, so that sampling can give unique values within range\n",
    "        # (range examined greater than population asked by random.sample()))\n",
    "        # place them around the main diagonal\n",
    "        for row in range(i0, i1):\n",
    "            random.seed(seed+row)\n",
    "            row_nonzeros = partial_snd[row-offset]\n",
    "            if(row_nonzeros>0):\n",
    "                if(int(row-row_nonzeros/d_f)<1 and int(row+row_nonzeros/d_f)>nr_cols):\n",
    "                    local_col_ind = np.sort(random.sample(range( 1, nr_cols+1), row_nonzeros))\n",
    "                elif(int(row-row_nonzeros/d_f)<1):\n",
    "                    local_col_ind = np.sort(random.sample(range( 1, int(row+row_nonzeros/d_f)+1), row_nonzeros))\n",
    "                elif(int(row+row_nonzeros/d_f)>nr_cols):\n",
    "                    local_col_ind = np.sort(random.sample(range( int(row-row_nonzeros/d_f), nr_cols+1), row_nonzeros))\n",
    "                else:\n",
    "                    local_col_ind = np.sort(random.sample(range( int(row-row_nonzeros/d_f), int(row+row_nonzeros/d_f)+1), row_nonzeros))\n",
    "                partial_col_ind_list.append(local_col_ind)\n",
    "                partial_bw[row-offset] = (local_col_ind[-1]-local_col_ind[0]+1)/nr_cols\n",
    "                partial_sc[row-offset] = row_nonzeros/partial_bw[row-offset]\n",
    "\n",
    "    b = time.time()\n",
    "    partial_col_ind = np.asarray([item-1 for sublist in partial_col_ind_list for item in sublist])\n",
    "    c = time.time()\n",
    "\n",
    "    col_ind = shared_to_numpy(*shared_col_ind)\n",
    "    bandwidth = shared_to_numpy(*shared_bw)\n",
    "    scatter = shared_to_numpy(*shared_sc)\n",
    "\n",
    "    col_ind[l0:l1] = partial_col_ind\n",
    "    bandwidth[i0:i1] = partial_bw\n",
    "    scatter[i0:i1] = partial_sc\n",
    "    e = time.time()\n",
    "    print(os.getpid(),\"\\tmain loop\", round(b-a,5), \"\\tcol_ind merging\", round(c-b,5), \"\\tshared_arr\", round(e-c,5), \"\\t-> total:\", round(e-a,5))\n",
    "\n",
    "\n",
    "def generate_random_matrix(nr_rows, nr_cols, avg_nnz_per_row, std_nnz_per_row, \\\n",
    "                           distribution, seed, placement, d_f, \\\n",
    "                           save_it, keep_it, low_mb, high_mb, precision):\n",
    "    ###############################################################################################    \n",
    "    start = time.time()\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    if(distribution == \"normal\"):\n",
    "        snd = np.random.normal(loc=avg_nnz_per_row,\n",
    "                               scale=std_nnz_per_row,\n",
    "                               size=nr_rows)\n",
    "        distrib = \"n\"\n",
    "    elif(distribution == \"gamma\"):\n",
    "        snd = np.random.gamma(shape=(avg_nnz_per_row**2/std_nnz_per_row**2), \n",
    "                              scale=(std_nnz_per_row**2/avg_nnz_per_row),\n",
    "                              size=nr_rows)\n",
    "        distrib = \"g\"\n",
    "\n",
    "    integerization = np.vectorize(lambda x : int(x) if x>0 else int(-x))\n",
    "    snd = integerization(snd)\n",
    "\n",
    "    # range of nonzeros per row\n",
    "    min_snd = np.min(snd)\n",
    "    max_snd = np.max(snd)\n",
    "    nr_nnz = np.sum(snd)\n",
    "    new_avg_nnz_per_row = np.mean(snd)\n",
    "    new_std_nnz_per_row = np.std(snd)\n",
    "    density = np.round(nr_nnz/(nr_rows*nr_cols)*100,4)\n",
    "    \n",
    "    mem_footprint = round(((precision+32)*nr_nnz + 32*(nr_rows+1))/(8*1024*1024),3) # MB\n",
    "    \n",
    "    # time1 : time needed to determine how many nonzeros per row exist\n",
    "    time1 = round(time.time()-start,4)\n",
    "    \n",
    "    if(mem_footprint<low_mb or mem_footprint>high_mb):\n",
    "        return (\" \",\n",
    "            [], [],\n",
    "            nr_nnz, density, mem_footprint,\n",
    "            0, 0,\n",
    "            0, 0,\n",
    "            0, 0,\n",
    "            time1, 0)\n",
    "    ###############################################################################################\n",
    "    start = time.time()\n",
    "    \n",
    "    placement_full = placement\n",
    "    if(placement==\"diagonal\"): # need to add diagonal_factor too\n",
    "        if(d_f>1):\n",
    "            print(\"Diagonal Factor is greater than 1. I have to stop now!\")\n",
    "            return\n",
    "        placement_full += \"_\"+str(d_f)\n",
    "\n",
    "    filename =  prefix+\\\n",
    "                \"synthetic_\"+\\\n",
    "                str(nr_rows)+\"_\"+str(nr_cols)+\"_\"+str(nr_nnz)+\\\n",
    "                \"_avg\"+str(avg_nnz_per_row)+\"_std\"+str(std_nnz_per_row)+\\\n",
    "                \"_\"+placement_full+\\\n",
    "                \"_\"+distrib+str(seed)+\\\n",
    "                \".mtx\"\n",
    "    # print_matrix_distribution_info(filename, nr_row, nr_nnz, snd, max_snd, min_snd, avg_nnz_per_row, std_nnz_per_row)\n",
    "    if(save_it == True):\n",
    "        f = open(filename, \"w\")\n",
    "        # f.write(\"%%MatrixMarket matrix coordinate real general\\n\") # if this is used, need to pass a value too!\n",
    "        f.write(\"%%MatrixMarket matrix coordinate pattern general\\n\")\n",
    "        f.write(str(nr_rows)+\" \"+str(nr_cols)+\" \"+str(nr_nnz)+\"\\n\")\n",
    "\n",
    "    row_ptr = np.zeros((nr_rows+1), dtype=np.uint32)\n",
    "\n",
    "    # no need to speed up this one, very small percentage of execution time\n",
    "    for row in range(len(snd)):\n",
    "        row_nonzeros = snd[row]\n",
    "        if(keep_it == True):\n",
    "            row_ptr[row+1] = row_nonzeros+row_ptr[row]\n",
    "\n",
    "    ################################################################################################################################################################\n",
    "    # start parallel (multiprocess) creation of col_ind\n",
    "    # thank you https://stackoverflow.com/questions/7894791/use-numpy-array-in-shared-memory-for-multiprocessing\n",
    "    mp.freeze_support() # https://stackoverflow.com/questions/24374288/where-to-put-freeze-support-in-a-python-script\n",
    "    # n_processes_list = [40, 20, 10,  8, 4, 2, 1]\n",
    "    # n_processes = os.cpu_count() #os.cpu_count()#//4\n",
    "    n_processes = 2\n",
    "    # Initialize 3 shared arrays. col_ind (the giant) and bandwidth and scattering (the goliaths) that will be shared among processes.\n",
    "    # Bandwidth and Scattering were initially calculated in serial manner, but it was pretty time consuming for large matrices (20 sec for 5M rows)\n",
    "    # Therefore, sharing is caring.\n",
    "    dtype = np.int32\n",
    "    shape = (int(nr_nnz),)\n",
    "    shared_col_ind, col_ind = create_shared_array(dtype, shape)\n",
    "    col_ind.flat[:] = np.zeros(shape)\n",
    "\n",
    "    dtype2 = np.float64\n",
    "    shape2 = (nr_rows,)\n",
    "    shared_bw, bandwidth = create_shared_array(dtype2, shape2)\n",
    "    bandwidth.flat[:] = np.zeros(shape2)\n",
    "\n",
    "    shared_sc, scatter = create_shared_array(dtype2, shape2)\n",
    "    scatter.flat[:] = np.zeros(shape2)\n",
    "\n",
    "    # Create a Pool of processes and expose the shared array to the processes, in a global variable (_init() function).\n",
    "    with closing(mp.Pool(n_processes, initializer=_init, initargs=((shared_col_ind, dtype, shape),(shared_bw, dtype2, shape2),(shared_sc, dtype2, shape2)))) as p:\n",
    "        n = nr_rows // n_processes\n",
    "        index_range = [(k*n, (k+1)*n) for k in range(n_processes)]\n",
    "        # verify that last process will process all final rows (if n_processes does not divide nr_rows fully)\n",
    "        s,_ = index_range[-1]\n",
    "        index_range[-1] = (s,nr_rows)\n",
    "        workload_augmented = []\n",
    "        for i in range(len(index_range)):\n",
    "            i0, i1 = index_range[i]\n",
    "            partial_snd = snd[i0:i1]\n",
    "            nnz_range = row_ptr[i0], row_ptr[i1]\n",
    "            workload_augmented.append([index_range[i], nnz_range, partial_snd, nr_cols, placement, d_f, seed])\n",
    "        p.map(parallel_function, workload_augmented)\n",
    "    # Close the processes.\n",
    "    p.join()\n",
    "    ################################################################################################################################################################\n",
    "\n",
    "    if(save_it == True):\n",
    "        for row in range(len(snd)):\n",
    "            local_col_ind = col_ind[row_ptr[row]:row_ptr[row+1]]\n",
    "            for i in local_col_ind:\n",
    "                f.write(str(row+1)+\" \"+str(i+1)+\"\\n\") # no need to write a value, only keep indices\n",
    "        f.close()\n",
    "\n",
    "    # fuck numpy arrays, no need to mess with their API\n",
    "    row_ptr = row_ptr.tolist()\n",
    "    col_ind = col_ind.tolist()\n",
    "    \n",
    "    avg_bw = np.mean(bandwidth)\n",
    "    std_bw = np.std(bandwidth)\n",
    "    avg_sc = np.mean(scatter)\n",
    "    std_sc = np.std(scatter)\n",
    "    \n",
    "    # time2 : time needed to determine where nonzeros are placed within each row\n",
    "    time2 = round(time.time()-start,4)\n",
    "    ###############################################################################################\n",
    "    return (filename.split(\"/\")[-1],\n",
    "            row_ptr, col_ind,\n",
    "            nr_nnz, density, mem_footprint,\n",
    "            new_avg_nnz_per_row, new_std_nnz_per_row,\n",
    "            avg_bw, std_bw,\n",
    "            avg_sc, std_sc,\n",
    "            time1, time2)\n",
    "\n",
    "def sparse_matrix_generator_wrapper(nr_rows, avg_nnz_per_row, std_nnz_per_row, distribution, placement, d_f, seed, precision, verbose):\n",
    "    low_mb_list = [4,8,16,32,64,128,256,512,1024,2048]\n",
    "    high_mb_list =  [8,16,32,64,128,256,512,1024,2048,4096]\n",
    "    low_mb, high_mb = low_mb_list[0], high_mb_list[-1]\n",
    "    save_it = False\n",
    "    keep_it = True\n",
    "    nr_cols = nr_rows\n",
    "    # verbose=1    \n",
    "    filename, row_ptr, col_ind, nr_nnz, density, mem_footprint, new_avg_nnz_per_row, new_std_nnz_per_row, avg_bw, std_bw, avg_sc, std_sc, time1, time2 = generate_random_matrix(nr_rows, nr_cols, avg_nnz_per_row, std_nnz_per_row, distribution, seed, placement, d_f, save_it, keep_it, low_mb, high_mb, precision)\n",
    "    pos = find_class(mem_footprint, low_mb_list, high_mb_list)\n",
    "    if(pos!=-1):\n",
    "        mem_range = '['+str(low_mb_list[pos])+'-'+str(high_mb_list[pos])+']'\n",
    "        if(verbose):\n",
    "            print(filename, \"\\t\", nr_rows, nr_cols, nr_nnz, '('+str(density)+'%)\\t', mem_footprint, 'MB ('+str(precision)+'-bit precision)', 'in', round(time1+time2,3), 'seconds', '\\t', mem_range)\n",
    "#             print(\"row_ptr[0:10] :\", row_ptr[0:10])\n",
    "#             print(\"col_ind[0:10] :\", col_ind[0:10])\n",
    "        print(\">>>>\", filename, mem_range, new_avg_nnz_per_row, new_std_nnz_per_row, avg_bw, std_bw, avg_sc, std_sc)\n",
    "        return row_ptr, col_ind, nr_nnz, density, mem_range, new_avg_nnz_per_row, new_std_nnz_per_row, avg_bw, std_bw, avg_sc, std_sc, time1, time2\n",
    "    else:\n",
    "        return [],           [],      0,       0,        '',                   0,                   0,       0,     0,      0,       0,    0,     0\n",
    "\n",
    "####################################################################################################################    \n",
    "nr_rows = 161000\n",
    "avg_nnz_per_row = 4\n",
    "std_nnz_per_row = 0.64\n",
    "distribution = \"normal\"\n",
    "placement = \"diagonal\"\n",
    "d_f = 0.005\n",
    "seed = 14\n",
    "precision = 64\n",
    "verbose = 1\n",
    "\n",
    "a = sparse_matrix_generator_wrapper(nr_rows, avg_nnz_per_row, std_nnz_per_row, distribution, placement, d_f, seed, precision, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "def matrix_size_estimator(nr_rows, nr_cols, avg_nnz_per_row, std_nnz_per_row, \\\n",
    "                                    distribution, seed, placement, d_f, \\\n",
    "                                    low_mb, high_mb, precision):\n",
    "    ###############################################################################################    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    if(distribution == \"normal\"):\n",
    "        snd = np.random.normal(loc=avg_nnz_per_row,\n",
    "                               scale=std_nnz_per_row,\n",
    "                               size=nr_rows)\n",
    "        distrib = \"n\"\n",
    "    elif(distribution == \"gamma\"):\n",
    "        snd = np.random.gamma(shape=(avg_nnz_per_row**2/std_nnz_per_row**2), \n",
    "                              scale=(std_nnz_per_row**2/avg_nnz_per_row),\n",
    "                              size=nr_rows)\n",
    "        distrib = \"g\"\n",
    "\n",
    "    integerization = np.vectorize(lambda x : int(x) if x>0 else int(-x))\n",
    "    snd = integerization(snd)\n",
    "    # range of nonzeros per row\n",
    "    nr_nnz = np.sum(snd)\n",
    "    density = np.round(nr_nnz/(nr_rows*nr_cols)*100,4)\n",
    "    mem_footprint = round(((precision+32)*nr_nnz + 32*(nr_rows+1))/(8*1024*1024),3) # MB\n",
    "    \n",
    "    filename =  \"synthetic_\"+\\\n",
    "                str(nr_rows)+\"_\"+str(nr_cols)+\"_\"+str(nr_nnz)+\\\n",
    "                \"_avg\"+str(avg_nnz_per_row)+\"_std\"+str(std_nnz_per_row)+\\\n",
    "                \"_\"+placement+\\\n",
    "                \"_\"+distrib+str(seed)+\\\n",
    "                \".mtx\"\n",
    "\n",
    "    ###############################################################################################\n",
    "    return (filename.split(\"/\")[-1], nr_nnz, density, mem_footprint)\n",
    "\n",
    "def matrix_size_estimator_wrapper(precision_type, distribution):\n",
    "    # nr_rows_list = [4000, 21000, 38000, 47000, 64000, 68000, 83000, 121000, 141000, 161000, 171000, 186000, 207000, 218000, 268000, 526000, 863000, 952000, 987000, 1000000, 1383000, 1635000, 4690000, 5155000, 5558000]\n",
    "    # avg_nnz_per_row_list = [3.1,4,4.3,5.6,6,10,12,20,22,39,45,50,55,65,70,80,105,120,155,220,420,2600]\n",
    "    # std_nnz_per_row_list = [0.02,0.09,0.2,0.25,0.3,0.39,0.43,0.55,0.64,0.72,0.78,0.84,0.98,1.14,1.32,1.5,1.6,2.25,2.5,3,8,13,125]\n",
    "\n",
    "    nr_rows_list = [4000, 21000, 38000, 47000, 64000, 68000, 83000, 121000, 141000, 161000, 171000, 186000, 207000, 218000, 268000, 526000, 863000, 952000, 987000, 1000000, 1383000, 1635000, 4690000, 5155000, 5558000]\n",
    "    avg_nnz_per_row_list = [3.1,4,6,10,20,45,70,105,220,420,2600]\n",
    "    std_nnz_per_row_list = [0.02,0.2,0.64,0.84,1.6,2.25,2.5,3,8,13,125]\n",
    "\n",
    "    # low_mb_list = [4,8,16,32,64,128,256,512,1024,2048]\n",
    "    # high_mb_list =  [8,16,32,64,128,256,512,1024,2048,4096]\n",
    "    low_mb_list = [4,8,16,32,64,128,256,512,1024] # removed largest mem range (2048-4096)\n",
    "    high_mb_list =  [8,16,32,64,128,256,512,1024,2048] \n",
    "\n",
    "    low_mb, high_mb = low_mb_list[0], high_mb_list[-1]\n",
    "    cnt = 0\n",
    "\n",
    "    if(precision_type==\"double\"):\n",
    "        precision = 64\n",
    "    else:\n",
    "        precision = 32\n",
    "\n",
    "    placement = \"random\"\n",
    "    d_f = 1\n",
    "\n",
    "    files_list, logs = [], []\n",
    "    for i in range(len(low_mb_list)):\n",
    "        log_filename = \"../matrix_generation_parameters/\"+precision_type+\"/logs/matrix_generator_\"+distribution+\"_\"+str(low_mb_list[i])+\"-\"+str(high_mb_list[i])+\"_log.txt\"\n",
    "        logs.append(log_filename)\n",
    "        f = open(log_filename,\"w\")\n",
    "        files_list.append(f)\n",
    "        files_list[i].write(\"\\t\".join([\"filename\",\"nr_rows\",\"nr_cols\",\"nr_nnz\",\"density\",\"mem_footprint\"])+\"\\n\")\n",
    "\n",
    "    for nr_rows in nr_rows_list:\n",
    "        print(\"\\n\\n--------------------------\\n\\nCURRENTLY TESTING nr_rows [\",nr_rows,\"]\\n\")\n",
    "        start = time.time()\n",
    "        nr_cols = nr_rows\n",
    "        for avg_nnz_per_row in avg_nnz_per_row_list:\n",
    "            for std_nnz_per_row in std_nnz_per_row_list:\n",
    "                for seed in [14]: #[14,80,96]\n",
    "                    cnt+=4\n",
    "                    filename, nr_nnz, density, mem_footprint = matrix_size_estimator(nr_rows, nr_cols, avg_nnz_per_row, std_nnz_per_row, distribution, seed, placement, d_f, low_mb, high_mb, precision)\n",
    "                    pos = find_class(mem_footprint, low_mb_list, high_mb_list)\n",
    "                    if(pos!=-1):\n",
    "                        print(\"matrix\"+str(cnt),\"\\t\", nr_rows, nr_cols, nr_nnz, \"(\",density,\"%)\\t\\t\",mem_footprint,\"MB\", \"\\t [\",low_mb_list[pos],\"-\",high_mb_list[pos],\"]\")\n",
    "                        str_list = [filename.split(\"/\")[-1], nr_rows, nr_cols, nr_nnz, density, mem_footprint]\n",
    "                        str_list = \"\\t\".join([str(x) for x in str_list])+\"\\n\"\n",
    "                        files_list[pos].write(str_list)\n",
    "        print(\"\\nTOOK ME\", round(time.time()-start,4), \" SECONDS TO FINISH nr_rows [\",nr_rows,\"]\")\n",
    "\n",
    "    for i in range(len(low_mb_list)):\n",
    "        files_list[i].close()\n",
    "\n",
    "    root_path = \"../matrix_generation_parameters/\"+precision_type+\"/\"\n",
    "    cnt = 0\n",
    "    for log in logs:\n",
    "        log_filename = log.split(\"/\")[-1].split(\"_\")\n",
    "        distribution = log_filename[2]\n",
    "        mem_footprint_range = log_filename[3]\n",
    "\n",
    "        mgp_filename = root_path + distribution + \"_\" + mem_footprint_range + \".txt\"\n",
    "        mgp_small_filename = root_path + \"/small/\" + distribution + \"_\" + mem_footprint_range + \".txt\"\n",
    "        print(mgp_filename)\n",
    "        f = open(mgp_filename,\"w\")\n",
    "        f2 = open(mgp_small_filename,\"w\")\n",
    "        \n",
    "        dataframe = pd.read_csv(log, delimiter =\"\\t\")\n",
    "        dataframe = dataframe.sort_values(\"mem_footprint\").reset_index() # sort by mem size, so that sampling the dataset is useful. reset_index() done to perform sampling too\n",
    "        dataframe_size = dataframe.shape[0]\n",
    "        small_pcg = 10\n",
    "        for index, row in dataframe.iterrows():\n",
    "            filename = row[\"filename\"].split(\"_\")\n",
    "            nr_rows = filename[1]\n",
    "            avg_nnz_per_row = filename[4].strip(\"avg\")\n",
    "            std_nnz_per_row = filename[5].strip(\"std\")\n",
    "            seed = filename[7].strip(\".mtx\").strip(\"n\").strip(\"g\")\n",
    "\n",
    "            placement_list = [\"random\",\"diagonal\" ]# and diagonal\n",
    "\n",
    "            for placement in placement_list:\n",
    "                df_list = [1]\n",
    "                if(placement==\"diagonal\"):\n",
    "                    df_list = [0.5, 0.05, 0.005]\n",
    "                for d_f in df_list:\n",
    "                    # matrix parameters (that are fed to C function) follow the given format :\n",
    "                    # nr_rows   avg_nnz_per_row   std_nnz_per_row   distribution   placement    diagonal_factor   seed\n",
    "                    line = str(nr_rows)+\" \"+str(avg_nnz_per_row)+\" \"+str(std_nnz_per_row)+\" \"+distribution+\" \"+placement+\" \"+str(d_f)+\" \"+str(seed)\n",
    "                    f.write(line+\"\\n\")\n",
    "                    if(index % small_pcg ==0):\n",
    "                        f2.write(line+\"\\n\")\n",
    "                    cnt+=1\n",
    "        f.close()\n",
    "        f2.close()\n",
    "    print(\"After all,\",cnt,\"matrices will be tested!\")\n",
    "\n",
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################################################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"main\")\n",
    "\n",
    "    # matrix_size_estimator_wrapper(\"double\", \"normal\")\n",
    "    # matrix_size_estimator_wrapper(\"double\", \"gamma\")\n",
    "\n",
    "    # matrix_size_estimator_wrapper(\"float\", \"normal\")\n",
    "    # matrix_size_estimator_wrapper(\"float\", \"gamma\")\n",
    "\n",
    "    # sparse_matrix_generator_wrapper(161000,4,0.64,\"normal\",\"diagonal\",0.005,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(161000,10,0.02,\"normal\",\"random\",1,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(207000,4,0.84,\"normal\",\"diagonal\",0.05,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(141000,20,0.64,\"normal\",\"random\",1,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(38000,220,0.84,\"normal\",\"diagonal\",0.005,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(526000,70,2.5,\"normal\",\"diagonal\",0.5,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(4690000,4,1.6,\"normal\",\"random\",1,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(1635000,45,0.2,\"normal\",\"diagonal\",0.05,14,64,1)\n",
    "    # sparse_matrix_generator_wrapper(5558000,20,0.64,\"normal\",\"diagonal\",0.005,14,64,1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
