{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c669a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3a9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_parser(log_file, results_file):\n",
    "    results_list = []\n",
    "    with open(log_file,\"r\") as fp:\n",
    "        for line in fp:\n",
    "            split = line.split()\n",
    "            split2 = line.split(\",\")\n",
    "            if(len(split)>0):\n",
    "                if(\"pmpakos@\" in split[0]):\n",
    "                    matrix_name = ''\n",
    "#                     print(\"---------\")\n",
    "\n",
    "            if(len(split)>2):\n",
    "                if((split[0]==\"INFO:\") & (split[1]==\"loading\") & (split[2]==\"Mtx\")):\n",
    "                    print(split[-1])\n",
    "                    matrix_name = split[-1].split(\"/\")[-1]\n",
    "                    matrix_name = matrix_name.replace(\".mtx\",\"\")\n",
    "            if(len(split2)>2):\n",
    "                if(split2[1]!=\" matrix\"):\n",
    "                    line=line.replace(\"app\",matrix_name).strip(\"DATA_CSV:,\")\n",
    "#                     line=line.replace(\",\",\"\\t\")\n",
    "                    results_list.append(line)\n",
    "                    print(line)\n",
    "\n",
    "    file = open(results_file,\"w\")\n",
    "    for res in results_list:\n",
    "        file.write(res)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa112438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matrix_generation_log(start_gen, results_gen):\n",
    "    fw = open(results_gen,\"w\")\n",
    "    fw_list = []\n",
    "    cnt = 0\n",
    "    with open(start_gen) as fp:\n",
    "        for line in fp:\n",
    "            if(\">>>> \" in line):\n",
    "                if(line not in fw_list):\n",
    "                    fw_list.append(line)\n",
    "                    line = line.strip(\">>>> \").replace(\" \",\",\")#.replace(\".mtx\",\"\")\n",
    "                    line_spl = line.split(\",\")\n",
    "                    line_spl[0] = line_spl[0].replace(\".0_\",\"_\")\n",
    "                    # line_spl[0] = line_spl[0].split(\"_\")\n",
    "                    # del line_spl[0][3]\n",
    "                    # line_spl[0] = \"_\".join(line_spl[0])\n",
    "                    line_new = \",\".join(line_spl)\n",
    "                    fw.write(line_new)\n",
    "                else:\n",
    "                    cnt+=1\n",
    "    print(\"duplicates found :\", cnt)\n",
    "    fw.close()\n",
    "\n",
    "def clean_results(start_list, results_list):\n",
    "    for t1,t2 in zip(start_list,results_list):\n",
    "        fw = open(t2,\"w\")\n",
    "        with open(t1) as fp:\n",
    "            for line in fp:\n",
    "                if(\"DATA_CSV:,\" in line):\n",
    "                    line_new = line.strip(\"DATA_CSV:,\").replace(\".0_\",\"_\")\n",
    "                    fw.write(line_new)\n",
    "        fw.close()\n",
    "    \n",
    "def read_results_single(result_file):\n",
    "    header = [\"matrix_name\",\"original rows\",\"original cols\",\"original NNZs\",\n",
    "              \"padded rows\",\"padded cols\",\"padded NNZs\",\"padding overhead[%]\",\n",
    "              \"num of runs\",\"total run time[sec]\",\"time[ms]/run\",\"performance[GFLOPs]\",\"performance (padded)[GFLOPs]\",\"mem_footprint[MB]\"]\n",
    "    df = pd.read_table(result_file, delimiter =\",\", names=header)\n",
    "    return df\n",
    "\n",
    "def read_results(results_list, results_gen, results_csv):\n",
    "    # this header was used for old result reporting\n",
    "    # header = [\"matrix_name\",\"mem_range\",\"avg_nnz_per_row\",\"std_nnz_per_row\",\"avg_bw\",\"std_bw\",\"avg_sc\",\"std_sc\"]\n",
    "    # v2 dgal generator\n",
    "    header = [\"matrix_name\", \"distribution\", \"placement\", \"seed\", \n",
    "              \"nr_rows\", \"nr_cols\", \"nr_nnz\", \"density\", \"mem_footprint\", \"mem_range\", \n",
    "              \"avg_nnz_per_row\", \"std_nnz_per_row\", \n",
    "              \"avg_bw\", \"std_bw\", \"avg_bw_scaled\", \"std_bw_scaled\", \n",
    "              \"avg_sc\", \"std_sc\", \"avg_sc_scaled\", \"std_sc_scaled\", \"skew_coeff\"]\n",
    "    df_gen = pd.read_table(results_gen, delimiter =\",\", names=header) \n",
    "    \n",
    "    dataframes = []\n",
    "    for result_file in results_list:\n",
    "        dataframes.append(read_results_single(result_file))\n",
    "    matrices = dataframes[0][\"matrix_name\"].unique()\n",
    "\n",
    "    n_runs = len(results_list)\n",
    "    results_final = []\n",
    "    cntt=0\n",
    "    for matrix in matrices:\n",
    "#         print(matrix)\n",
    "        selected_gen = df_gen[df_gen[\"matrix_name\"]==matrix]\n",
    "        if(len(selected_gen)==0):\n",
    "            print('\\t', matrix)\n",
    "            cntt+=1\n",
    "        else:\n",
    "            matrix_name = np.asarray(selected_gen[\"matrix_name\"])[0]\n",
    "            distribution = np.asarray(selected_gen[\"distribution\"])[0]\n",
    "            placement = np.asarray(selected_gen[\"placement\"])[0]\n",
    "            seed = np.asarray(selected_gen[\"seed\"])[0]\n",
    "            nr_rows = np.asarray(selected_gen[\"nr_rows\"])[0]\n",
    "            nr_cols = np.asarray(selected_gen[\"nr_cols\"])[0]\n",
    "            nr_nnz = np.asarray(selected_gen[\"nr_nnz\"])[0]\n",
    "            density = np.asarray(selected_gen[\"density\"])[0]\n",
    "            # if I want to show mem_footprint of CSR double representation\n",
    "            mem_footprint = np.asarray(selected_gen[\"mem_footprint\"])[0]\n",
    "            \n",
    "            mem_range = np.asarray(selected_gen[\"mem_range\"])[0]\n",
    "            avg_nnz_per_row = np.asarray(selected_gen[\"avg_nnz_per_row\"])[0]\n",
    "            std_nnz_per_row = np.asarray(selected_gen[\"std_nnz_per_row\"])[0]\n",
    "            avg_bw = np.asarray(selected_gen[\"avg_bw\"])[0]\n",
    "            std_bw = np.asarray(selected_gen[\"std_bw\"])[0]\n",
    "            avg_bw_scaled = np.asarray(selected_gen[\"avg_bw_scaled\"])[0]\n",
    "            std_bw_scaled = np.asarray(selected_gen[\"std_bw_scaled\"])[0]\n",
    "            avg_sc = np.asarray(selected_gen[\"avg_sc\"])[0]\n",
    "            std_sc = np.asarray(selected_gen[\"std_sc\"])[0]\n",
    "            avg_sc_scaled = np.asarray(selected_gen[\"avg_sc_scaled\"])[0]\n",
    "            std_sc_scaled = np.asarray(selected_gen[\"std_sc_scaled\"])[0]\n",
    "            skew_coeff = np.asarray(selected_gen[\"skew_coeff\"])[0]\n",
    "\n",
    "            matrix_list = matrix.split(\"_\")\n",
    "            mtx_name = matrix_list[0]\n",
    "\n",
    "            # nr_rows = int(matrix_list[1])\n",
    "            # nr_cols = int(matrix_list[2])\n",
    "\n",
    "            # if(len(matrix_list)==7):#random\n",
    "            #     placement = \"random\"\n",
    "            #     diagonal_factor = 1\n",
    "            # else: #diagonal\n",
    "            #     placement = \"diagonal\"\n",
    "            #     diagonal_factor = matrix_list[6]\n",
    "\n",
    "            # seed = matrix_list[-1].strip(\"n\").strip(\"g\")\n",
    "\n",
    "            # distr = list(filter(lambda x: x.isalpha(), matrix_list[-1]))[0]\n",
    "            # if(distr==\"g\"):\n",
    "            #     distribution=\"gamma\"\n",
    "            # else:\n",
    "            #     distribution=\"normal\"\n",
    "\n",
    "            # nr_nnz = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original NNZs\"])[0]\n",
    "            # density = nr_nnz/(nr_rows*nr_cols)*100\n",
    "\n",
    "            runtime_iter = np.zeros(shape=(n_runs,1))\n",
    "            perf_padded = np.zeros(shape=(n_runs,1))\n",
    "            # mem_footprint = np.zeros(shape=(n_runs,1))\n",
    "\n",
    "            for run in range(0,n_runs):\n",
    "                df = dataframes[run]\n",
    "                runtime_iter[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"time[ms]/run\"])[0]\n",
    "                perf_padded[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"performance (padded)[GFLOPs]\"])[0]\n",
    "                # mem_footprint[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"mem_footprint[MB]\"])[0]\n",
    "            if(perf_padded[0][0]<0): # why? nobody knows why\n",
    "                continue\n",
    "\n",
    "            runtime_iter_hm = hmean(runtime_iter,axis=0)[0]\n",
    "            perf_padded_hm = hmean(perf_padded,axis=0)[0]\n",
    "            # if I want to show mem_footprint of Xilinx sparse double representation\n",
    "            # mem_footprint = hmean(mem_footprint,axis=0)[0]\n",
    "\n",
    "            # selected_gen = df_gen[df_gen[\"matrix_name\"]==matrix]\n",
    "            # mem_range = np.asarray(selected_gen[\"mem_range\"])[0]\n",
    "            # avg_nnz_per_row = np.asarray(selected_gen[\"avg_nnz_per_row\"])[0]\n",
    "            # std_nnz_per_row = np.asarray(selected_gen[\"std_nnz_per_row\"])[0]\n",
    "            # avg_bw = np.asarray(selected_gen[\"avg_bw\"])[0]\n",
    "            # std_bw = np.asarray(selected_gen[\"std_bw\"])[0]\n",
    "            # avg_sc = np.asarray(selected_gen[\"avg_sc\"])[0]\n",
    "            # std_sc = np.asarray(selected_gen[\"std_sc\"])[0]/nr_cols\n",
    "\n",
    "            W_avg = 33\n",
    "            J_estimated = W_avg*runtime_iter_hm\n",
    "\n",
    "            line_list = [matrix_name, distribution, placement, seed,\n",
    "                         nr_rows, nr_cols, nr_nnz, density, mem_footprint, mem_range,\n",
    "                         avg_nnz_per_row, std_nnz_per_row, \n",
    "                         avg_bw, std_bw, avg_bw_scaled, std_bw_scaled,\n",
    "                         avg_sc, std_sc, avg_sc_scaled, std_sc_scaled,\n",
    "                         skew_coeff,\n",
    "                         \"Xilinx_SpMV\", runtime_iter_hm, perf_padded_hm, W_avg, J_estimated\n",
    "                        ]\n",
    "            line = \",\".join(str(x) for x in line_list) + \"\\n\"\n",
    "            results_final.append(line)\n",
    "        \n",
    "    file = open(results_csv,\"w\")\n",
    "    for line in results_final:\n",
    "        file.write(line)\n",
    "    file.close()\n",
    "    print(\"Results for\",len(results_final),\"matrices for\",results_csv.split(\"/\")[-1])\n",
    "    if(cntt>0):\n",
    "        print(cntt, \"matrices not found\")\n",
    "\n",
    "\n",
    "    \n",
    "def extract_results_of_distr_memrange(distr_memrange):\n",
    "    start_gen = \"./generation_stats/\"+distr_memrange+\"_log.txt\"\n",
    "    results_gen = \"./generation_stats/\"+distr_memrange+\"_log_CLEAN.txt\"\n",
    "    clean_matrix_generation_log(start_gen, results_gen)\n",
    "\n",
    "    start_list = [\n",
    "        \"./dirty/\"+distr_memrange+\"_run1.txt\",\n",
    "    ]\n",
    "\n",
    "    results_list = [\n",
    "        \"./clean/\"+distr_memrange+\"_run_CLEAN1.txt\",\n",
    "    ]\n",
    "    clean_results(start_list, results_list)\n",
    "\n",
    "    results_csv = \"./results_\"+distr_memrange+\".csv\"\n",
    "    read_results(results_list, results_gen, results_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8037e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 764 matrices for results_normal_4-8.csv\n",
      "Results for 864 matrices for results_normal_8-16.csv\n",
      "Results for 844 matrices for results_normal_16-32.csv\n",
      "Results for 1212 matrices for results_normal_32-64.csv\n",
      "Results for 1232 matrices for results_normal_64-128.csv\n",
      "Results for 1415 matrices for results_normal_128-256.csv\n",
      "Results for 908 matrices for results_normal_256-512.csv\n",
      "Results for 968 matrices for results_normal_512-1024.csv\n",
      "Results for 816 matrices for results_normal_1024-2048.csv\n",
      "CPU times: user 24.7 s, sys: 122 ms, total: 24.8 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "distr_base = \"normal\"\n",
    "mem_ranges = [\"4-8\",\"8-16\",\"16-32\",\"32-64\",\"64-128\",\"128-256\",\"256-512\",\"512-1024\",\"1024-2048\"]\n",
    "# mem_ranges = [\"1024-2048\"]\n",
    "\n",
    "for mem_range in mem_ranges:\n",
    "    distr_memrange = distr_base + \"_\" + mem_range\n",
    "    extract_results_of_distr_memrange(distr_memrange)\n",
    "\n",
    "filenames = [\"results_\"+distr_base+\"_\"+mr+\".csv\" for mr in mem_ranges]\n",
    "\n",
    "with open('../Benchmarks/xilinx_spmv_4-2048_normal_dataset_dtype-D.csv', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20201e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates found : 163\n",
      "Results for 688 matrices for results_validation_matrices_synthetic_small.csv\n",
      "CPU times: user 1.41 s, sys: 14.9 ms, total: 1.42 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "distr_memrange = \"validation_matrices_synthetic_small\"\n",
    "extract_results_of_distr_memrange(distr_memrange)\n",
    "filename = \"results_\"+distr_memrange+\".csv\"\n",
    "\n",
    "with open('../Benchmarks/xilinx_spmv_'+distr_memrange+'_dtype-D.csv', 'w') as outfile:\n",
    "    with open(filename) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb48292",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a554adc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba8f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results2(results_list, results_csv):\n",
    "    dataframes = []\n",
    "    for result_file in results_list:\n",
    "        dataframes.append(read_results_single(result_file))\n",
    "    # get matrices sorted by mem_footprint and then begin processing them (so that I do not have to sort them later...)\n",
    "    matrices = dataframes[0][\"matrix_name\"].unique()\n",
    "    # matrices = dataframes[0].groupby([\"matrix name\",\"mem_footprint[MB]\"]).size().reset_index().sort_values(\"mem_footprint[MB]\").reset_index(drop=True)[\"matrix name\"]\n",
    "    \n",
    "    n_runs = len(results_list)\n",
    "    results_final = []\n",
    "    for matrix in matrices:\n",
    "        nr_rows = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original rows\"])[0]\n",
    "        nr_cols = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original cols\"])[0]        \n",
    "        nr_nnz = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original NNZs\"])[0]\n",
    "        density = nr_nnz/(nr_rows*nr_cols)*100\n",
    "        runtime_iter = np.zeros(shape=(n_runs,1))\n",
    "        perf_padded = np.zeros(shape=(n_runs,1))\n",
    "        mem_footprint = np.zeros(shape=(n_runs,1))\n",
    "\n",
    "        for run in range(0,n_runs):\n",
    "            df = dataframes[run]\n",
    "            runtime_iter[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"time[ms]/run\"])[0]\n",
    "            perf_padded[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"performance (padded)[GFLOPs]\"])[0]\n",
    "            mem_footprint[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"mem_footprint[MB]\"])[0]\n",
    "        if(perf_padded[0][0]<0): # why? nobody knows why\n",
    "            continue\n",
    "\n",
    "        runtime_iter_hm = hmean(runtime_iter,axis=0)[0]\n",
    "        perf_padded_hm = hmean(perf_padded,axis=0)[0]\n",
    "        mem_footprint = hmean(mem_footprint,axis=0)[0]\n",
    "\n",
    "        W_avg = 33\n",
    "        J_estimated = W_avg*runtime_iter_hm\n",
    "        \n",
    "        line_list = [matrix, nr_rows, nr_cols, nr_nnz, density, mem_footprint, \n",
    "                     \"Xilinx_SpMV\", runtime_iter_hm, perf_padded_hm, W_avg, J_estimated\n",
    "                    ]\n",
    "        line = \",\".join(str(x) for x in line_list) + \"\\n\"\n",
    "        results_final.append(line)\n",
    "\n",
    "    file = open(results_csv,\"w\")\n",
    "    for line in results_final:\n",
    "        file.write(line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b4b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = [\n",
    "    \"./dirty/validation_matrices_run1.txt\",\n",
    "]\n",
    "\n",
    "results_list = [\n",
    "    \"./clean/validation_matrices_run1.txt\",\n",
    "]\n",
    "clean_results(start_list, results_list)\n",
    "\n",
    "results_csv = \"./results_validation_matrices.csv\"\n",
    "read_results2(results_list, results_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a43585",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650470c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_equally(starter_file, nummer):\n",
    "    cnt_m = 0\n",
    "    with open(starter_file) as fp:\n",
    "        for line in fp:\n",
    "            curr_m = int(line.split(\" \")[0])\n",
    "            cnt_m += curr_m\n",
    "    step = cnt_m//nummer\n",
    "    fp = open(starter_file,\"r\")\n",
    "    lines = fp.readlines()\n",
    "    cnt_file = 0\n",
    "    for num in range(nummer):\n",
    "        partial_file = starter_file.split(\".txt\")[0] + \"_\" + str(num+1) + \".txt\"\n",
    "        fw = open(partial_file,\"w\")\n",
    "        cnt_m = 0\n",
    "        while(cnt_m <= step and cnt_file < len(lines)):\n",
    "            curr_line = lines[cnt_file]\n",
    "            fw.write(curr_line)\n",
    "            cnt_file += 1\n",
    "            cnt_m += int(curr_line.split(\" \")[0])\n",
    "        fw.close()\n",
    "        print(partial_file.split(\"/\")[-1], \"\\t\", num, \"\\t\", cnt_file, \"\\t\", cnt_m)\n",
    "    fp.close()\n",
    "    \n",
    "starter_file = \"../artificial_matrix_generation/pmpakos_impl/matrix_generation_parameters/double/validation_matrices_friends/dataset_small.txt\"\n",
    "nummer = 7\n",
    "\n",
    "# split_equally(starter_file, nummer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9e39c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "151f27fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "0 / 13 ready. 13 remain\n"
     ]
    }
   ],
   "source": [
    "def clean_progress_log(start_gen, clean_gen, clean_gen2):\n",
    "    fw = open(clean_gen,\"w\")\n",
    "    # fw2 = open(clean_gen2,\"w\")\n",
    "    cnt = 0\n",
    "    with open(start_gen) as fp:\n",
    "        for line in fp:\n",
    "            # print(line)\n",
    "            if(  (\"%|\" not in line) and not(line==\"\\n\") and (\"MEMORY USED :\" not in line) and (\"->\" not in line)):\n",
    "                fw.write(line)\n",
    "            # if(  (\"%|\" not in line) and not(line==\"\\n\") ):\n",
    "                # fw2.write(line)\n",
    "    fw.close()\n",
    "    # fw2.close()\n",
    "    \n",
    "def clean_progress_log_wrapper(distr_memrange):\n",
    "    prefix = \"../artificial_matrix_generation/pmpakos_impl/matrix_generation_parameters/double/rest/progress\"\n",
    "    workers=0\n",
    "    for ID in range(0,15,1):\n",
    "        start_gen = prefix+distr_memrange+\"_\"+str(ID)\n",
    "        if(os.path.exists(start_gen)):\n",
    "            workers+=1\n",
    "            clean_gen = prefix+distr_memrange+\"_\"+str(ID)+\"_clean\"\n",
    "            clean_gen2 = prefix+distr_memrange+\"_\"+str(ID)+\"_clean2\"\n",
    "            print(ID)\n",
    "            clean_progress_log(start_gen, clean_gen, clean_gen2)\n",
    "    if(workers>0):\n",
    "        fw = open(\"../artificial_matrix_generation/pmpakos_impl/matrix_generation_parameters/double/rest/progress_total\", \"w\")\n",
    "        cnt = -workers\n",
    "        for ID in range(0,15,1):\n",
    "            start_gen = prefix+distr_memrange+\"_\"+str(ID)+\"_clean\"\n",
    "            if(os.path.exists(start_gen)):\n",
    "                with open(start_gen) as fp:\n",
    "                    for line in fp:\n",
    "                        fw.write(line)\n",
    "                        if(\">>>>\" in line):\n",
    "                            cnt+=1\n",
    "        fw.close()\n",
    "        total_set = \"../artificial_matrix_generation/pmpakos_impl/matrix_generation_parameters/double/rest/dataset_small.txt\"\n",
    "        cnt_total=0\n",
    "        if(os.path.exists(total_set)):\n",
    "            cnt_total = sum(1 for line in open(total_set,\"r\"))\n",
    "        print(cnt,\"/\",cnt_total,\"ready.\", cnt_total-cnt, \"remain\")\n",
    "\n",
    "\n",
    "distr_memrange = \"\"\n",
    "clean_progress_log_wrapper(distr_memrange)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
