{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab84ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import hmean\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9aebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_parser(log_file, results_file):\n",
    "    results_list = []\n",
    "    with open(log_file,\"r\") as fp:\n",
    "        for line in fp:\n",
    "            split = line.split()\n",
    "            split2 = line.split(\",\")\n",
    "            if(len(split)>0):\n",
    "                if(\"pmpakos@\" in split[0]):\n",
    "                    matrix_name = ''\n",
    "                    # print(\"---------\")\n",
    "            if(len(split)>2):\n",
    "                if((split[0]==\"INFO:\") & (split[1]==\"loading\") & (split[2]==\"Mtx\")):\n",
    "                    print(split[-1])\n",
    "                    matrix_name = split[-1].split(\"/\")[-1]\n",
    "                    matrix_name = matrix_name.replace(\".mtx\",\"\")\n",
    "            if(len(split2)>2):\n",
    "                if(split2[1]!=\" matrix\"):\n",
    "                    line=line.replace(\"app\",matrix_name).strip(\"DATA_CSV:,\")\n",
    "                    # line=line.replace(\",\",\"\\t\")\n",
    "                    results_list.append(line)\n",
    "                    print(line)\n",
    "\n",
    "    file = open(results_file,\"w\")\n",
    "    for res in results_list:\n",
    "        file.write(res)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "93332d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates found : 621\n",
      "478\n",
      "CPU times: user 5.27 s, sys: 0 ns, total: 5.27 s\n",
      "Wall time: 5.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean_matrix_generation_log2(start_gen):\n",
    "    fw_list = []\n",
    "    cnt = 0\n",
    "    with open(start_gen) as fp:\n",
    "        prev_line = \"NULL\"\n",
    "        param_df = pd.DataFrame()\n",
    "        param_df[\"param\"] = []\n",
    "        param_df[\"name\"] = []\n",
    "        \n",
    "        for line in fp:\n",
    "            if(\">>>> \" in line):\n",
    "                line = line.strip(\">>>> \").replace(\" \",\",\")#.replace(\".mtx\",\"\")\n",
    "                line_spl = line.split(\",\")\n",
    "                line_spl[0] = line_spl[0].replace(\".0_\",\"_\")\n",
    "                line_new = \",\".join(line_spl)\n",
    "                param_df = param_df.append({\"param\": prev_line, \"name\": line_spl[0]}, ignore_index = True)\n",
    "                if(line not in fw_list):\n",
    "                    fw_list.append(line)\n",
    "                else:\n",
    "                    cnt+=1\n",
    "            prev_line = line.strip(\"\\n\")\n",
    "    print(\"duplicates found :\", cnt)\n",
    "    return param_df\n",
    "\n",
    "\n",
    "\n",
    "mem_range = \"4-32\"\n",
    "# mem_range = \"32-512\"\n",
    "# mem_range = \"512-2048\"\n",
    "\n",
    "start_gen = \"./generation_stats/normal_\"+mem_range+\"_log.txt\"\n",
    "param_df = clean_matrix_generation_log2(start_gen)\n",
    "\n",
    "counter = Counter(param_df[\"name\"])\n",
    "filtered_counter = dict()\n",
    "for (key, value) in counter.items():\n",
    "    if(value > 1):\n",
    "        filtered_counter[key] = value\n",
    "\n",
    "filtered_counter = dict(sorted(filtered_counter.items(), key=lambda item: item[1]))\n",
    "duplicate_matrices = filtered_counter.keys()\n",
    "print(len(duplicate_matrices))\n",
    "\n",
    "fw = open(\"duplicate_matrices_neighbours_generator_\"+mem_range+\".txt\",\"w\")\n",
    "for matrix in duplicate_matrices:\n",
    "    fw.write(matrix+\"\\n\")\n",
    "    lista = list(param_df[param_df[\"name\"] == matrix][\"param\"])\n",
    "    for a in lista:\n",
    "        fw.write('\\t'+a+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39e28a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_matrix_generation_log(start_gen, results_gen):\n",
    "    fw = open(results_gen,\"w\")\n",
    "    fw_list = []\n",
    "    cnt = 0\n",
    "    with open(start_gen) as fp:\n",
    "        prev_line = \"NULL\"\n",
    "        param_df = pd.DataFrame()\n",
    "        \n",
    "        for line in fp:\n",
    "            if(\">>>> \" in line):\n",
    "                param_df.append({\"param\": prev_line, \"name\": line}, ignore_index = True)\n",
    "                if(line not in fw_list):\n",
    "                    fw_list.append(line)\n",
    "                    line = line.strip(\">>>> \").replace(\" \",\",\")#.replace(\".mtx\",\"\")\n",
    "                    line_spl = line.split(\",\")\n",
    "                    line_spl[0] = line_spl[0].replace(\".0_\",\"_\")\n",
    "                    # line_spl[0] = line_spl[0].split(\"_\")\n",
    "                    # del line_spl[0][3]\n",
    "                    # line_spl[0] = \"_\".join(line_spl[0])\n",
    "                    line_new = \",\".join(line_spl)\n",
    "                    fw.write(line_new)\n",
    "                else:\n",
    "                    cnt+=1\n",
    "                    \n",
    "            prev_line = line\n",
    "    print(\"duplicates found :\", cnt)\n",
    "    fw.close()\n",
    "\n",
    "def clean_results(start_list, results_list):\n",
    "    for t1,t2 in zip(start_list,results_list):\n",
    "        fw = open(t2,\"w\")\n",
    "        with open(t1) as fp:\n",
    "            for line in fp:\n",
    "                if(\"DATA_CSV:,\" in line):\n",
    "                    line_new = line.strip(\"DATA_CSV:,\").replace(\".0_\",\"_\")\n",
    "                    fw.write(line_new)\n",
    "        fw.close()\n",
    "    \n",
    "def read_results_single(result_file):\n",
    "    header = [\"matrix_name\",\"original rows\",\"original cols\",\"original NNZs\",\n",
    "              \"padded rows\",\"padded cols\",\"padded NNZs\",\"padding overhead[%]\",\n",
    "              \"num of runs\",\"total run time[sec]\",\"time[ms]/run\",\"performance[GFLOPs]\",\"performance (padded)[GFLOPs]\",\"mem_footprint[MB]\"]\n",
    "    df = pd.read_table(result_file, delimiter =\",\", names=header)\n",
    "    return df\n",
    "\n",
    "def read_results(results_list, results_gen, results_csv):\n",
    "    # this header was used for old result reporting\n",
    "    # header = [\"matrix_name\",\"mem_range\",\"avg_nnz_per_row\",\"std_nnz_per_row\",\"avg_bw\",\"std_bw\",\"avg_sc\",\"std_sc\"]\n",
    "    # v2 dgal generator\n",
    "    header = [\"matrix_name\", \"distribution\", \"placement\", \"seed\", \n",
    "              \"nr_rows\", \"nr_cols\", \"nr_nnz\", \"density\", \"mem_footprint\", \"mem_range\", \n",
    "              \"avg_nnz_per_row\", \"std_nnz_per_row\", \n",
    "              \"avg_bw\", \"std_bw\", \"avg_bw_scaled\", \"std_bw_scaled\", \n",
    "              \"avg_sc\", \"std_sc\", \"avg_sc_scaled\", \"std_sc_scaled\", \n",
    "              \"skew_coeff\", \"avg_num_neighbours\", \"cross_row_similarity\"]\n",
    "    df_gen = pd.read_table(results_gen, delimiter =\",\", names=header) \n",
    "    \n",
    "    dataframes = []\n",
    "    for result_file in results_list:\n",
    "        dataframes.append(read_results_single(result_file))\n",
    "    matrices = dataframes[0][\"matrix_name\"].unique()\n",
    "\n",
    "    n_runs = len(results_list)\n",
    "    results_final = []\n",
    "    cntt=0\n",
    "    for matrix in matrices:\n",
    "        # print(matrix)\n",
    "        selected_gen = df_gen[df_gen[\"matrix_name\"]==matrix]\n",
    "        if(len(selected_gen)==0):\n",
    "            print('\\t', matrix)\n",
    "            cntt+=1\n",
    "        else:\n",
    "            matrix_name = np.asarray(selected_gen[\"matrix_name\"])[0]\n",
    "            distribution = np.asarray(selected_gen[\"distribution\"])[0]\n",
    "            placement = np.asarray(selected_gen[\"placement\"])[0]\n",
    "            seed = np.asarray(selected_gen[\"seed\"])[0]\n",
    "            nr_rows = np.asarray(selected_gen[\"nr_rows\"])[0]\n",
    "            nr_cols = np.asarray(selected_gen[\"nr_cols\"])[0]\n",
    "            nr_nnz = np.asarray(selected_gen[\"nr_nnz\"])[0]\n",
    "            density = np.asarray(selected_gen[\"density\"])[0]\n",
    "            # if I want to show mem_footprint of CSR double representation\n",
    "            mem_footprint = np.asarray(selected_gen[\"mem_footprint\"])[0]\n",
    "            \n",
    "            mem_range = np.asarray(selected_gen[\"mem_range\"])[0]\n",
    "            avg_nnz_per_row = np.asarray(selected_gen[\"avg_nnz_per_row\"])[0]\n",
    "            std_nnz_per_row = np.asarray(selected_gen[\"std_nnz_per_row\"])[0]\n",
    "            avg_bw = np.asarray(selected_gen[\"avg_bw\"])[0]\n",
    "            std_bw = np.asarray(selected_gen[\"std_bw\"])[0]\n",
    "            avg_bw_scaled = np.asarray(selected_gen[\"avg_bw_scaled\"])[0]\n",
    "            std_bw_scaled = np.asarray(selected_gen[\"std_bw_scaled\"])[0]\n",
    "            avg_sc = np.asarray(selected_gen[\"avg_sc\"])[0]\n",
    "            std_sc = np.asarray(selected_gen[\"std_sc\"])[0]\n",
    "            avg_sc_scaled = np.asarray(selected_gen[\"avg_sc_scaled\"])[0]\n",
    "            std_sc_scaled = np.asarray(selected_gen[\"std_sc_scaled\"])[0]\n",
    "            skew_coeff = np.asarray(selected_gen[\"skew_coeff\"])[0]\n",
    "            avg_num_neighbours = np.asarray(selected_gen[\"avg_num_neighbours\"])[0]\n",
    "            cross_row_similarity = np.asarray(selected_gen[\"cross_row_similarity\"])[0]\n",
    "\n",
    "            matrix_list = matrix.split(\"_\")\n",
    "            mtx_name = matrix_list[0]\n",
    "\n",
    "            # nr_rows = int(matrix_list[1])\n",
    "            # nr_cols = int(matrix_list[2])\n",
    "\n",
    "            # if(len(matrix_list)==7):#random\n",
    "            #     placement = \"random\"\n",
    "            #     diagonal_factor = 1\n",
    "            # else: #diagonal\n",
    "            #     placement = \"diagonal\"\n",
    "            #     diagonal_factor = matrix_list[6]\n",
    "\n",
    "            # seed = matrix_list[-1].strip(\"n\").strip(\"g\")\n",
    "\n",
    "            # distr = list(filter(lambda x: x.isalpha(), matrix_list[-1]))[0]\n",
    "            # if(distr==\"g\"):\n",
    "            #     distribution=\"gamma\"\n",
    "            # else:\n",
    "            #     distribution=\"normal\"\n",
    "\n",
    "            # nr_nnz = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original NNZs\"])[0]\n",
    "            # density = nr_nnz/(nr_rows*nr_cols)*100\n",
    "\n",
    "            runtime_iter = np.zeros(shape=(n_runs,1))\n",
    "            perf_padded = np.zeros(shape=(n_runs,1))\n",
    "            # mem_footprint = np.zeros(shape=(n_runs,1))\n",
    "\n",
    "            for run in range(0,n_runs):\n",
    "                df = dataframes[run]\n",
    "                runtime_iter[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"time[ms]/run\"])[0]\n",
    "                perf_padded[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"performance (padded)[GFLOPs]\"])[0]\n",
    "                # mem_footprint[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"mem_footprint[MB]\"])[0]\n",
    "            if(perf_padded[0][0]<0): # why? nobody knows why\n",
    "                continue\n",
    "\n",
    "            runtime_iter_hm = hmean(runtime_iter,axis=0)[0]\n",
    "            perf_padded_hm = hmean(perf_padded,axis=0)[0]\n",
    "            # if I want to show mem_footprint of Xilinx sparse double representation\n",
    "            # mem_footprint = hmean(mem_footprint,axis=0)[0]\n",
    "\n",
    "            # selected_gen = df_gen[df_gen[\"matrix_name\"]==matrix]\n",
    "            # mem_range = np.asarray(selected_gen[\"mem_range\"])[0]\n",
    "            # avg_nnz_per_row = np.asarray(selected_gen[\"avg_nnz_per_row\"])[0]\n",
    "            # std_nnz_per_row = np.asarray(selected_gen[\"std_nnz_per_row\"])[0]\n",
    "            # avg_bw = np.asarray(selected_gen[\"avg_bw\"])[0]\n",
    "            # std_bw = np.asarray(selected_gen[\"std_bw\"])[0]\n",
    "            # avg_sc = np.asarray(selected_gen[\"avg_sc\"])[0]\n",
    "            # std_sc = np.asarray(selected_gen[\"std_sc\"])[0]/nr_cols\n",
    "\n",
    "            W_avg = 33\n",
    "            J_estimated = W_avg*runtime_iter_hm\n",
    "\n",
    "            line_list = [matrix_name, distribution, placement, seed,\n",
    "                         nr_rows, nr_cols, nr_nnz, density, mem_footprint, mem_range,\n",
    "                         avg_nnz_per_row, std_nnz_per_row, \n",
    "                         avg_bw, std_bw, avg_bw_scaled, std_bw_scaled,\n",
    "                         avg_sc, std_sc, avg_sc_scaled, std_sc_scaled,\n",
    "                         skew_coeff, avg_num_neighbours, cross_row_similarity, \n",
    "                         \"Xilinx_SpMV\", runtime_iter_hm, perf_padded_hm, W_avg, J_estimated\n",
    "                        ]\n",
    "            line = \",\".join(str(x) for x in line_list) + \"\\n\"\n",
    "            results_final.append(line)\n",
    "        \n",
    "    file = open(results_csv,\"w\")\n",
    "    for line in results_final:\n",
    "        file.write(line)\n",
    "    file.close()\n",
    "    print(\"Results for\",len(results_final),\"matrices for\",results_csv.split(\"/\")[-1])\n",
    "    if(cntt>0):\n",
    "        print(cntt, \"matrices not found\")\n",
    "\n",
    "def extract_results_of_distr_memrange(distr_memrange):\n",
    "    start_gen = \"./generation_stats/\"+distr_memrange+\"_log.txt\"\n",
    "    results_gen = \"./generation_stats/\"+distr_memrange+\"_log_CLEAN.txt\"\n",
    "    clean_matrix_generation_log(start_gen, results_gen)\n",
    "\n",
    "    start_list = [\n",
    "        \"./dirty/\"+distr_memrange+\"_run1.txt\",\n",
    "    ]\n",
    "\n",
    "    results_list = [\n",
    "        \"./clean/\"+distr_memrange+\"_run_CLEAN1.txt\",\n",
    "    ]\n",
    "    clean_results(start_list, results_list)\n",
    "\n",
    "    results_csv = \"./results_\"+distr_memrange+\".csv\"\n",
    "    read_results(results_list, results_gen, results_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "ed9594a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates found : 465\n",
      "Results for 1690 matrices for results_normal_4-32.csv\n",
      "duplicates found : 100\n",
      "Results for 2330 matrices for results_normal_32-512.csv\n",
      "duplicates found : 0\n",
      "Results for 1425 matrices for results_normal_512-2048.csv\n",
      "CPU times: user 37.2 s, sys: 132 ms, total: 37.3 s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "distr_base = \"normal\"\n",
    "# mem_ranges = [\"4-8\",\"8-16\",\"16-32\",\"32-64\",\"64-128\",\"128-256\",\"256-512\",\"512-1024\",\"1024-2048\"]\n",
    "mem_ranges = [\"4-32\", \"32-512\", \"512-2048\"]\n",
    "\n",
    "for mem_range in mem_ranges:\n",
    "    distr_memrange = distr_base + \"_\" + mem_range\n",
    "    extract_results_of_distr_memrange(distr_memrange)\n",
    "\n",
    "filenames = [\"results_\"+distr_base+\"_\"+mr+\".csv\" for mr in mem_ranges]\n",
    "\n",
    "with open('../Benchmarks/xilinx_spmv_4-2048_dtype-D.csv', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b818c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# distr_memrange = \"validation_matrices_synthetic_small\"\n",
    "# extract_results_of_distr_memrange(distr_memrange)\n",
    "# filename = \"results_\"+distr_memrange+\".csv\"\n",
    "\n",
    "# with open('../Benchmarks/xilinx_spmv_'+distr_memrange+'_dtype-D.csv', 'w') as outfile:\n",
    "#     with open(filename) as infile:\n",
    "#             outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda26f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af5492",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36249db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results2(results_list, results_csv):\n",
    "    dataframes = []\n",
    "    for result_file in results_list:\n",
    "        dataframes.append(read_results_single(result_file))\n",
    "    # get matrices sorted by mem_footprint and then begin processing them (so that I do not have to sort them later...)\n",
    "    matrices = dataframes[0][\"matrix_name\"].unique()\n",
    "    # matrices = dataframes[0].groupby([\"matrix name\",\"mem_footprint[MB]\"]).size().reset_index().sort_values(\"mem_footprint[MB]\").reset_index(drop=True)[\"matrix name\"]\n",
    "    \n",
    "    n_runs = len(results_list)\n",
    "    results_final = []\n",
    "    for matrix in matrices:\n",
    "        nr_rows = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original rows\"])[0]\n",
    "        nr_cols = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original cols\"])[0]        \n",
    "        nr_nnz = np.asarray(dataframes[0][dataframes[0][\"matrix_name\"]==matrix][\"original NNZs\"])[0]\n",
    "        density = nr_nnz/(nr_rows*nr_cols)*100\n",
    "        runtime_iter = np.zeros(shape=(n_runs,1))\n",
    "        perf_padded = np.zeros(shape=(n_runs,1))\n",
    "        mem_footprint = np.zeros(shape=(n_runs,1))\n",
    "\n",
    "        for run in range(0,n_runs):\n",
    "            df = dataframes[run]\n",
    "            runtime_iter[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"time[ms]/run\"])[0]\n",
    "            perf_padded[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"performance (padded)[GFLOPs]\"])[0]\n",
    "            mem_footprint[run] = np.asarray(df[df[\"matrix_name\"]==matrix][\"mem_footprint[MB]\"])[0]\n",
    "        if(perf_padded[0][0]<0): # why? nobody knows why\n",
    "            continue\n",
    "\n",
    "        runtime_iter_hm = hmean(runtime_iter,axis=0)[0]\n",
    "        perf_padded_hm = hmean(perf_padded,axis=0)[0]\n",
    "        mem_footprint = hmean(mem_footprint,axis=0)[0]\n",
    "\n",
    "        W_avg = 33\n",
    "        J_estimated = W_avg*runtime_iter_hm\n",
    "        \n",
    "        line_list = [matrix, nr_rows, nr_cols, nr_nnz, density, mem_footprint, \n",
    "                     \"Xilinx_SpMV\", runtime_iter_hm, perf_padded_hm, W_avg, J_estimated\n",
    "                    ]\n",
    "        line = \",\".join(str(x) for x in line_list) + \"\\n\"\n",
    "        results_final.append(line)\n",
    "\n",
    "    file = open(results_csv,\"w\")\n",
    "    for line in results_final:\n",
    "        file.write(line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_list = [\n",
    "#     \"./dirty/validation_matrices_run1.txt\",\n",
    "# ]\n",
    "\n",
    "# results_list = [\n",
    "#     \"./clean/validation_matrices_run1.txt\",\n",
    "# ]\n",
    "# clean_results(start_list, results_list)\n",
    "\n",
    "# results_csv = \"./results_validation_matrices.csv\"\n",
    "# read_results2(results_list, results_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592696f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "e2925e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 33\n",
      "synthetic_matrices_small_dataset_4-32_part11.txt \t 32 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part12.txt \t 64 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part13.txt \t 96 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part14.txt \t 128 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part15.txt \t 160 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part16.txt \t 192 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part17.txt \t 224 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part18.txt \t 256 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part19.txt \t 288 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part20.txt \t 320 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part21.txt \t 352 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part22.txt \t 384 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part23.txt \t 416 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part24.txt \t 448 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part25.txt \t 480 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part26.txt \t 512 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part27.txt \t 544 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part28.txt \t 576 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part29.txt \t 608 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part30.txt \t 640 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part31.txt \t 672 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part32.txt \t 704 \t 32\n",
      "synthetic_matrices_small_dataset_4-32_part33.txt \t 720 \t 16\n"
     ]
    }
   ],
   "source": [
    "def split_equally(starter_file, nummer, extra):\n",
    "    cnt_m = sum(1 for line in open(starter_file,\"r\"))\n",
    "    print(cnt_m, nummer)\n",
    "    if(cnt_m%nummer != 0):\n",
    "        step = cnt_m//(nummer-10-1)\n",
    "    else:\n",
    "        step = cnt_m//(nummer-10)\n",
    "    fp = open(starter_file,\"r\")\n",
    "    lines = fp.readlines()\n",
    "    cnt_file = 0\n",
    "    for num in range(10, nummer):\n",
    "        partial_file = starter_file.split(\".txt\")[0].replace(extra,\"\") + \"_part\" + str(num+1) + \".txt\"\n",
    "        fw = open(partial_file,\"w\")\n",
    "        cnt_m = 0\n",
    "        while(cnt_m < step and cnt_file < len(lines)):\n",
    "            curr_line = lines[cnt_file]\n",
    "            fw.write(curr_line)\n",
    "            cnt_file += 1\n",
    "            cnt_m += 1  # int(curr_line.split(\" \")[0])\n",
    "        fw.close()\n",
    "        print(partial_file.split(\"/\")[-1], \"\\t\", cnt_file, \"\\t\", cnt_m)\n",
    "    fp.close()\n",
    "    \n",
    "distr_memrange = \"4-32\"\n",
    "extra = \"extra_1.4_\"\n",
    "starter_file = \"../matrix_generation_parameters/synthetic_matrices_small_dataset_\"+extra+distr_memrange+\".txt\"\n",
    "nummer = 33\n",
    "\n",
    "split_equally(starter_file, nummer, extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16eeb6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "4ae0f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 remain\n",
      "\n",
      "FINAL_LOG\n",
      "\t 3600 ready\t( 3130 successful - success rate 86.94 % )\n"
     ]
    }
   ],
   "source": [
    "def clean_progress_log(start_gen, clean_gen, flag_write = True):\n",
    "    if(flag_write):\n",
    "        fw = open(clean_gen,\"w\")\n",
    "    cnt, cnt2 = 0, 0\n",
    "    with open(start_gen) as fp:\n",
    "        for line in fp:\n",
    "            # print(line)\n",
    "            if( flag_write and (\"%|\" not in line) and not(line==\"\\n\") and (\"MEMORY USED :\" not in line) and (\"->\" not in line)):\n",
    "                fw.write(line)\n",
    "            if(\"MATRIX FINISHED.\" in line):\n",
    "                cnt+=1\n",
    "            if(\"partition done.\" in line):\n",
    "                cnt2+=1\n",
    "    if(flag_write):\n",
    "        fw.close()\n",
    "    return cnt, cnt2\n",
    "    \n",
    "def clean_progress_log_wrapper(distr_memrange):\n",
    "    prefix = \"../matrix_generation_parameters/\"\n",
    "    max_ID = 35\n",
    "    cnt_total = 0\n",
    "    cnt2_total = 0\n",
    "    cnt3_total = 0\n",
    "    for ID in range(1,max_ID,1):\n",
    "        param_set = prefix+\"synthetic_matrices_small_dataset_\"+distr_memrange+\"_part\"+str(ID)+\".txt\"\n",
    "        if(os.path.exists(param_set)):\n",
    "            cnt3 = sum(1 for line in open(param_set,\"r\"))\n",
    "            cnt3_total += cnt3\n",
    "            cnt, cnt2 = 0, 0\n",
    "            start_gen = prefix+\"progress_\"+distr_memrange+\"_\"+str(ID)\n",
    "            if(os.path.exists(start_gen)):\n",
    "                clean_gen = prefix+\"progress_\"+distr_memrange+\"_\"+str(ID)+\"_clean\"\n",
    "                cnt, cnt2 = clean_progress_log(start_gen, clean_gen)\n",
    "            cnt_total += cnt\n",
    "            cnt2_total += cnt2\n",
    "            print(ID,\"\\t\",cnt,'/',cnt3, \"ready.\\t(\", cnt2, \"successful )\")\n",
    "\n",
    "    if(cnt_total>0):\n",
    "        print(cnt_total,\"/\",cnt3_total,\"ready\\t\\t(\",cnt2_total,\"successful - success rate\", np.round(cnt2_total/cnt_total*100,2),\"% )\")\n",
    "    print(cnt3_total-cnt_total, \"remain\")\n",
    "    final_log = \"../FPGA_stuff/generation_stats/normal_\" + distr_memrange + \"_log.txt\"\n",
    "    cnt, cnt2 = clean_progress_log(final_log, \"\", False)\n",
    "    print(\"\\nFINAL_LOG\\n\\t\",cnt, \"ready\\t(\", cnt2, \"successful - success rate\", np.round(cnt2/cnt*100,2),\"% )\")\n",
    "\n",
    "distr_memrange = \"4-32\"\n",
    "clean_progress_log_wrapper(distr_memrange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1af7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
