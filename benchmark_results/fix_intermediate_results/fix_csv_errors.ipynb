{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34eccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If new format added here, need to specify in key:value with:\n",
    "# key:   filename (without _d.csv) \n",
    "# value: how the format appears in file\n",
    "impl_dict = {\n",
    "    'csr_naive': 'Naive_CSR_CPU',\n",
    "    'csr': 'Custom_CSR_B',\n",
    "    'csr_vector_x86': 'Custom_CSR_BV_x86',\n",
    "    'csr_vector_sve': 'Custom_CSR_BV_SVE',\n",
    "\n",
    "    'mkl_ie': 'MKL_IE',\n",
    "    'aocl_optmv': 'AOCL_OPTMV',\n",
    "    'armpl': 'ARMPL',\n",
    "\n",
    "    'csr5': 'CSR5',\n",
    "    'merge': 'MERGE',\n",
    "    'sell_C_s': 'SELL-32-1',\n",
    "    'sparsex': 'SparseX',\n",
    "\n",
    "    'csr_rocm_vector_b512_nv': 'Custom_CSR_ROCM_VECTOR_b512',\n",
    "    'csr_rocm_adaptive_b512_mb1_nv': 'Custom_CSR_CUDA_ADAPTIVE_b512_1',\n",
    "    'csr_rocm_const_nnz_per_thread_b512_nnz4_nv': 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4',\n",
    "\n",
    "    'csr_rocm_acc_flat_b512_nv': 'ACC_FLAT_b512',\n",
    "    'csr_rocm_acc_line_enhance_b512_nv': 'ACC_LINE_ENHANCE_b512',\n",
    "\n",
    "    'rocsparse_csr_nv': 'ROCSPARSE_CSR',\n",
    "    'rocsparse_coo_nv': 'ROCSPARSE_COO',\n",
    "    'rocsparse_hyb_nv': 'ROCSPARSE_HYB',\n",
    "\n",
    "    'csr_cuda_vector_b256_nv': 'Custom_CSR_CUDA_VECTOR_b256',\n",
    "    'csr_cuda_adaptive_b256_mb1_nv': 'Custom_CSR_CUDA_ADAPTIVE_b256_1',\n",
    "    'csr_cuda_const_nnz_per_thread_b1024_nnz4_nv': 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4',\n",
    "\n",
    "    'csr5_cuda_nv': 'CSR5_CUDA',\n",
    "    'merge_cuda_nv': 'MERGE_CUDA',\n",
    "    'dasp_cuda_nv': 'DASP_CUDA',\n",
    "\n",
    "    'cusparse_csr_nv': 'CUSPARSE_CSR',\n",
    "    'cusparse_coo_nv': 'CUSPARSE_COO',\n",
    "}\n",
    "\n",
    "precision = \"d\"\n",
    "prefix = \"/home/pmpakos/A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc4f71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "def fix_synthetic_csv_errors(file_path, flag=0):\n",
    "    # Read the entire file to count lines and occurrences of \"synthetic\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Count lines excluding the header\n",
    "    # flag=1 (sell-C-s) does not have a header, flag=0 (all others) does have a header\n",
    "    if(flag==0):\n",
    "        num_lines = len(lines) - 1\n",
    "    else:\n",
    "        num_lines = len(lines)\n",
    "\n",
    "    # Count occurrences of the word \"synthetic\"\n",
    "    count_synthetic = sum(line.lower().count(\"synthetic\") for line in lines)\n",
    "\n",
    "    # Check if counts differ\n",
    "    if num_lines != count_synthetic:\n",
    "        # Print counts\n",
    "        print(f\"Number of lines (excluding header): {num_lines}\")\n",
    "        print(f\"Occurrences of 'synthetic'        : {count_synthetic}\")\n",
    "        print(f\"Difference in line count and 'synthetic' occurrences for file: {file_path}\\n\")\n",
    "\n",
    "        # Backup the original file\n",
    "        backup_file_path = file_path.replace('.csv', '_BAD.csv')\n",
    "        os.rename(file_path, backup_file_path)\n",
    "        print(f\"Original file backed up as: {backup_file_path}\")\n",
    "\n",
    "        # Filter out lines that do not contain \"synthetic\"\n",
    "        if(flag==0):\n",
    "            filtered_lines = [lines[0]] + [line for line in lines[1:] if \"synthetic\" in line.lower()]\n",
    "        else:\n",
    "            filtered_lines = [line for line in lines if \"synthetic\" in line.lower()]\n",
    "\n",
    "        # Write the filtered content back to the original file path\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(filtered_lines)\n",
    "        print(f\"Filtered file saved as: {file_path}\\n\")\n",
    "\n",
    "def read_synthetic(root, file):\n",
    "    file_path = os.path.join(root, file)\n",
    "    # print(f\"File: {file_path}\")\n",
    "    try:\n",
    "        if (\"sell_C_s_d\" in file):\n",
    "            fix_synthetic_csv_errors(file_path, 1) # 1 for flag\n",
    "            # We need to do the following because SELL-C-s runs on different from other matrices benchmark.\n",
    "            # This way, we make sure that when merging all results according to matrix features, \n",
    "            # all different features will be considered \n",
    "            fix_features(root, file)\n",
    "            SELL_C_S_D_HEADER = [\n",
    "                \"matrix_name\", \"distribution\", \"placement\", \"seed\", \"nr_rows\", \"nr_cols\", \n",
    "                \"nr_nzeros\", \"density\", \"mem_footprint\", \"mem_range\", \"avg_nnz_per_row\", \n",
    "                \"std_nnz_per_row\", \"avg_bw\", \"std_bw\", \"avg_bw_scaled\", \"std_bw_scaled\", \n",
    "                \"avg_sc\", \"std_sc\", \"avg_sc_scaled\", \"std_sc_scaled\", \"skew\", \n",
    "                \"avg_num_neighbours\", \"cross_row_similarity\", \"format_name\", \"time\", \n",
    "                \"gflops\", \"W_avg\", \"J_estimated\"]\n",
    "            df = pd.read_csv(file_path, names=SELL_C_S_D_HEADER, header=0)\n",
    "        else:\n",
    "            fix_synthetic_csv_errors(file_path)\n",
    "            fix_features(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"1) Error reading {file_path}: {e}\\n\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4264804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "def fix_validation_csv_errors(file_path, flag=0):\n",
    "    # Read the entire file to count lines and occurrences of \"synthetic\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Count lines excluding the header\n",
    "    # flag=1 (sell-C-s) does not have a header, flag=0 (all others) does have a header\n",
    "    if(flag==0):\n",
    "        num_lines = len(lines) - 1\n",
    "    else:\n",
    "        num_lines = len(lines)\n",
    "\n",
    "    # Count occurrences of the word \"synthetic\"\n",
    "    count_mtx = sum(line.lower().count(\"mtx\") for line in lines)\n",
    "\n",
    "    # Check if counts differ\n",
    "    if num_lines != count_mtx:\n",
    "        # Print counts\n",
    "        print(f\"Number of lines (excluding header): {num_lines}\")\n",
    "        print(f\"Occurrences of 'mtx'              : {count_mtx}\")\n",
    "        print(f\"Difference in line count and 'mtx' occurrences for file: {file_path}\\n\")\n",
    "\n",
    "        # Backup the original file\n",
    "        backup_file_path = file_path.replace('.csv', '_BAD.csv')\n",
    "        os.rename(file_path, backup_file_path)\n",
    "        print(f\"Original file backed up as: {backup_file_path}\")\n",
    "\n",
    "        # Filter out lines that do not contain \"synthetic\"\n",
    "        if(flag==0):\n",
    "            filtered_lines = [lines[0]] + [line for line in lines[1:] if \"mtx\" in line.lower()]\n",
    "        else:\n",
    "            filtered_lines = [line for line in lines if \"mtx\" in line.lower()]\n",
    "\n",
    "        # Write the filtered content back to the original file path\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(filtered_lines)\n",
    "        print(f\"Filtered file saved as: {file_path}\\n\")\n",
    "\n",
    "\n",
    "def read_validation(root, file):\n",
    "    file_path = os.path.join(root, file)\n",
    "    # print(f\"File: {file_path}\")\n",
    "    try:\n",
    "        SELL_C_S_D_HEADER = [\n",
    "            \"matrix_name\", \"num_threads\", \"csr_m\", \"csr_n\", \"csr_nnz\", \"time\",\n",
    "            \"gflops\", \"csr_mem_footprint\", \"W_avg\", \"J_estimated\", \"format_name\", \n",
    "            \"m\", \"n\", \"nnz\", \"mem_footprint\"]\n",
    "        if (\"sell_C_s_d\" in file):\n",
    "            fix_validation_csv_errors(file_path, 1) # 1 for flag\n",
    "            df = pd.read_csv(file_path, names=SELL_C_S_D_HEADER, header=0)\n",
    "        else:\n",
    "            fix_validation_csv_errors(file_path)\n",
    "            df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"2) Error reading {file_path}: {e}\\n\")    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688ac6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "def find_csv_files(directory):\n",
    "    val_df_list = []\n",
    "    friends_df_list = []\n",
    "    synthetic_df_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if (\"DELETE\" not in root) and (\"rep\" in root) and (\"BAD\" not in file):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    if (\"validation\" in root):\n",
    "                        curr_df = read_validation(root, file)\n",
    "                        # print(\"val_df_list:\", file_path)\n",
    "                        val_df_list.append(curr_df)          \n",
    "                    else:\n",
    "                        curr_df = read_synthetic(root, file)\n",
    "                        if(\"friends\" in root):\n",
    "                            # print(\"friends_df_list:\", file_path)\n",
    "                            friends_df_list.append(curr_df)\n",
    "                        if(\"synthetic\" in root):\n",
    "                            # print(\"synthetic_df_list:\", file_path)\n",
    "                            synthetic_df_list.append(curr_df)\n",
    "    friends_df = pd.concat(friends_df_list, ignore_index=True)\n",
    "    synthetic_df = pd.concat(synthetic_df_list, ignore_index=True)\n",
    "    print(\"friends:   \", friends_df.shape)\n",
    "    print(\"synthetic: \", synthetic_df.shape)\n",
    "    return (friends_df, synthetic_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0c421",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729dfb78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 2 µs, total: 11 µs\n",
      "Wall time: 20.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# testbed = \"amd-epyc7763\"\n",
    "# threads = 64\n",
    "\n",
    "# friends_df, synthetic_df = find_csv_files(prefix + testbed + \"/\")\n",
    "\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"friends_10_samples_30_range\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "# friends_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"synthetic\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "# synthetic_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b68f873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# testbed = \"amd-mi250\"\n",
    "\n",
    "# friends_df, synthetic_df = find_csv_files(prefix + testbed + \"/\")\n",
    "\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"friends_10_samples_30_range\" + \"_\" + precision + \".csv\"\n",
    "# friends_df.to_csv(output_csv_file, index=False, sep=',')\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"synthetic\" + \"_\" + precision + \".csv\"\n",
    "# synthetic_df.to_csv(output_csv_file, index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd86ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 16.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# testbed = \"intel-sapphire\"\n",
    "# threads = 56\n",
    "\n",
    "# friends_df, synthetic_df = find_csv_files(prefix + testbed + \"/\")\n",
    "\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"friends_10_samples_30_range\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "# friends_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n",
    "# output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"synthetic\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "# synthetic_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "714c4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines (excluding header): 16190\n",
      "Occurrences of 'synthetic'        : 15760\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/csr_vector_sve_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/csr_vector_sve_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/csr_vector_sve_d.csv\n",
      "\n",
      "Number of lines (excluding header): 16190\n",
      "Occurrences of 'synthetic'        : 16186\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/sparsex_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/sparsex_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-arm/intermediate/rep1/synthetic/sparsex_d.csv\n",
      "\n",
      "Number of lines (excluding header): 3637\n",
      "Occurrences of 'synthetic'        : 3570\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/csr_vector_sve_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/csr_vector_sve_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/csr_vector_sve_d.csv\n",
      "\n",
      "Number of lines (excluding header): 3637\n",
      "Occurrences of 'synthetic'        : 3623\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/sparsex_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/sparsex_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-arm/intermediate/rep1/friends/sparsex_d.csv\n",
      "\n",
      "friends:    (21741, 28)\n",
      "synthetic:  (96706, 28)\n",
      "CPU times: user 2.55 s, sys: 208 ms, total: 2.75 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def fix_features(root, file):\n",
    "    file_path = os.path.join(root, file)\n",
    "    if('friends' in file_path):\n",
    "        with open('feats_friends.csv') as f:\n",
    "            features = f.readlines()\n",
    "    if('synthetic' in file_path):\n",
    "        with open('feats_synthetic.csv') as f:\n",
    "            features = f.readlines()\n",
    "    for i in range(len(features)):\n",
    "        features[i] = features[i].strip('\\n')\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if('sell_C_s' not in file_path):\n",
    "            lines0 = lines[0]\n",
    "            lines = lines[1:]\n",
    "    \n",
    "    impl  = file.replace('_'+precision+'.csv','')\n",
    "    impl2 = impl_dict[impl]\n",
    "    # print(impl, impl2)\n",
    "    filtered_lines = []\n",
    "    if('sell_C_s' not in file_path):\n",
    "        filtered_lines.append(lines0)\n",
    "    if(len(features) == len(lines)):\n",
    "        for i,j in zip(features, lines):\n",
    "            j_stripped = j.split(','+impl2)[1]\n",
    "            new_line = i.strip('\\n') + ',' + impl2 + j_stripped\n",
    "            filtered_lines.append(new_line)\n",
    "    else:\n",
    "        # print(file_path, \"\\t\", \"len(features)\", len(features), \"\\t\", \"len(lines)\", len(lines))\n",
    "        cnt = 0\n",
    "        for j in lines:\n",
    "            j_spl = j.split(',')\n",
    "            j_spl_new = ','.join(j_spl[0:5])\n",
    "\n",
    "            i = features[cnt]\n",
    "            i_spl = i.split(',')\n",
    "            i_spl_new = ','.join(i_spl[0:5])\n",
    "\n",
    "            while(i_spl_new != j_spl_new):\n",
    "                cnt+=1\n",
    "                i = features[cnt]\n",
    "                i_spl = i.split(',')\n",
    "                i_spl_new = ','.join(i_spl[0:5])\n",
    "\n",
    "            if(i_spl_new == j_spl_new):\n",
    "                \n",
    "                j_stripped = j.split(','+impl2)[1]\n",
    "                new_line = i.strip('\\n') + ',' + impl2 + j_stripped\n",
    "                filtered_lines.append(new_line)\n",
    "            cnt+=1\n",
    "#             print(j, cnt)\n",
    "\n",
    "    # Backup the original file\n",
    "    backup_file_path = file_path.replace('.csv', '_BAD_FEATURES.csv')\n",
    "    os.rename(file_path, backup_file_path)\n",
    "    # Write the filtered content back to the original file path\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.writelines(filtered_lines)\n",
    "    # print(f\"Original file backed up as: {backup_file_path}\")\n",
    "    # print(f\"Filtered file saved as: {file_path}\\n\")\n",
    "testbed = \"grace1-arm\"\n",
    "threads = 72\n",
    "\n",
    "friends_df, synthetic_df = find_csv_files(prefix + testbed + \"/\")\n",
    "\n",
    "output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"friends_10_samples_30_range\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "friends_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n",
    "output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"synthetic\" + \"_t\" + str(threads) + \"_\" + precision + \".csv\"\n",
    "synthetic_df.to_csv(output_csv_file, index=False, header=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93eb3d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines (excluding header): 16190\n",
      "Occurrences of 'synthetic'        : 15650\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/merge_cuda_nv_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/merge_cuda_nv_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/merge_cuda_nv_d.csv\n",
      "\n",
      "Number of lines (excluding header): 16865\n",
      "Occurrences of 'synthetic'        : 13445\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/csr_cuda_adaptive_b256_mb1_nv_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/csr_cuda_adaptive_b256_mb1_nv_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-H100/intermediate/rep1/synthetic/csr_cuda_adaptive_b256_mb1_nv_d.csv\n",
      "\n",
      "Number of lines (excluding header): 3637\n",
      "Occurrences of 'synthetic'        : 3633\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/merge_cuda_nv_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/merge_cuda_nv_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/merge_cuda_nv_d.csv\n",
      "\n",
      "Number of lines (excluding header): 3643\n",
      "Occurrences of 'synthetic'        : 2909\n",
      "Difference in line count and 'synthetic' occurrences for file: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/csr_cuda_adaptive_b256_mb1_nv_d.csv\n",
      "\n",
      "Original file backed up as: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/csr_cuda_adaptive_b256_mb1_nv_d_BAD.csv\n",
      "Filtered file saved as: /home/pmpakos/A/grace1-H100/intermediate/rep1/friends/csr_cuda_adaptive_b256_mb1_nv_d.csv\n",
      "\n",
      "friends:    (28364, 28)\n",
      "synthetic:  (142425, 28)\n",
      "CPU times: user 3.35 s, sys: 146 ms, total: 3.5 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "testbed = \"grace1-H100\"\n",
    "\n",
    "friends_df, synthetic_df = find_csv_files(prefix + testbed + \"/\")\n",
    "\n",
    "output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"friends_10_samples_30_range\" + \"_\" + precision + \".csv\"\n",
    "friends_df.to_csv(output_csv_file, index=False, sep=',')\n",
    "output_csv_file = prefix + testbed + \"/\" + testbed + \"_\" + \"synthetic\" + \"_\" + precision + \".csv\"\n",
    "synthetic_df.to_csv(output_csv_file, index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51da949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
