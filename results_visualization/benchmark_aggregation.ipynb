{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423de4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import time\n",
    "import os\n",
    "# import pickle\n",
    "import dill as pickle  # Use dill instead of pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588eb55",
   "metadata": {},
   "source": [
    "---\n",
    "# some general use functions before moving on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb6d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_category(x, cat_list, cat_size, ranges_size_flag=False):\n",
    "    for index in range(len(cat_list)):\n",
    "        cat = cat_list[index]\n",
    "        cat_min = float(cat.strip('[').strip(']').split('-')[0])\n",
    "        cat_max = float(cat.strip('[').strip(']').split('-')[1])\n",
    "        # print(cat_min, cat_max,'->\\t->', x)\n",
    "        if(x>cat_min and x<=cat_max):\n",
    "            if(ranges_size_flag==True):\n",
    "                return cat_size[index]\n",
    "            else:\n",
    "                return cat_list[index]\n",
    "\n",
    "def set_category2(x, cat_list, cat_size, ranges_size_flag=False):\n",
    "    for index in range(len(cat_list)):\n",
    "        cat = cat_list[index]\n",
    "        if(x==cat):\n",
    "            return cat_size[index]\n",
    "\n",
    "# write all available devices here\n",
    "ranges_dev = [\n",
    "                'NVIDIA-P100', 'NVIDIA-V100', 'NVIDIA-A100', 'NVIDIA-H100', 'AMD-MI250',\n",
    "                'AMD-EPYC-24', 'AMD-EPYC-64',\n",
    "                'INTEL-XEON-14', 'INTEL-ICY-16', 'INTEL-SAPPHIRE-56',\n",
    "                'ARM-NEON-80', 'ARM-GRACE-72',\n",
    "                'IBM-POWER9-32'\n",
    "             ]\n",
    "ranges_dev_backup = ranges_dev\n",
    "\n",
    "# this is used to set limits on the y-axis for each device separately\n",
    "y_limit_dictionary = {\n",
    "    'NVIDIA-P100' : [0, 100],\n",
    "    'NVIDIA-V100' : [0, 140],\n",
    "    'NVIDIA-A100' : [0, 230],\n",
    "    'NVIDIA-H100' : [0, 630],\n",
    "    'AMD-MI250' : [0, 240],\n",
    "   \n",
    "    'AMD-EPYC-64' : [0, 240],\n",
    "    'AMD-EPYC-24' : [0, 110],\n",
    "\n",
    "    'INTEL-XEON-14' : [0, 50],\n",
    "    'INTEL-ICY-16' : [0, 70],\n",
    "    'INTEL-SAPPHIRE-56' : [0, 320],\n",
    "\n",
    "    'ARM-NEON-80' : [0, 190],\n",
    "    'ARM-GRACE-72' : [0, 280],\n",
    "   \n",
    "    'IBM-POWER9-32' : [0, 55],\n",
    "\n",
    "    # 'Alveo-U280' : [0, 30]\n",
    "}\n",
    "\n",
    "llc_thresholds = {\n",
    "    'AMD-EPYC-64' : 256,\n",
    "    'AMD-EPYC-24' : 128,\n",
    "\n",
    "    'INTEL-XEON-14' : 19.25,\n",
    "    'INTEL-ICY-16' : 24,\n",
    "    'INTEL-SAPPHIRE-56' : 105,\n",
    "\n",
    "    'ARM-NEON-80' : 80,\n",
    "    'ARM-GRACE-72' : 114,\n",
    "   \n",
    "    'IBM-POWER9-32' : 80,\n",
    "}\n",
    "\n",
    "# need to write them all down here, so that they appear in this specific order when printing them per device...\n",
    "ranges_impl_arch = [         \n",
    "    '( NVIDIA-P100 )\\tcu-COO', '( NVIDIA-P100 )\\tcu-CSR', '( NVIDIA-P100 )\\tcu-HYB',\n",
    "    '( NVIDIA-P100 )\\tCSR5',\n",
    "\n",
    "    '( NVIDIA-V100 )\\tcu-COO', '( NVIDIA-V100 )\\tcu-CSR', '( NVIDIA-V100 )\\tcu-HYB',\n",
    "    '( NVIDIA-V100 )\\tCSR5',\n",
    "\n",
    "    '( NVIDIA-A100 )\\tcu-COO', '( NVIDIA-A100 )\\tcu-CSR',\n",
    "    '( NVIDIA-A100 )\\tMerge-CSR', '( NVIDIA-A100 )\\tSELL-C-σ',\n",
    "\n",
    "    '( NVIDIA-H100 )\\tcu-CSR', '( NVIDIA-H100 )\\tcu-COO',\n",
    "    '( NVIDIA-H100 )\\tVec-CSR', '( NVIDIA-H100 )\\tAda-CSR', '( NVIDIA-H100 )\\tCustom-CSR',\n",
    "    '( NVIDIA-H100 )\\tCSR5', '( NVIDIA-H100 )\\tDASP', '( NVIDIA-H100 )\\tMerge-CSR',\n",
    "\n",
    "    '( AMD-MI250 )\\troc-CSR', '( AMD-MI250 )\\troc-COO', '( AMD-MI250 )\\troc-HYB',\n",
    "    '( AMD-MI250 )\\tVec-CSR', '( AMD-MI250 )\\tAda-CSR', '( AMD-MI250 )\\tCustom-CSR',\n",
    "    '( AMD-MI250 )\\tACC-Line', '( AMD-MI250 )\\tACC-Flat',\n",
    "\n",
    "    '( AMD-EPYC-24 )\\tMKL-IE', '( AMD-EPYC-24 )\\tAOCL',\n",
    "    '( AMD-EPYC-24 )\\tNaive-CSR', '( AMD-EPYC-24 )\\tVec-CSR',  # '( AMD-EPYC-24 )\\tVec-Bal-CSR',\n",
    "    '( AMD-EPYC-24 )\\tCSR5', '( AMD-EPYC-24 )\\tSparseX', '( AMD-EPYC-24 )\\tMerge-CSR', '( AMD-EPYC-24 )\\tSELL-C-σ',\n",
    "   \n",
    "    '( AMD-EPYC-64 )\\tMKL-IE', '( AMD-EPYC-64 )\\tAOCL',\n",
    "    '( AMD-EPYC-64 )\\tNaive-CSR', '( AMD-EPYC-64 )\\tBal-CSR', '( AMD-EPYC-64 )\\tVec-CSR',\n",
    "    '( AMD-EPYC-64 )\\tCSR5', '( AMD-EPYC-64 )\\tSparseX', '( AMD-EPYC-64 )\\tMerge-CSR', '( AMD-EPYC-64 )\\tSELL-C-σ', '( AMD-EPYC-64 )\\tLCM',\n",
    "\n",
    "    '( INTEL-XEON-14 )\\tMKL-IE',\n",
    "    '( INTEL-XEON-14 )\\tNaive-CSR', '( INTEL-XEON-14 )\\tVec-CSR',\n",
    "    '( INTEL-XEON-14 )\\tCSR5', '( INTEL-XEON-14 )\\tSparseX', '( INTEL-XEON-14 )\\tMerge-CSR', '( INTEL-XEON-14 )\\tSELL-C-σ', \n",
    "\n",
    "    '( INTEL-ICY-16 )\\tMKL-IE',\n",
    "    '( INTEL-ICY-16 )\\tNaive-CSR', '( INTEL-ICY-16 )\\tVec-CSR',\n",
    "    '( INTEL-ICY-16 )\\tCSR5', '( INTEL-ICY-16 )\\tSparseX', '( INTEL-ICY-16 )\\tMerge-CSR', '( INTEL-ICY-16 )\\tSELL-C-σ',\n",
    "\n",
    "    '( INTEL-SAPPHIRE-56 )\\tMKL-IE', # '( INTEL-SAPPHIRE-56 )\\tAOCL',\n",
    "    '( INTEL-SAPPHIRE-56 )\\tNaive-CSR', '( INTEL-SAPPHIRE-56 )\\tBal-CSR', '( INTEL-SAPPHIRE-56 )\\tVec-CSR',\n",
    "    '( INTEL-SAPPHIRE-56 )\\tCSR5', '( INTEL-SAPPHIRE-56 )\\tSparseX', '( INTEL-SAPPHIRE-56 )\\tMerge-CSR', '( INTEL-SAPPHIRE-56 )\\tSELL-C-σ', '( INTEL-SAPPHIRE-56 )\\tLCM',\n",
    "\n",
    "    '( ARM-NEON-80 )\\tARM-lib',\n",
    "    '( ARM-NEON-80 )\\tNaive-CSR',\n",
    "    '( ARM-NEON-80 )\\tSparseX', '( ARM-NEON-80 )\\tMerge-CSR', '( ARM-NEON-80 )\\tSELL-C-σ',\n",
    "\n",
    "    '( ARM-GRACE-72 )\\tARM-lib',\n",
    "    '( ARM-GRACE-72 )\\tNaive-CSR', '( ARM-GRACE-72 )\\tBal-CSR', '( ARM-GRACE-72 )\\tVec-CSR',\n",
    "    '( ARM-GRACE-72 )\\tSparseX', '( ARM-GRACE-72 )\\tMerge-CSR',\n",
    "\n",
    "    '( IBM-POWER9-32 )\\tNaive-CSR', '( IBM-POWER9-32 )\\tBal-CSR', '( IBM-POWER9-32 )\\tVec-CSR',\n",
    "    '( IBM-POWER9-32 )\\tSparseX', '( IBM-POWER9-32 )\\tMerge-CSR',\n",
    "]\n",
    "ranges_impl_arch_backup = ranges_impl_arch\n",
    "def filter_ranges_impl_arch(ranges_impl_arch_backup, groupdata, ranges_dev):\n",
    "    return [x for x in ranges_impl_arch_backup if\n",
    "            ((x.split(' )')[0].split('( ')[1] in ranges_dev) and\n",
    "             (x.split('\\t')[1] in set(groupdata[groupdata['System']==x.split(' )')[0].split('( ')[1]]['format_name'])))\n",
    "           ]\n",
    "\n",
    "def calculate_format_wins(ranges_impl_arch, groupdata, ranges_dev):\n",
    "    wins = []\n",
    "    for sys in ranges_dev:\n",
    "        # print('---\\n',sys)\n",
    "        groupdata_sys = groupdata[groupdata['System']==sys]\n",
    "        sys_shape = groupdata_sys.shape[0]\n",
    "        for impl_arch_curr in ranges_impl_arch:\n",
    "            if(sys in impl_arch_curr):\n",
    "                impl = impl_arch_curr.split('\\t')[1]\n",
    "                group_sys_impl = groupdata_sys[groupdata_sys['format_name']==impl]\n",
    "                sys_impl_shape = group_sys_impl.shape[0]\n",
    "                perc = np.round(sys_impl_shape/sys_shape*100,2)\n",
    "                # print(impl, '\\t', perc, '%')\n",
    "                if(perc==100): # This was for the FPGA kernel, which was only 1\n",
    "                    perc = 0\n",
    "                wins.append(perc)\n",
    "    return wins\n",
    "\n",
    "# These ranges_* lists here define the ranges for each feature, that will be used to plot later...\n",
    "ranges_memr = ['[4-8]','[8-16]','[16-32]','[32-64]','[64-128]','[128-256]','[256-512]','[512-1024]','[1024-2048]'] # mem_footprint\n",
    "\n",
    "# ranges_anr = ['[0-20]', '[20-75]','[75-150]', '[150-510]'] # avg_nnz_per_row\n",
    "# ranges_anr = ['[0-15]', '[15-40]', '[40-75]','[75-150]', '[150-510]'] # avg_nnz_per_row\n",
    "# ranges_anr = ['[0-10]', '[10-50]', '[50-510]'] # avg_nnz_per_row\n",
    "ranges_anr = ['[0-10]', '[10-50]', '[50-100]', '[100-510]'] # avg_nnz_per_row\n",
    "\n",
    "# ranges_skew = ['[0-100]', '[100-500]', '[500-2000]', '[2000-180000]'] # skew_coeff\n",
    "ranges_skew = ['[0-1.5]', '[1.5-50]', '[50-250]', '[250-3000]', '[3000-10000]'] # skew_coeff\n",
    "\n",
    "# ranges_ann = ['[0-0.6]', '[0.6-1.4]', '[1.4-2]'] # avg_num_neighbours\n",
    "# ranges_crs = ['[0-0.3]', '[0.3-0.7]', '[0.7-1]'] # cross_row_similarity\n",
    "ranges_ann = ['[0-1]', '[1-2]'] # avg_num_neighbours\n",
    "ranges_crs = ['[0-0.5]', '[0.5-1]'] # cross_row_similarity\n",
    "\n",
    "# ranges_size = ['S', 'M', 'L']\n",
    "# ranges_regularity = ['SS', 'SM', 'SL', 'MS', 'MM', 'ML', 'LS', 'LM', 'LL']\n",
    "ranges_size = ['S', 'L']\n",
    "ranges_regularity = ['SS', 'SL', 'LS', 'LL']\n",
    "\n",
    "cat_list = ['mem_footprint',\n",
    "            'avg_nnz_per_row',\n",
    "            'skew','avg_num_neighbours','cross_row_similarity']\n",
    "ranges_list = [ranges_memr,\n",
    "               ranges_anr,\n",
    "               ranges_skew,\n",
    "               ranges_ann, ranges_crs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144327a",
   "metadata": {},
   "source": [
    "# Store variables and functions to be used in other jupyter notebooks too (using a Pickle/Dill object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd915be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the objects in a file\n",
    "objects_to_save = {\n",
    "    'ranges_dev': ranges_dev,\n",
    "    'ranges_dev_backup': ranges_dev_backup,\n",
    "    'y_limit_dictionary': y_limit_dictionary,\n",
    "    'llc_thresholds': llc_thresholds,\n",
    "    'ranges_impl_arch': ranges_impl_arch,\n",
    "    'ranges_impl_arch_backup': ranges_impl_arch_backup,\n",
    "    'ranges_memr': ranges_memr,\n",
    "    'ranges_anr': ranges_anr,\n",
    "    'ranges_skew': ranges_skew,\n",
    "    'ranges_ann': ranges_ann,\n",
    "    'ranges_crs': ranges_crs,\n",
    "    'ranges_size': ranges_size,\n",
    "    'ranges_regularity': ranges_regularity,\n",
    "    'cat_list': cat_list,\n",
    "    'ranges_list': ranges_list,\n",
    "    \n",
    "    # functions\n",
    "    'set_category': set_category,\n",
    "    'set_category2': set_category2,\n",
    "    'filter_ranges_impl_arch': filter_ranges_impl_arch,\n",
    "    'calculate_format_wins': calculate_format_wins,\n",
    "}\n",
    "\n",
    "with open('objects.pkl', 'wb') as f:\n",
    "    pickle.dump(objects_to_save, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321fb23",
   "metadata": {},
   "source": [
    "---\n",
    "# Some variables and functions to be used when reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc51c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['matrix_name','distribution','placement','seed',\n",
    "                'nr_rows','nr_cols','nr_nzeros','density','mem_footprint','mem_range',\n",
    "                'avg_nnz_per_row','std_nnz_per_row',\n",
    "                'avg_bw','std_bw','avg_bw_scaled','std_bw_scaled',\n",
    "                'avg_sc','std_sc','avg_sc_scaled','std_sc_scaled',\n",
    "                'skew','avg_num_neighbours','cross_row_similarity',\n",
    "                'format_name','time','gflops','W_avg','J_estimated', 'System', 'Arch']\n",
    "\n",
    "# precision = 'f'\n",
    "precision = 'd' # for double-precision arithmetic\n",
    "\n",
    "prefix = '../benchmark_results/'\n",
    "# If new format added here, need to specify in key:value with:\n",
    "# key:   filename (without _d.csv) \n",
    "# value: how the format appears in file\n",
    "impl_dict = {\n",
    "    'csr_naive': 'Naive_CSR_CPU',\n",
    "    'csr': 'Custom_CSR_B',\n",
    "    'csr_vector_x86': 'Custom_CSR_BV_x86',\n",
    "    'csr_vector_sve': 'Custom_CSR_BV_SVE',\n",
    "\n",
    "    'mkl_ie': 'MKL_IE',\n",
    "    'aocl_optmv': 'AOCL_OPTMV',\n",
    "    'armpl': 'ARMPL',\n",
    "\n",
    "    'csr5': 'CSR5',\n",
    "    'merge': 'MERGE',\n",
    "    'sell_C_s': 'SELL-32-1',\n",
    "    # 'sell_C_s': 'SELL-32-512',\n",
    "    'sparsex': 'SparseX',\n",
    "    'lcm': 'LCM', \n",
    "\n",
    "    'csr_rocm_vector_b512_nv': 'Custom_CSR_ROCM_VECTOR_b512',\n",
    "    'csr_rocm_adaptive_b512_mb1_nv': 'Custom_CSR_CUDA_ADAPTIVE_b512_1',\n",
    "    'csr_rocm_const_nnz_per_thread_b512_nnz4_nv': 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4',\n",
    "\n",
    "    'csr_rocm_acc_flat_b512_nv': 'ACC_FLAT_b512',\n",
    "    'csr_rocm_acc_line_enhance_b512_nv': 'ACC_LINE_ENHANCE_b512',\n",
    "\n",
    "    'rocsparse_csr_nv': 'ROCSPARSE_CSR',\n",
    "    'rocsparse_coo_nv': 'ROCSPARSE_COO',\n",
    "    'rocsparse_hyb_nv': 'ROCSPARSE_HYB',\n",
    "\n",
    "    'csr_cuda_vector_b256_nv': 'Custom_CSR_CUDA_VECTOR_b256',\n",
    "    'csr_cuda_adaptive_b256_mb1_nv': 'Custom_CSR_CUDA_ADAPTIVE_b256_1',\n",
    "    'csr_cuda_const_nnz_per_thread_b1024_nnz4_nv': 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4',\n",
    "\n",
    "    'csr5_cuda_nv': 'CSR5_CUDA',\n",
    "    'merge_cuda_nv': 'MERGE_CUDA',\n",
    "    'dasp_cuda_nv': 'DASP_CUDA',\n",
    "\n",
    "    'cusparse_csr_nv': 'CUSPARSE_CSR',\n",
    "    'cusparse_coo_nv': 'CUSPARSE_COO',\n",
    "}\n",
    "\n",
    "def remove_formats(df, formats_to_discard):\n",
    "    for ftd in formats_to_discard:\n",
    "        df = df[df['format_name'] != ftd]\n",
    "    return df\n",
    "\n",
    "def print_formats_per_device(df):\n",
    "    print('------------------------')\n",
    "    print('Size of dataframe')\n",
    "    print(df.shape)\n",
    "    print('Tested formats')\n",
    "    print(set(df['format_name']))\n",
    "    print('Tested formats per device:')\n",
    "    for sys in set(df['System']):\n",
    "        df_sys = df[df['System'] == sys]\n",
    "        print(sys, '\\t', set(df_sys['format_name']))\n",
    "    print('------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62272316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_features(root, file):\n",
    "    file_path = os.path.join(root, file)\n",
    "    backup_file_path = file_path.replace('.csv', '_BAD_FEATURES.csv')\n",
    "    \n",
    "    if(not(os.path.isfile(backup_file_path))):\n",
    "        print('need to do sth for', backup_file_path)\n",
    "        if('friends' in file_path):\n",
    "            with open('feats_friends.csv') as f:\n",
    "                features = f.readlines()\n",
    "        if('synthetic' in file_path):\n",
    "            with open('feats_synthetic.csv') as f:\n",
    "                features = f.readlines()\n",
    "        for i in range(len(features)):\n",
    "            features[i] = features[i].strip('\\n')\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if('sell_C_s' not in file_path):\n",
    "                lines0 = lines[0]\n",
    "                lines = lines[1:]\n",
    "\n",
    "        impl  = file.replace('_'+precision+'.csv','')\n",
    "        impl2 = impl_dict[impl]\n",
    "        # print(impl, impl2)\n",
    "        filtered_lines = []\n",
    "        if('sell_C_s' not in file_path):\n",
    "            filtered_lines.append(lines0)\n",
    "        if(len(features) == len(lines)):\n",
    "            for i,j in zip(features, lines):\n",
    "                j_stripped = j.split(','+impl2)[1]\n",
    "                new_line = i.strip('\\n') + ',' + impl2 + j_stripped\n",
    "                filtered_lines.append(new_line)\n",
    "        else:\n",
    "            # print(file_path, '\\t', 'len(features)', len(features), '\\t', 'len(lines)', len(lines))\n",
    "            cnt = 0\n",
    "            for j in lines:\n",
    "                j_spl = j.split(',')\n",
    "                j_spl_new = ','.join(j_spl[0:5])\n",
    "\n",
    "                i = features[cnt]\n",
    "                i_spl = i.split(',')\n",
    "                i_spl_new = ','.join(i_spl[0:5])\n",
    "\n",
    "                while(i_spl_new != j_spl_new):\n",
    "                    cnt+=1\n",
    "                    i = features[cnt]\n",
    "                    i_spl = i.split(',')\n",
    "                    i_spl_new = ','.join(i_spl[0:5])\n",
    "\n",
    "                if(i_spl_new == j_spl_new):\n",
    "                    j_stripped = j.split(','+impl2)[1]\n",
    "                    new_line = i.strip('\\n') + ',' + impl2 + j_stripped\n",
    "                    filtered_lines.append(new_line)\n",
    "                cnt+=1\n",
    "                # print(j, cnt)\n",
    "\n",
    "        # Backup the original file\n",
    "        backup_file_path = file_path.replace('.csv', '_BAD_FEATURES.csv')\n",
    "        os.rename(file_path, backup_file_path)\n",
    "        # Write the filtered content back to the original file path\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(filtered_lines)\n",
    "        # print(f'Original file backed up as: {backup_file_path}')\n",
    "        # print(f'Filtered file saved as: {file_path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77521323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_synthetic_csv_errors(file_path, flag=0):\n",
    "    # Read the entire file to count lines and occurrences of 'synthetic'\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Count lines excluding the header\n",
    "    # flag=1 (sell-C-σ) does not have a header, flag=0 (all others) does have a header\n",
    "    if(flag==0):\n",
    "        num_lines = len(lines) - 1\n",
    "    else:\n",
    "        num_lines = len(lines)\n",
    "\n",
    "    # Count occurrences of the word 'synthetic'\n",
    "    count_synthetic = sum(line.lower().count('synthetic') for line in lines)\n",
    "\n",
    "    # Check if counts differ\n",
    "    if num_lines != count_synthetic:\n",
    "        # Print counts\n",
    "        print(f'Number of lines (excluding header): {num_lines}')\n",
    "        print(f'Occurrences of \"synthetic\"        : {count_synthetic}')\n",
    "        print(f'Difference in line count and \"synthetic\" occurrences for file: {file_path}\\n')\n",
    "\n",
    "        # Backup the original file\n",
    "        backup_file_path = file_path.replace('.csv', '_BAD.csv')\n",
    "        os.rename(file_path, backup_file_path)\n",
    "        print(f'Original file backed up as: {backup_file_path}')\n",
    "\n",
    "        # Filter out lines that do not contain 'synthetic'\n",
    "        if(flag==0):\n",
    "            filtered_lines = [lines[0]] + [line for line in lines[1:] if 'synthetic' in line.lower()]\n",
    "        else:\n",
    "            filtered_lines = [line for line in lines if 'synthetic' in line.lower()]\n",
    "\n",
    "        # Write the filtered content back to the original file path\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(filtered_lines)\n",
    "        print(f'Filtered file saved as: {file_path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_synthetic(root, file):\n",
    "    file_path = os.path.join(root, file)\n",
    "    # print(f'File: {file_path}')\n",
    "    try:\n",
    "        if ('sell_C_s_d' in file):\n",
    "            fix_synthetic_csv_errors(file_path, 1) # 1 for flag\n",
    "            # We need to do the following because SELL-C-σ runs on different from other matrices benchmark.\n",
    "            # This way, we make sure that when merging all results according to matrix features, \n",
    "            # all different features will be considered \n",
    "            fix_features(root, file)\n",
    "            SELL_C_S_D_HEADER = header_names[:-2]            \n",
    "            df = pd.read_csv(file_path, names=SELL_C_S_D_HEADER, header=0)\n",
    "        else:\n",
    "            fix_synthetic_csv_errors(file_path)\n",
    "            fix_features(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f'1) Error reading {file_path}: {e}\\n')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2dc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_device_data_old(directory, System, Arch, header_names, synthetic_flag, threads = 0):\n",
    "    if(synthetic_flag==1):\n",
    "        if(Arch == 'CPU'):\n",
    "            # it is CPU data that we want to read, have to append number of threads too\n",
    "            df = pd.read_csv('../benchmark_results/' + directory + '/' + directory + '_synthetic_t%d_%s.csv' % (threads, precision), names = header_names)\n",
    "        else: \n",
    "            # it is GPU or FPGA data that we want to read\n",
    "            # df = pd.read_csv('../benchmark_results/' + directory + '/' + directory + '_synthetic_%s.csv' % (precision), names = header_names)\n",
    "            df = pd.read_csv('../benchmark_results/'+ directory + '/' + directory + '_dtype-D_run_full_dataset.csv', names = header_names)\n",
    "    else:\n",
    "        if(Arch == 'GPU'):\n",
    "            df = pd.read_csv('../benchmark_results/' + directory + '/' + directory + '_dtype-D_run_friend_dataset.csv', names = header_names)\n",
    "        elif(Arch == 'CPU'):\n",
    "            df = pd.read_csv('../benchmark_results/' + directory + '/' + directory + '_friends_10_samples_30_range_t%d_%s.csv' % (threads, precision), names = header_names)\n",
    "\n",
    "    df['System'] = System\n",
    "    print('Finished reading ', System)\n",
    "    return df\n",
    "\n",
    "def find_csv_files(directory, system_name, synthetic_flag):\n",
    "    if(synthetic_flag == 1):\n",
    "        keyword = 'synthetic'\n",
    "    else:\n",
    "        keyword = 'friends'\n",
    "    df_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if ('DELETE' not in root) and ('rep' in root) and ('BAD' not in file):\n",
    "                if file.endswith('.csv'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    if (keyword in root):\n",
    "                        # print(root,file)\n",
    "                        curr_df = read_synthetic(root, file)\n",
    "                        df_list.append(curr_df)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    df['System'] = system_name\n",
    "    print('Finished reading ', system_name)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6499d6",
   "metadata": {},
   "source": [
    "---\n",
    "# Read GPU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671b6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gpu_data(header_names, synthetic_flag):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    inputdata_GPU_P100 = read_device_data_old('vulcan-P100', 'NVIDIA-P100', 'GPU', header_names, synthetic_flag)\n",
    "    inputdata_GPU_V100 = read_device_data_old('vulcan-V100', 'NVIDIA-V100', 'GPU', header_names, synthetic_flag)\n",
    "    inputdata_GPU_A100 = read_device_data_old('epyc5-A100', 'NVIDIA-A100', 'GPU', header_names, synthetic_flag)\n",
    "    # perhaps it will be needed\n",
    "    inputdata_GPU_A100 = inputdata_GPU_A100[inputdata_GPU_A100['gflops']<800] # panastaaaaaaas (some Merge shit is going on here...)\n",
    "    \n",
    "    inputdata_GPU_H100  = find_csv_files(prefix + 'grace1-H100', 'NVIDIA-H100', synthetic_flag)\n",
    "    inputdata_GPU_MI250 = find_csv_files(prefix + 'amd-mi250', 'AMD-MI250', synthetic_flag)\n",
    "    # Only for 'friends' dataset this has to be applied..\n",
    "    if(synthetic_flag == 0):    \n",
    "        inputdata_GPU_MI250 = inputdata_GPU_MI250[inputdata_GPU_MI250['gflops'] < 250]\n",
    "\n",
    "    inputdata_GPU = pd.concat([inputdata_GPU_P100, inputdata_GPU_V100, inputdata_GPU_A100, inputdata_GPU_H100, inputdata_GPU_MI250])\n",
    "    inputdata_GPU['Arch'] = 'GPU'\n",
    "\n",
    "    formats_to_discard = []\n",
    "    inputdata_GPU = remove_formats(inputdata_GPU, formats_to_discard)\n",
    "\n",
    "    print_formats_per_device(inputdata_GPU)\n",
    "    \n",
    "    # inputdata_GPU = inputdata_GPU.round({'nz': -1, 'mem_footprint': 3, 'density': 3,\n",
    "    #              'avg_nnz_row': 3, 'std_nnz_row': 3,\n",
    "    #              'avg_bandwidth': -1, 'std_bandwidth': -1, 'avg_bandwidth_scaled': 2, 'std_bandwidth_scaled': 2,\n",
    "    #              'avg_scattering': 2, 'std_scattering': 2, 'avg_scattering_scaled': -1, 'std_scattering_scaled': -1,\n",
    "    #              'skew_coeff': 1,\n",
    "    #              'avg_num_neighbours' : 3, 'cross_row_similarity': 3})\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in read_gpu_data: {elapsed_time:.2f} seconds\\n')\n",
    "    return inputdata_GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f664164",
   "metadata": {},
   "source": [
    "---\n",
    "# Read CPU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bd312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cpu_data(header_names, synthetic_flag):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    Hawk_threads     = 64\n",
    "    Epyc_threads     = 24\n",
    "    Xeon_threads     = 14\n",
    "    Icy_threads      = 16\n",
    "    Sapphire_threads = 56\n",
    "    Arm_threads      = 80\n",
    "    Grace_threads    = 72\n",
    "    Power9_threads   = 32\n",
    "\n",
    "    inputdata_CPU_AMD_EPYC1       = read_device_data_old('amd-epyc1', 'AMD-EPYC-24', 'CPU', header_names, synthetic_flag, threads = Epyc_threads)\n",
    "    inputdata_CPU_AMD_EPYC_64     = find_csv_files(prefix + 'amd-epyc7763', 'AMD-EPYC-64', synthetic_flag)\n",
    "\n",
    "    inputdata_CPU_INTEL_GOLD2     = read_device_data_old('intel-gold2', 'INTEL-XEON-14', 'CPU', header_names, synthetic_flag, threads = Xeon_threads)\n",
    "    inputdata_CPU_INTEL_ICY3      = read_device_data_old('intel-icy3', 'INTEL-ICY-16', 'CPU', header_names, synthetic_flag, threads = Icy_threads)\n",
    "    inputdata_CPU_INTEL_SAPPHIRE  = find_csv_files(prefix + 'intel-sapphire', 'INTEL-SAPPHIRE-56', synthetic_flag)\n",
    "    # only for this, please discard AMD AOCL format for Intel CPU!\n",
    "    inputdata_CPU_INTEL_SAPPHIRE  = inputdata_CPU_INTEL_SAPPHIRE[inputdata_CPU_INTEL_SAPPHIRE['format_name']!='AOCL_OPTMV']\n",
    "    inputdata_CPU_ARM_NEON        = read_device_data_old('arm', 'ARM-NEON-80',    'CPU', header_names, synthetic_flag, threads = Arm_threads)\n",
    "    inputdata_CPU_ARM_GRACE       = find_csv_files(prefix + 'grace1-arm', 'ARM-GRACE-72', synthetic_flag)\n",
    "\n",
    "    inputdata_CPU_IBM_POWER9      = read_device_data_old('power9-m100', 'IBM-POWER9-32', 'CPU', header_names, synthetic_flag, threads = Power9_threads)\n",
    "\n",
    "    # fix some things...\n",
    "    inputdata_CPU_AMD_EPYC1.astype({'avg_bw': 'float64'})\n",
    "    inputdata_CPU_IBM_POWER9['W_avg'] = 200.1 # We could not measure power consumption from IBM Power9\n",
    "\n",
    "    inputdata_CPU = pd.concat([inputdata_CPU_AMD_EPYC_64, inputdata_CPU_AMD_EPYC1,\n",
    "                               inputdata_CPU_INTEL_GOLD2, inputdata_CPU_INTEL_ICY3, inputdata_CPU_INTEL_SAPPHIRE,\n",
    "                               inputdata_CPU_ARM_NEON, inputdata_CPU_ARM_GRACE,\n",
    "                               inputdata_CPU_IBM_POWER9])\n",
    "    inputdata_CPU['Arch'] = 'CPU'\n",
    "\n",
    "    # formats to discard here!\n",
    "    formats_to_discard = ['Custom_CSR_PBV_x86', 'Custom_CSR_PBV']\n",
    "    inputdata_CPU = remove_formats(inputdata_CPU, formats_to_discard)\n",
    "\n",
    "    print_formats_per_device(inputdata_CPU)\n",
    "\n",
    "    # inputdata_CPU = inputdata_CPU.round({'nr_nzeros': -1, 'mem_footprint': 3, 'density': 3,\n",
    "    #              'avg_nnz_row': 3, 'std_nnz_row': 3,\n",
    "    #              'avg_bw': -1, 'std_bw': -1, 'avg_bw_scaled': 2, 'std_bw_scaled': 2,\n",
    "    #              'avg_sc': 2, 'std_sc': 2, 'avg_sc_scaled': -1, 'std_sc_scaled': -1,\n",
    "    #              'skew': 1,\n",
    "    #              'avg_num_neighbours' : 3, 'cross_row_similarity': 3})\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in read_cpu_data: {elapsed_time:.2f} seconds\\n')\n",
    "    return inputdata_CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77872a4a",
   "metadata": {},
   "source": [
    "---\n",
    "# Read FPGA data (skip this for now...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a976852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fpga_data(header_names, synthetic_flag):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Will use this when data from FPGA regarding Vitis Library have been cleaned up\n",
    "    # inputdata_FPGA_ALVEO_U280 = read_device_data('alveo-u280', 'Alveo-U280', 'FPGA')\n",
    "    if(synthetic_flag==1):\n",
    "        inputdata_FPGA_ALVEO_U280 = pd.read_csv('../benchmark_results/alveo-u280/PADDED-alveo-u280_spmv_4-2048_dtype-D.csv', names = header_names)\n",
    "    else:\n",
    "        fname = 'alveo-u280_spmv_validation_matrices_10_samples_30_range_twins_dtype-D.csv'\n",
    "        inputtdata_FPGA = pd.read_csv('../benchmark_results/alveo-u280/%s' % fname, names = header_names)\n",
    "    inputdata_FPGA_ALVEO_U280['System'] = 'Alveo-U280'\n",
    "\n",
    "    inputdata_FPGA = pd.concat([inputdata_FPGA_ALVEO_U280])\n",
    "    inputdata_FPGA['Arch'] = 'FPGA'\n",
    "    print_formats_per_device(inputdata_FPGA)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in read_fpga_data: {elapsed_time:.2f} seconds\\n')\n",
    "    return inputdata_FPGA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2a097",
   "metadata": {},
   "source": [
    "---\n",
    "# Concatenate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efacccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_inputdata(inputdata_GPU, inputdata_CPU, inputdata_FPGA = []):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Merge the results\n",
    "    # inputdata = pd.concat([inputdata_GPU,inputdata_CPU,inputdata_FPGA])\n",
    "    inputdata = pd.concat([inputdata_GPU,inputdata_CPU])\n",
    "    print('Concatenated data of all devices:', inputdata.shape)\n",
    "\n",
    "    # Keep mean of benchmarks, store in 'groupreps', take mean\n",
    "    # groupreps = inputdata.groupby(['matrix_name','distribution','placement','seed',\n",
    "    #                                'nr_rows','nr_cols','nr_nzeros','density','mem_footprint','mem_range',\n",
    "    #                                'avg_nnz_per_row','std_nnz_per_row',\n",
    "    #                                'avg_bw','std_bw','avg_bw_scaled','std_bw_scaled',\n",
    "    #                                'avg_sc','std_sc','avg_sc_scaled','std_sc_scaled',\n",
    "    #                                'skew','avg_num_neighbours','cross_row_similarity',\n",
    "    #                                'format_name','System', 'Arch']).mean().reset_index().reindex(columns=header_names)\n",
    "\n",
    "    # These 4 columns are the ones that we want the new dataframe to be averaged (different measurements collected for the same matrix)\n",
    "    group_by_header = [x for x in header_names if x not in  ['time','gflops','W_avg','J_estimated']]\n",
    "    groupreps = inputdata.groupby(group_by_header, observed = True).mean().reset_index().reindex(columns=header_names)\n",
    "    print('Concatenated data of all devices (average):', groupreps.shape)\n",
    "    \n",
    "    # Rename formats to human-readable form...\n",
    "    format_name_mapping = {\n",
    "        'cuSPARSE_csr11': 'cu-CSR',\n",
    "        'cuSPARSE_coo11': 'cu-COO',\n",
    "        'cuSPARSE_hyb9-2': 'cu-HYB',\n",
    "        'CUSPARSE_CSR': 'cu-CSR',\n",
    "        'CUSPARSE_COO': 'cu-COO',\n",
    "\n",
    "        'ROCSPARSE_CSR': 'roc-CSR',\n",
    "        'ROCSPARSE_COO': 'roc-COO',\n",
    "        'ROCSPARSE_HYB': 'roc-HYB',\n",
    "\n",
    "        'Merge_11': 'Merge-CSR',\n",
    "        'MERGE_CUDA': 'Merge-CSR',\n",
    "        'MERGE': 'Merge-CSR',\n",
    "\n",
    "        'Custom_CSR_CUDA_ADAPTIVE_b512_1': 'Ada-CSR',\n",
    "        'Custom_CSR_CUDA_ADAPTIVE_b256_1': 'Ada-CSR',\n",
    "        'Custom_CSR_ROCM_ADAPTIVE_b512_1': 'Ada-CSR',\n",
    "\n",
    "        # 'Custom_CSR_CUDA_VECTOR_b512': 'Vec-CSR',\n",
    "        'Custom_CSR_CUDA_VECTOR_b256': 'Vec-CSR',\n",
    "        'Custom_CSR_ROCM_VECTOR_b512': 'Vec-CSR',\n",
    "\n",
    "        'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4': 'Custom-CSR',\n",
    "        'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4': 'Custom-CSR',\n",
    "\n",
    "        'ACC_LINE_ENHANCE_b512': 'ACC-Line',\n",
    "        'ACC_FLAT_b512': 'ACC-Flat',\n",
    "\n",
    "        'SELL-32-1': 'SELL-C-σ',\n",
    "        # 'SELL-32-512': 'SELL-C-σ',\n",
    "\n",
    "        'Naive_CSR_CPU': 'Naive-CSR',\n",
    "        'Custom_CSR_B': 'Bal-CSR',\n",
    "        'Custom_CSR_BV_x86': 'Vec-CSR',\n",
    "        'Custom_CSR_BV_SVE': 'Vec-CSR',\n",
    "\n",
    "        'MKL_IE': 'MKL-IE',\n",
    "        'AOCL_OPTMV': 'AOCL',\n",
    "        'ARMPL': 'ARM-lib',\n",
    "\n",
    "        'SparseX': 'SparseX',\n",
    "        'CSR5_9': 'CSR5',\n",
    "        'CSR5_CUDA': 'CSR5',\n",
    "        'CSR5': 'CSR5',\n",
    "        'DASP_CUDA': 'DASP',\n",
    "        'LCM': 'LCM',\n",
    "    }\n",
    "    groupreps['format_name'] = groupreps['format_name'].replace(format_name_mapping)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in concatenate_inputdata: {elapsed_time:.2f} seconds\\n')\n",
    "    return groupreps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76ebc2",
   "metadata": {},
   "source": [
    "---\n",
    "# Group by \"best-of\" format_name for each device\n",
    "# Skip this step if you want to plot every measurement collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc430e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_best_of(groupreps, header_names):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Group per system, take best (it was over 'inputdata', but 'groupreps' is better choice I think)\n",
    "    # fixed this after reordering groupreps columns according to header_names\n",
    "    # before this, columns and data were mixed and it was a complete shitstorm\n",
    "    # group_system = groupreps.groupby(['matrix_name','distribution','placement','seed',\n",
    "    #                                   'nr_rows','nr_cols','nr_nzeros','density','mem_footprint','mem_range',\n",
    "    #                                   'avg_nnz_per_row','std_nnz_per_row',\n",
    "    #                                   'avg_bw','std_bw','avg_bw_scaled','std_bw_scaled',\n",
    "    #                                   'avg_sc','std_sc','avg_sc_scaled','std_sc_scaled',\n",
    "    #                                   'skew','avg_num_neighbours','cross_row_similarity',\n",
    "    #                                   'System','Arch'], as_index = False)\n",
    "    group_by_header = [x for x in header_names if x not in  ['format_name', 'time','gflops','W_avg','J_estimated']]\n",
    "    group_system = groupreps.groupby(group_by_header, as_index = False, observed = True)\n",
    "\n",
    "    reslist = []\n",
    "    for desc, experiment in group_system:\n",
    "        best_format = experiment['format_name'].iloc[experiment['gflops'].argmax()]\n",
    "        outrow = experiment[experiment['format_name'] == best_format]\n",
    "        # if(len(outrow)>1):\n",
    "        #     print(len(outrow), outrow)\n",
    "        reslist.append(outrow.values.tolist()[0])             \n",
    "\n",
    "    group_system_best = pd.DataFrame(reslist, columns = header_names)\n",
    "    print('Concatenated data of all devices (best performing format for each matrix):', group_system_best.shape)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in group_by_best_of: {elapsed_time:.2f} seconds\\n')\n",
    "    return group_system_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c15f1c",
   "metadata": {},
   "source": [
    "# Also try the group by \"top-K\" format_names approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4633e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_topK_best(groupreps, header_names, k=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Group per system, take best (it was over 'inputdata', but 'groupreps' is better choice I think)\n",
    "    # fixed this after reordering groupreps columns according to header_names\n",
    "    # before this, columns and data were mixed and it was a complete shitstorm\n",
    "    # group_system = groupreps.groupby(['matrix_name','distribution','placement','seed',\n",
    "    #                                   'nr_rows','nr_cols','nr_nzeros','density','mem_footprint','mem_range',\n",
    "    #                                   'avg_nnz_per_row','std_nnz_per_row',\n",
    "    #                                   'avg_bw','std_bw','avg_bw_scaled','std_bw_scaled',\n",
    "    #                                   'avg_sc','std_sc','avg_sc_scaled','std_sc_scaled',\n",
    "    #                                   'skew','avg_num_neighbours','cross_row_similarity',\n",
    "    #                                   'System','Arch'], as_index = False)\n",
    "    group_by_header = [x for x in header_names if x not in  ['format_name', 'time','gflops','W_avg','J_estimated']]\n",
    "    group_system = groupreps.groupby(group_by_header, as_index = False, observed = True)\n",
    "\n",
    "    reslist = []\n",
    "    for desc, experiment in group_system:\n",
    "        # best_format = experiment['format_name'].iloc[experiment['gflops'].argmax()]\n",
    "        # outrow = experiment[experiment['format_name'] == best_format]\n",
    "        # reslist.append(outrow.values.tolist()[0])\n",
    "        topK_formats = experiment.nlargest(k, 'gflops')\n",
    "        reslist.append(topK_formats)\n",
    "\n",
    "    group_system_best = pd.concat(reslist).reset_index(drop=True)\n",
    "    print('Concatenated data of all devices (Top', k, 'performing format for each matrix):', group_system_best.shape)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in group_by_best_of: {elapsed_time:.2f} seconds\\n')\n",
    "    return group_system_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad38db",
   "metadata": {},
   "source": [
    "---\n",
    "# Add some extra columns to dataframes \"groupreps\" and \"group_system_best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c10c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_columns(df, ranges_crs, ranges_ann, ranges_size, ranges_anr, ranges_skew):\n",
    "    df = df[df['W_avg']>=0]\n",
    "\n",
    "    # this has to be to discard some anomalies from AMD-HAWK measurements\n",
    "    # df1 = df[df['System'] != 'AMD-EPYC-64']\n",
    "    # df2 = df[df['System'] == 'AMD-EPYC-64'] \n",
    "    # df2 = df2[df2['W_avg']>30]\n",
    "    # df = pd.concat([df1, df2])\n",
    "    # df = df[df['W_avg']>32.9]\n",
    "\n",
    "    df['impl_arch'] = '( ' + df['System'] + ' ' ')\\t' + df['format_name']\n",
    "    df['energy_efficiency'] = df['gflops'] / df['W_avg'] \n",
    "    df['GFLOPs^2-per-W'] = df['gflops'] * df['gflops'] / df['W_avg']\n",
    "\n",
    "    df['crs_categ'] = df.apply(lambda row: set_category(row['cross_row_similarity'], ranges_crs, ranges_size, ranges_size_flag=True), axis=1)\n",
    "    df['ann_categ'] = df.apply(lambda row: set_category(row['avg_num_neighbours'], ranges_ann, ranges_size, ranges_size_flag=True), axis=1)\n",
    "    df['regularity'] = df['crs_categ'] + df['ann_categ']\n",
    "\n",
    "    df['anr_categ'] = df.apply(lambda row: set_category(row['avg_nnz_per_row'], ranges_anr, [], ranges_size_flag=False), axis=1)\n",
    "    df['skew_categ'] = df.apply(lambda row: set_category(row['skew'], ranges_skew, [], ranges_size_flag=False), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def insert_new_info(groupreps, group_system_best):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    groupreps = add_extra_columns(groupreps, ranges_crs, ranges_ann, ranges_size, ranges_anr, ranges_skew)\n",
    "    group_system_best = add_extra_columns(group_system_best, ranges_crs, ranges_ann, ranges_size, ranges_anr, ranges_skew)\n",
    "\n",
    "    # this will be used sometime in the future...\n",
    "    extra_header_names = ['impl_arch', 'energy_efficiency', 'GFLOPs^2-per-W', \n",
    "                          'crs_categ', 'ann_categ', 'regularity', 'anr_categ', 'skew_categ']\n",
    "    groupreps = groupreps.replace([np.inf, -np.inf], np.nan)\n",
    "    group_system_best = group_system_best.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time spent in insert_new_info: {elapsed_time:.2f} seconds\\n')\n",
    "    return groupreps, group_system_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a6e36",
   "metadata": {},
   "source": [
    "# Read benchmarks regarding synthetic matrices (15K matrix dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b498ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading  NVIDIA-P100\n",
      "Finished reading  NVIDIA-V100\n",
      "Finished reading  NVIDIA-A100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151402/2480784182.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading  NVIDIA-H100\n",
      "Finished reading  AMD-MI250\n",
      "------------------------\n",
      "Size of dataframe\n",
      "(1283609, 30)\n",
      "Tested formats\n",
      "{'cuSPARSE_csr11', 'cuSPARSE_coo11', 'CSR5_CUDA', 'Custom_CSR_CUDA_ADAPTIVE_b512_1', 'ACC_FLAT_b512', 'Custom_CSR_CUDA_VECTOR_b256', 'CUSPARSE_COO', 'CUSPARSE_CSR', 'ROCSPARSE_COO', 'ROCSPARSE_CSR', 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4', 'Custom_CSR_CUDA_ADAPTIVE_b256_1', 'Custom_CSR_ROCM_VECTOR_b512', 'cuSPARSE_hyb9-2', 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4', 'DASP_CUDA', 'MERGE_CUDA', 'SELL-32-1', 'ACC_LINE_ENHANCE_b512', 'ROCSPARSE_HYB', 'CSR5_9', 'Merge_11'}\n",
      "Tested formats per device:\n",
      "AMD-MI250 \t {'ACC_LINE_ENHANCE_b512', 'ROCSPARSE_COO', 'ROCSPARSE_CSR', 'ROCSPARSE_HYB', 'Custom_CSR_CUDA_ADAPTIVE_b512_1', 'Custom_CSR_ROCM_VECTOR_b512', 'ACC_FLAT_b512', 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4'}\n",
      "NVIDIA-P100 \t {'CSR5_9', 'cuSPARSE_hyb9-2', 'cuSPARSE_csr11', 'cuSPARSE_coo11'}\n",
      "NVIDIA-A100 \t {'SELL-32-1', 'cuSPARSE_csr11', 'cuSPARSE_coo11', 'Merge_11'}\n",
      "NVIDIA-H100 \t {'CUSPARSE_CSR', 'DASP_CUDA', 'CSR5_CUDA', 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4', 'Custom_CSR_CUDA_ADAPTIVE_b256_1', 'MERGE_CUDA', 'Custom_CSR_CUDA_VECTOR_b256', 'CUSPARSE_COO'}\n",
      "NVIDIA-V100 \t {'CSR5_9', 'cuSPARSE_hyb9-2', 'cuSPARSE_csr11', 'cuSPARSE_coo11'}\n",
      "------------------------\n",
      "Time spent in read_gpu_data: 4.21 seconds\n",
      "\n",
      "Finished reading  AMD-EPYC-24\n",
      "Finished reading  AMD-EPYC-64\n",
      "Finished reading  INTEL-XEON-14\n",
      "Finished reading  INTEL-ICY-16\n",
      "Finished reading  INTEL-SAPPHIRE-56\n",
      "Finished reading  ARM-NEON-80\n",
      "Finished reading  ARM-GRACE-72\n",
      "Finished reading  IBM-POWER9-32\n",
      "------------------------\n",
      "Size of dataframe\n",
      "(3410904, 30)\n",
      "Tested formats\n",
      "{'CSR5', 'SELL-32-1', 'ARMPL', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'Custom_CSR_BV', 'Custom_CSR_BV_SVE', 'LCM', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "Tested formats per device:\n",
      "ARM-GRACE-72 \t {'ARMPL', 'Naive_CSR_CPU', 'Custom_CSR_B', 'Custom_CSR_BV_SVE', 'MERGE', 'SparseX'}\n",
      "IBM-POWER9-32 \t {'Naive_CSR_CPU', 'Custom_CSR_B', 'MERGE', 'SparseX', 'Custom_CSR_BV'}\n",
      "INTEL-XEON-14 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Naive_CSR_CPU', 'MKL_IE', 'MERGE', 'SparseX'}\n",
      "INTEL-SAPPHIRE-56 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'LCM', 'MERGE', 'SparseX'}\n",
      "AMD-EPYC-24 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Naive_CSR_CPU', 'MKL_IE', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "INTEL-ICY-16 \t {'CSR5', 'SELL-32-1', 'Naive_CSR_CPU', 'MKL_IE', 'MERGE', 'SparseX', 'Custom_CSR_BV'}\n",
      "AMD-EPYC-64 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'LCM', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "ARM-NEON-80 \t {'SELL-32-1', 'ARMPL', 'Naive_CSR_CPU', 'MERGE', 'SparseX'}\n",
      "------------------------\n",
      "Time spent in read_cpu_data: 13.00 seconds\n",
      "\n",
      "Concatenated data of all devices: (4694513, 30)\n",
      "Concatenated data of all devices (average): (1252763, 30)\n",
      "Time spent in concatenate_inputdata: 7.25 seconds\n",
      "\n",
      "Concatenated data of all devices (best performing format for each matrix): (190519, 30)\n",
      "Time spent in group_by_best_of: 94.04 seconds\n",
      "\n",
      "Time spent in insert_new_info: 33.75 seconds\n",
      "\n",
      "CPU times: user 2min 44s, sys: 9.29 s, total: 2min 53s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "synthetic_flag = 1\n",
    "# inputdata_FPGA = read_fpga_data(header_names, synthetic_flag)\n",
    "inputdata_GPU = read_gpu_data(header_names, synthetic_flag)\n",
    "inputdata_CPU = read_cpu_data(header_names, synthetic_flag)\n",
    "\n",
    "# Concatenate all data\n",
    "groupreps = concatenate_inputdata(inputdata_GPU, inputdata_CPU)\n",
    "\n",
    "# Group by 'best-of' format_name for each device\n",
    "group_system_best = group_by_best_of(groupreps, header_names)\n",
    "\n",
    "# Add some extra columns to dataframes 'groupreps' and 'group_system_best'\n",
    "groupreps, group_system_best = insert_new_info(groupreps, group_system_best)\n",
    "\n",
    "# Store in 2 csv files. 1 for 'all' benchmarks, 1 for 'best-of' benchmarks\n",
    "groupreps.to_csv('synthetic_benchmarks_all-devices_all.csv', sep=',', header=True, index=False)\n",
    "group_system_best.to_csv('synthetic_benchmarks_all-devices_best-of.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb5ea6",
   "metadata": {},
   "source": [
    "# Read benchmarks regarding validation-friends matrices (3K matrix dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3462be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading  NVIDIA-P100\n",
      "Finished reading  NVIDIA-V100\n",
      "Finished reading  NVIDIA-A100\n",
      "Finished reading  NVIDIA-H100\n",
      "Finished reading  AMD-MI250\n",
      "------------------------\n",
      "Size of dataframe\n",
      "(337309, 30)\n",
      "Tested formats\n",
      "{'cuSPARSE_csr11', 'cuSPARSE_coo11', 'CSR5_CUDA', 'Custom_CSR_CUDA_ADAPTIVE_b512_1', 'ACC_FLAT_b512', 'Custom_CSR_CUDA_VECTOR_b256', 'CUSPARSE_COO', 'CUSPARSE_CSR', 'ROCSPARSE_COO', 'ROCSPARSE_CSR', 'Custom_CSR_CUDA_ADAPTIVE_b256_1', 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4', 'Custom_CSR_ROCM_VECTOR_b512', 'cuSPARSE_hyb9-2', 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4', 'DASP_CUDA', 'MERGE_CUDA', 'SELL-32-1', 'ACC_LINE_ENHANCE_b512', 'ROCSPARSE_HYB', 'CSR5_9', 'Merge_11'}\n",
      "Tested formats per device:\n",
      "AMD-MI250 \t {'ACC_LINE_ENHANCE_b512', 'ROCSPARSE_COO', 'ROCSPARSE_CSR', 'ROCSPARSE_HYB', 'Custom_CSR_CUDA_ADAPTIVE_b512_1', 'Custom_CSR_ROCM_VECTOR_b512', 'ACC_FLAT_b512', 'Custom_CSR_ROCM_constant_nnz_per_thread_b512_nnz4'}\n",
      "NVIDIA-P100 \t {'CSR5_9', 'cuSPARSE_hyb9-2', 'cuSPARSE_csr11', 'cuSPARSE_coo11'}\n",
      "NVIDIA-A100 \t {'SELL-32-1', 'cuSPARSE_csr11', 'cuSPARSE_coo11', 'Merge_11'}\n",
      "NVIDIA-H100 \t {'CUSPARSE_CSR', 'DASP_CUDA', 'CSR5_CUDA', 'Custom_CSR_CUDA_constant_nnz_per_thread_b1024_nnz4', 'Custom_CSR_CUDA_ADAPTIVE_b256_1', 'MERGE_CUDA', 'Custom_CSR_CUDA_VECTOR_b256', 'CUSPARSE_COO'}\n",
      "NVIDIA-V100 \t {'cuSPARSE_csr11', 'cuSPARSE_coo11', 'CSR5_9', 'Merge_11', 'cuSPARSE_hyb9-2'}\n",
      "------------------------\n",
      "Time spent in read_gpu_data: 0.98 seconds\n",
      "\n",
      "Finished reading  AMD-EPYC-24\n",
      "Finished reading  AMD-EPYC-64\n",
      "Finished reading  INTEL-XEON-14\n",
      "Finished reading  INTEL-ICY-16\n",
      "Finished reading  INTEL-SAPPHIRE-56\n",
      "Finished reading  ARM-NEON-80\n",
      "Finished reading  ARM-GRACE-72\n",
      "Finished reading  IBM-POWER9-32\n",
      "------------------------\n",
      "Size of dataframe\n",
      "(810332, 33)\n",
      "Tested formats\n",
      "{'CSR5', 'SELL-32-1', 'ARMPL', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'Custom_CSR_BV', 'Custom_CSR_BV_SVE', 'LCM', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "Tested formats per device:\n",
      "ARM-GRACE-72 \t {'ARMPL', 'Naive_CSR_CPU', 'Custom_CSR_B', 'Custom_CSR_BV_SVE', 'MERGE', 'SparseX'}\n",
      "IBM-POWER9-32 \t {'Naive_CSR_CPU', 'Custom_CSR_B', 'MERGE', 'SparseX', 'Custom_CSR_BV'}\n",
      "INTEL-XEON-14 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Naive_CSR_CPU', 'MKL_IE', 'MERGE', 'SparseX'}\n",
      "INTEL-SAPPHIRE-56 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'LCM', 'MERGE', 'SparseX'}\n",
      "AMD-EPYC-24 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Naive_CSR_CPU', 'MKL_IE', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "INTEL-ICY-16 \t {'CSR5', 'SELL-32-1', 'Naive_CSR_CPU', 'MKL_IE', 'MERGE', 'SparseX', 'Custom_CSR_BV'}\n",
      "AMD-EPYC-64 \t {'CSR5', 'SELL-32-1', 'Custom_CSR_BV_x86', 'Custom_CSR_B', 'MKL_IE', 'Naive_CSR_CPU', 'LCM', 'AOCL_OPTMV', 'SparseX', 'MERGE'}\n",
      "ARM-NEON-80 \t {'SELL-32-1', 'ARMPL', 'Naive_CSR_CPU', 'MERGE', 'SparseX'}\n",
      "------------------------\n",
      "Time spent in read_cpu_data: 2.66 seconds\n",
      "\n",
      "Concatenated data of all devices: (1147641, 33)\n",
      "Concatenated data of all devices (average): (268041, 30)\n",
      "Time spent in concatenate_inputdata: 39.09 seconds\n",
      "\n",
      "Concatenated data of all devices (best performing format for each matrix): (41824, 30)\n",
      "Time spent in group_by_best_of: 18.94 seconds\n",
      "\n",
      "CPU times: user 1min 5s, sys: 373 ms, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "synthetic_flag = 0\n",
    "# inputdata_FPGA = read_fpga_data(header_names, synthetic_flag)\n",
    "inputdata_GPU = read_gpu_data(header_names, synthetic_flag)\n",
    "inputdata_CPU = read_cpu_data(header_names, synthetic_flag)\n",
    "\n",
    "# Concatenate all data\n",
    "groupreps = concatenate_inputdata(inputdata_GPU, inputdata_CPU)\n",
    "\n",
    "# Group by 'best-of' format_name for each device\n",
    "group_system_best = group_by_best_of(groupreps, header_names)\n",
    "# group_system_top2 = group_by_topK_best(groupreps, header_names, k=2)\n",
    "# group_system_top3 = group_by_topK_best(groupreps, header_names, k=3)\n",
    "# group_system_top4 = group_by_topK_best(groupreps, header_names, k=4)\n",
    "# group_system_top5 = group_by_topK_best(groupreps, header_names, k=5)\n",
    "\n",
    "# NO NEED TO DO THIS FOR VALIDATION-FRIENDS\n",
    "# Add some extra columns to dataframes 'groupreps' and 'group_system_best'\n",
    "# groupreps, group_system_best = insert_new_info(groupreps, group_system_best)\n",
    "\n",
    "# Store in 2 csv files. 1 for 'all' benchmarks, 1 for 'best-of' benchmarks\n",
    "groupreps.to_csv('validation_friends_benchmarks_all-devices_all.csv', sep=',', header=True, index=False)\n",
    "group_system_best.to_csv('validation_friends_benchmarks_all-devices_best-of.csv', sep=',', header=True, index=False)\n",
    "# group_system_top2.to_csv('validation_friends_benchmarks_all-devices_top2.csv', sep=',', header=True, index=False)\n",
    "# group_system_top3.to_csv('validation_friends_benchmarks_all-devices_top3.csv', sep=',', header=True, index=False)\n",
    "# group_system_top4.to_csv('validation_friends_benchmarks_all-devices_top4.csv', sep=',', header=True, index=False)\n",
    "# group_system_top5.to_csv('validation_friends_benchmarks_all-devices_top5.csv', sep=',', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e45bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# synthetic_flag = 0\n",
    "# # inputdata_FPGA = read_fpga_data(header_names, synthetic_flag)\n",
    "# inputdata_GPU = read_gpu_data(header_names, synthetic_flag)\n",
    "# inputdata_GPU = inputdata_GPU[inputdata_GPU['gflops']<1000]\n",
    "# inputdata_CPU = read_cpu_data(header_names, synthetic_flag)\n",
    "\n",
    "# # Concatenate all data\n",
    "# groupreps = concatenate_inputdata(inputdata_GPU, inputdata_CPU)\n",
    "\n",
    "# # Group by 'best-of' format_name for each device\n",
    "# group_system_best = group_by_best_of(groupreps, header_names)\n",
    "\n",
    "# # NO NEED TO DO THIS FOR VALIDATION-FRIENDS\n",
    "# # Add some extra columns to dataframes 'groupreps' and 'group_system_best'\n",
    "# groupreps, group_system_best = insert_new_info(groupreps, group_system_best)\n",
    "\n",
    "# # Store in 2 csv files. 1 for 'all' benchmarks, 1 for 'best-of' benchmarks\n",
    "# groupreps.to_csv('validation_friends_benchmarks_all-devices_all2.csv', sep=',', header=True, index=False)\n",
    "# group_system_best.to_csv('validation_friends_benchmarks_all-devices_best-of2.csv', sep=',', header=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv-conda)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
