{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "#mpl.use('pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "#Red\n",
    "red1= sns.color_palette(\"Reds_d\",1)\n",
    "red2= sns.color_palette(\"Reds_d\",2)\n",
    "red3= sns.color_palette(\"Reds_d\",3)\n",
    "red4= sns.color_palette(\"Reds_d\",4)\n",
    "red5= sns.color_palette(\"Reds_d\",5)\n",
    "red6= sns.color_palette(\"Reds_d\",6)\n",
    "red7= sns.color_palette(\"Reds_d\",7)\n",
    "red8= sns.color_palette(\"Reds_d\",8)\n",
    "\n",
    "#YellowGreen\n",
    "yg1= sns.color_palette(\"YlGn_d\",1)\n",
    "yg2= sns.color_palette(\"YlGn_d\",2)\n",
    "yg3= sns.color_palette(\"YlGn_d\",3)\n",
    "yg4= sns.color_palette(\"YlGn_d\",4)\n",
    "yg5= sns.color_palette(\"YlGn_d\",5)\n",
    "yg7= sns.color_palette(\"YlGn_d\",7)\n",
    "\n",
    "#GreenBlue\n",
    "gb1= sns.color_palette(\"GnBu_d\",1)\n",
    "gb2= sns.color_palette(\"GnBu_d\",2)\n",
    "gb3= sns.color_palette(\"GnBu_d\",3)\n",
    "gb4= sns.color_palette(\"GnBu_d\",4)\n",
    "gb5= sns.color_palette(\"GnBu_d\",5)\n",
    "gb6= sns.color_palette(\"GnBu_d\",6)\n",
    "gb7= sns.color_palette(\"GnBu_d\",7)\n",
    "gb8= sns.color_palette(\"GnBu_d\",8)\n",
    "\n",
    "cp2 = list(map(lambda x: sns.desaturate(x,0.9),[red7[2],gb7[4]]))\n",
    "cp2v1 = list(map(lambda x: sns.desaturate(x,0.9),[red7[2],yg7[0]]))\n",
    "cp3 = list(map(lambda x: sns.desaturate(x,0.9),[yg7[0],gb7[4],red7[2]]))\n",
    "#cp4 = list(map(lambda x: sns.desaturate(x,0.9),red1+gb2+yg1))\n",
    "cp2_2 = list(map(lambda x: sns.desaturate(x,0.9),[red7[0],red7[3],gb7[4],gb7[6]]))\n",
    "cp_total_spectrum = list(map(lambda x: sns.desaturate(x,0.9),gb7 + yg7 + red7))\n",
    "\n",
    "#color_mine = colors(0)\n",
    "#color_cublasxt = colors(2)\n",
    "#color_ideal = colors(3)\n",
    "#color_werk = colors1(2)\n",
    "\n",
    "from pylab import cm\n",
    "colors = cm.get_cmap('PuRd',  5)\n",
    "viridis = cm.get_cmap('viridis',  4)\n",
    "magma = cm.get_cmap('magma',  8)\n",
    "cp6 = list(map(lambda x: sns.desaturate(x,0.9),[colors(2), red7[2], magma(6),  viridis(3), yg7[0], gb7[4]]))\n",
    "\n",
    "colors_dark = cm.get_cmap('Dark2',  5)\n",
    "cp5 = list(map(lambda x: sns.desaturate(x,0.9),[colors_dark(0), colors_dark(1), colors_dark(2), colors_dark(3), colors_dark(4)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(cp2)\n",
    "sns.color_palette()\n",
    "\n",
    "sns.set_palette(cp2v1)\n",
    "sns.color_palette()\n",
    "\n",
    "sns.set_palette(cp3)\n",
    "sns.color_palette()\n",
    "\n",
    "cpbasic = list(map(lambda x: sns.desaturate(x,0.9),['g','r','b','orange','grey']))\n",
    "sns.set_palette(cpbasic)\n",
    "sns.color_palette()\n",
    "\n",
    "font=10\n",
    "plt.rc('font', family='serif', serif='Times')\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rc('figure', figsize=(12,8))\n",
    "plt.rc('xtick', labelsize=font-1)\n",
    "plt.rc('ytick', labelsize=font-1)\n",
    "plt.rc('axes', labelsize=font)\n",
    "plt.rcParams.update({'axes.titlesize': font+2})\n",
    "\n",
    "#fig, axs = plt.subplots()\n",
    "#fig.subplots_adjust(left=.15, bottom=.16, right=.99, top=.97)\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.set(style=\"whitegrid\", palette=cpbasic,font_scale=0.2, rc={\"lines.linewidth\": 1})\n",
    "def harry_plotter_scatter(plot_df, plot_x_axis_list, plot_y_axis_list, select_str, plot_id, \n",
    "                      rotation = 30, adj_left = .1, adj_bottom = .2, adj_right = .99, adj_top = .88, no_sort=False, hue_hue = 'None', hue_hue_order = []):\n",
    "    for plot_x_itter in plot_x_axis_list:\n",
    "        if no_sort:\n",
    "            plot_df_sorted = plot_df\n",
    "        else:\n",
    "            dataTypeX = plot_df[plot_x_itter].dtype\n",
    "            if dataTypeX == np.float64 or dataTypeX == np.int64 or dataTypeX == float or dataTypeX == int:\n",
    "                plot_df_sorted = plot_df.sort_values(plot_x_itter)\n",
    "            elif plot_x_itter == 'mem_range':\n",
    "                if(\"FPGA\" in plot_id):\n",
    "                    cat_mem_range = CategoricalDtype([\"[4-8]\", \"[8-16]\", \"[16-32]\", \"[32-64]\", \"[64-128]\", \"[128-256]\", \"[256-512]\", \"[512-1024]\", \"[1024-2048]\"], ordered=True)\n",
    "                    plot_df_sorted = plot_df\n",
    "                    pd.options.mode.chained_assignment = None # https://stackoverflow.com/a/49729413\n",
    "                    plot_df_sorted[\"mem_range\"] = plot_df_sorted[\"mem_range\"].astype(cat_mem_range)\n",
    "                    plot_df_sorted = plot_df_sorted.sort_values('mem_range')                \n",
    "                else:\n",
    "                    plot_df_sorted = plot_df.sort_values('A_mem_footprint')\n",
    "            else:\n",
    "                print(\"Warning: X not sorted: dtype = %s\" % (dataTypeX))\n",
    "                plot_df_sorted = plot_df\n",
    "        for plot_y_itter in plot_y_axis_list:\n",
    "            fig, axs = plt.subplots()\n",
    "            if hue_hue == 'None':\n",
    "                sns_plot = sns.scatterplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, ax=axs)\n",
    "            else:\n",
    "                sns_plot = sns.scatterplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, hue=hue_hue, hue_order=hue_hue_order, ax=axs)\n",
    "                \n",
    "            if(hue_hue_order != []):               \n",
    "                # reordering the labels\n",
    "                handles, labels = plt.gca().get_legend_handles_labels()\n",
    "                order = [labels.index(i) for i in hue_hue_order]\n",
    "                plt.legend([handles[i] for i in order], [labels[i] for i in order], title = hue_hue.replace(\"_categ\",\"\"), fancybox=True)\n",
    "\n",
    "            axs.set_title('Select: %s' %(select_str))\n",
    "            fig.subplots_adjust(left=adj_left, bottom=adj_bottom, right=adj_right, top=adj_top)\n",
    "            plt.xticks(rotation=rotation)\n",
    "            select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "            fig.savefig('./Paper_plots/%s_Select-%s_x-%s_y-%s.pdf' % (plot_id, select_str_id, plot_x_itter, plot_y_itter))\n",
    "            plt.close()\n",
    "            \n",
    "def harry_plotter_box(plot_df, plot_x_axis_list, plot_y_axis_list, select_str, plot_id, \n",
    "                      rotation = 30, adj_left = .1, adj_bottom = .2, adj_right = .99, adj_top = .88, no_sort=False, hue_hue = 'None', hue_hue_order = []):\n",
    "    for plot_x_itter in plot_x_axis_list:\n",
    "        if no_sort:\n",
    "            plot_df_sorted = plot_df\n",
    "        else:\n",
    "            dataTypeX = plot_df[plot_x_itter].dtype\n",
    "            if dataTypeX == np.float64 or dataTypeX == np.int64 or dataTypeX == float or dataTypeX == int:\n",
    "                plot_df_sorted = plot_df.sort_values(plot_x_itter)\n",
    "            elif plot_x_itter == 'mem_range':\n",
    "                if(\"FPGA\" in plot_id):\n",
    "                    cat_mem_range = CategoricalDtype([\"[4-8]\", \"[8-16]\", \"[16-32]\", \"[32-64]\", \"[64-128]\", \"[128-256]\", \"[256-512]\", \"[512-1024]\", \"[1024-2048]\"], ordered=True)\n",
    "                    plot_df_sorted = plot_df\n",
    "                    pd.options.mode.chained_assignment = None # https://stackoverflow.com/a/49729413\n",
    "                    plot_df_sorted[\"mem_range\"] = plot_df_sorted[\"mem_range\"].astype(cat_mem_range)\n",
    "                    plot_df_sorted = plot_df_sorted.sort_values('mem_range')                \n",
    "                else:\n",
    "                    plot_df_sorted = plot_df.sort_values('A_mem_footprint')\n",
    "            else:\n",
    "                print(\"Warning: X not sorted: dtype = %s\" % (dataTypeX))\n",
    "                plot_df_sorted = plot_df\n",
    "        for plot_y_itter in plot_y_axis_list:\n",
    "            fig, axs = plt.subplots()\n",
    "            if hue_hue == 'None':\n",
    "                sns_plot = sns.boxplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, ax=axs)\n",
    "            else:\n",
    "                if(hue_hue_order != []):\n",
    "                    sns_plot = sns.boxplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, hue=hue_hue, hue_order=hue_hue_order, ax=axs)\n",
    "                else:\n",
    "                    sns_plot = sns.boxplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, hue=hue_hue, ax=axs)\n",
    "\n",
    "            if(hue_hue_order != []):               \n",
    "                # reordering the labels\n",
    "                handles, labels = plt.gca().get_legend_handles_labels()\n",
    "                order = [labels.index(i) for i in hue_hue_order]\n",
    "                plt.legend([handles[i] for i in order], [labels[i] for i in order], title = hue_hue.replace(\"_categ\",\"\"), fancybox=True)\n",
    "\n",
    "            axs.set_title('Select: %s' %(select_str))\n",
    "            fig.subplots_adjust(left=adj_left, bottom=adj_bottom, right=adj_right, top=adj_top)\n",
    "            plt.xticks(rotation=rotation)\n",
    "            select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "            fig.savefig('./Paper_plots/%s_Select-%s_x-%s_y-%s.pdf' % (plot_id, select_str_id, plot_x_itter, plot_y_itter))\n",
    "            plt.close()\n",
    "\n",
    "            \n",
    "def harry_plotter_violinplot(plot_df, plot_x_axis_list, plot_y_axis_list, select_str, plot_id, \n",
    "                      rotation = 30, adj_left = .1, adj_bottom = .2, adj_right = .99, adj_top = .88, no_sort=False, hue_hue = 'None', hue_hue_order = []):\n",
    "    for plot_x_itter in plot_x_axis_list:\n",
    "        if no_sort:\n",
    "            plot_df_sorted = plot_df\n",
    "        else:\n",
    "            dataTypeX = plot_df[plot_x_itter].dtype\n",
    "            if dataTypeX == np.float64 or dataTypeX == np.int64 or dataTypeX == float or dataTypeX == int:\n",
    "                plot_df_sorted = plot_df.sort_values(plot_x_itter)\n",
    "            elif plot_x_itter == 'mem_range':\n",
    "                if(\"FPGA\" in plot_id):\n",
    "                    cat_mem_range = CategoricalDtype([\"[4-8]\", \"[8-16]\", \"[16-32]\", \"[32-64]\", \"[64-128]\", \"[128-256]\", \"[256-512]\", \"[512-1024]\", \"[1024-2048]\"], ordered=True)\n",
    "                    plot_df_sorted = plot_df\n",
    "                    pd.options.mode.chained_assignment = None # https://stackoverflow.com/a/49729413\n",
    "                    plot_df_sorted[\"mem_range\"] = plot_df_sorted[\"mem_range\"].astype(cat_mem_range)\n",
    "                    plot_df_sorted = plot_df_sorted.sort_values('mem_range')                \n",
    "                else:\n",
    "                    plot_df_sorted = plot_df.sort_values('A_mem_footprint')\n",
    "            else:\n",
    "                print(\"Warning: X not sorted: dtype = %s\" % (dataTypeX))\n",
    "                plot_df_sorted = plot_df\n",
    "        for plot_y_itter in plot_y_axis_list:\n",
    "            fig, axs = plt.subplots()\n",
    "            if hue_hue == 'None':\n",
    "                sns_plot = sns.violiplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, ax=axs)\n",
    "            else:\n",
    "                if(hue_hue_order != []):\n",
    "                    sns_plot = sns.violinplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, hue=hue_hue, hue_order=hue_hue_order, ax=axs)\n",
    "                else:\n",
    "                    sns_plot = sns.violinplot(data=plot_df_sorted, x=plot_x_itter, y=plot_y_itter, hue=hue_hue, ax=axs)\n",
    "\n",
    "            if(hue_hue_order != []):               \n",
    "                # reordering the labels\n",
    "                handles, labels = plt.gca().get_legend_handles_labels()\n",
    "                order = [labels.index(i) for i in hue_hue_order]\n",
    "                plt.legend([handles[i] for i in order], [labels[i] for i in order], title = hue_hue.replace(\"_categ\",\"\"), fancybox=True)\n",
    "\n",
    "            axs.set_title('Select: %s' %(select_str))\n",
    "            fig.subplots_adjust(left=adj_left, bottom=adj_bottom, right=adj_right, top=adj_top)\n",
    "            plt.xticks(rotation=rotation)\n",
    "            select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "            fig.savefig('./Paper_plots/%s_Select-%s_x-%s_y-%s.pdf' % (plot_id, select_str_id, plot_x_itter, plot_y_itter))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read GPU Data (panastas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['mtx_name','distribution','placement','seed',\n",
    "                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                'avg_nz_row','std_nz_row',\n",
    "                'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                'avg_scattering','std_scattering','avg_scattering_scaled','std_scattering_scaled',\n",
    "                'skew_coeff','avg_num_neighbours','cross_row_similarity',\n",
    "                'implementation','time','gflops','W_avg','J_estimated', 'System', 'Arch','friends']\n",
    "\n",
    "# select for CPU which data to read (used later in validation too)\n",
    "# Hawk_threads = 64\n",
    "Hawk_threads = 128\n",
    "Arm_threads = 80\n",
    "# Arm_threads = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20748, 31)\n",
      "{'cuSPARSE_hyb9-2', 'CSR5_9', 'cuSPARSE_csr11', 'cuSPARSE_coo11'}\n"
     ]
    }
   ],
   "source": [
    "dtypes=['D']\n",
    "for dtype in dtypes:\n",
    "\n",
    "    inputdata_GPU_V100_friends = pd.read_csv('../Benchmarks/vulcanV100/vulcanV100_dtype-%s_run_friend_dataset.csv' % dtype, names = header_names)\n",
    "    inputdata_GPU_V100_friends['System'] = 'TeslaV100'\n",
    "    \n",
    "    \n",
    "    inputdata_GPU_P100_friends = pd.read_csv('../Benchmarks/vulcanP100/vulcanP100_dtype-%s_run_friend_dataset.csv' % dtype, names = header_names)\n",
    "    inputdata_GPU_P100_friends['System'] = 'TeslaP100'\n",
    "    \n",
    "    inputdata_GPU = pd.concat([inputdata_GPU_V100_friends, inputdata_GPU_P100_friends])\n",
    "    inputdata_GPU['friends'] = True\n",
    "    inputdata_GPU['Arch'] = 'GPU'\n",
    "\n",
    "    print(inputdata_GPU.shape)\n",
    "    # print(inputdata_GPU.head(2))\n",
    "    print(set(inputdata_GPU['implementation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CPU Data (dgal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53775, 31)\n",
      "{'CSR5', 'Naive_CSR_CPU', 'MKL_IE', 'ARM_library'}\n"
     ]
    }
   ],
   "source": [
    "    inputdata_CPU_AMD_friends = pd.read_csv('../Benchmarks/hawk_friends_10_samples_30_range_t%d_d.csv' % Hawk_threads, names=header_names)\n",
    "    inputdata_CPU_AMD_friends['System'] = 'HawkAmdRome'\n",
    "    \n",
    "\n",
    "    inputdata_CPU_ARM_friends = pd.read_csv('../Benchmarks/arm_friends_10_samples_30_range_t%d_d.csv' % Arm_threads, names=header_names)\n",
    "    inputdata_CPU_ARM_friends['System'] = 'Arm'\n",
    "    \n",
    "    inputdata_CPU = pd.concat([inputdata_CPU_AMD_friends, inputdata_CPU_ARM_friends])\n",
    "    inputdata_CPU['friends'] = True\n",
    "    inputdata_CPU['Arch'] = 'CPU'    \n",
    "    \n",
    "    print(inputdata_CPU.shape)\n",
    "    # print(inputdata_CPU.head(2))\n",
    "    print(set(inputdata_CPU['implementation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read FPGA Data (pmpakos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3502, 31)\n",
      "{'Xilinx_SpMV'}\n"
     ]
    }
   ],
   "source": [
    "    fname = \"xilinx_spmv_validation_matrices_10_samples_30_range_twins_dtype-%s.csv\" % dtype\n",
    "    inputdata_FPGA_friends = pd.read_csv('../Benchmarks/%s' % fname, names = header_names)\n",
    "    inputdata_FPGA_friends['System'] = 'AlveoU280'\n",
    "\n",
    "    inputdata_FPGA = inputdata_FPGA_friends\n",
    "    inputdata_FPGA['friends'] = True\n",
    "    inputdata_FPGA['Arch'] = 'FPGA'\n",
    "\n",
    "    print(inputdata_FPGA.shape)\n",
    "    # print(inputdata_FPGA.head(2))\n",
    "    print(set(inputdata_FPGA['implementation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all data, place in *inputdata* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78025, 31)\n",
      "(28956, 31)\n"
     ]
    }
   ],
   "source": [
    "    # Merge the results\n",
    "    inputdata = pd.concat([inputdata_GPU,inputdata_CPU,inputdata_FPGA])\n",
    "    print(inputdata.shape)\n",
    "\n",
    "    # Group per reps, take mean\n",
    "    groupreps = inputdata.groupby(['mtx_name','distribution','placement','seed',\n",
    "                                   'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                                   'avg_nz_row','std_nz_row',\n",
    "                                   'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                                   'avg_scattering','std_scattering','avg_scattering_scaled','std_scattering_scaled',\n",
    "                                   'skew_coeff','avg_num_neighbours','cross_row_similarity',\n",
    "                                   'implementation','System', 'Arch','friends']).mean().reset_index().reindex(columns=header_names)\n",
    "\n",
    "    # dataTypeSeries = groupreps.dtypes\n",
    "    # print('Data type of each column of Dataframe :')\n",
    "    # print(dataTypeSeries)\n",
    "    print(groupreps.shape)\n",
    "    group_system_best = groupreps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Group by \"best-of\" implementation for each device\n",
    "# skip this step if you want to plot every measurement collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13292, 31)\n"
     ]
    }
   ],
   "source": [
    "    # Group per system, take best (it was over \"inputdata\", but \"groupreps\" is better choice I think)\n",
    "    # fixed this after reordering groupreps columns according to header_names\n",
    "    # before this, columns and data were mixed and it was a complete shitstorm\n",
    "    group_system = groupreps.groupby(['mtx_name','distribution','placement','seed',\n",
    "                                      'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                                      'avg_nz_row','std_nz_row',\n",
    "                                      'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                                      'avg_scattering','std_scattering','avg_scattering_scaled','std_scattering_scaled',\n",
    "                                      'skew_coeff','avg_num_neighbours','cross_row_similarity',\n",
    "                                      'System','Arch','friends'], as_index = False)\n",
    "    reslist = []\n",
    "    for desc, experiment in group_system:\n",
    "        best_format = experiment['implementation'].iloc[experiment['gflops'].argmax()]\n",
    "        outrow = experiment[experiment['implementation'] == best_format]\n",
    "        # if(len(outrow)>1):\n",
    "        #     print(len(outrow), outrow)\n",
    "        reslist.append(outrow.values.tolist()[0])\n",
    "        # print(outrow.values.tolist()[0])\n",
    "    group_system_best = pd.DataFrame(reslist, columns = header_names)\n",
    "\n",
    "    print(group_system_best.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Validation matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['mtx_name','distribution','placement','seed',\n",
    "                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                'avg_nz_row','std_nz_row',\n",
    "                'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                'skew_coeff', 'avg_num_neighbours','cross_row_similarity',\n",
    "                'implementation','time','gflops','W_avg','J_estimated', 'System', 'Arch']\n",
    "\n",
    "def find_class(mem_footprint):\n",
    "    low_mb_list =   [4,8, 16,32,64, 128,256,512, 1024,2048, 4096] # removed largest mem range (2048-4096)\n",
    "    high_mb_list =  [8,16,32,64,128,256,512,1024,2048,4096, 8192]\n",
    "    for i in range(len(low_mb_list)):\n",
    "        if(mem_footprint>=low_mb_list[i] and mem_footprint<=high_mb_list[i]):\n",
    "            pos = i\n",
    "            mem_range = '['+str(low_mb_list[pos])+'-'+str(high_mb_list[pos])+']'\n",
    "            return mem_range\n",
    "    return str(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read GPU Data (panastas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes=['D']\n",
    "for dtype in dtypes:\n",
    "    def modify_footprint(v):\n",
    "        if(v[\"implementation\"]==\"CSR5_9\"):\n",
    "            return (v[\"A_mem_footprint\"] - 4*(v[\"m\"]+v[\"n\"]))/(1024*1024.0)\n",
    "        else:\n",
    "            return v[\"A_mem_footprint\"]\n",
    "\n",
    "    def create_complete_gpu_csv(gpu_dataframe, system, arch):\n",
    "        gpu_dataframe[\"mtx_name\"] = gpu_dataframe[\"mtx_name\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "        vm_features = pd.read_csv(\"../Benchmarks/validation_matrices_features.csv\", sep=\"\\t\")\n",
    "        mtx_names = list(vm_features[\"matrix\"]) # same as : list(set(inputdata_GPU[\"mtx_name\"]))\n",
    "\n",
    "        inputvaldata_GPU = pd.DataFrame(columns=header_names)\n",
    "        \n",
    "        for mtx_name in mtx_names:\n",
    "            for index, curr in gpu_dataframe[gpu_dataframe[\"mtx_name\"] == mtx_name].iterrows():\n",
    "                mtx_name = mtx_name\n",
    "                distribution = \"unused\"\n",
    "                placement = \"unused\"\n",
    "                seed = curr[\"seed\"]\n",
    "                m = curr[\"m\"]\n",
    "                n = curr[\"n\"]\n",
    "                nz = curr[\"nz\"]\n",
    "                density = nz/(m*n)*100.0\n",
    "                A_mem_footprint = curr[\"A_mem_footprint\"]\n",
    "                mem_range = find_class((nz*(64+32)+32*(m+1))/(8*1024*1024))\n",
    "                avg_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-avg\"])[0]\n",
    "                std_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-std\"])[0]\n",
    "                avg_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-avg\"])[0]*n\n",
    "                std_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-std\"])[0]*n\n",
    "                avg_bandwidth_scaled = avg_bandwidth/n\n",
    "                std_bandwidth_scaled = std_bandwidth/n\n",
    "                # avg_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-avg\"])[0]\n",
    "                # std_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-std\"])[0]\n",
    "                # avg_scattering_scaled = avg_scattering*n\n",
    "                # std_scattering_scaled = std_scattering*n\n",
    "                # skew_coeff = (list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-max\"])[0] - avg_nz_row)/avg_nz_row\n",
    "                skew_coeff = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"skew_coeff\"])[0]\n",
    "                avg_num_neighbours = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"neigh-avg\"])[0]\n",
    "                cross_row_similarity = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"cross_row_sim-avg\"])[0]\n",
    "                \n",
    "                implementation = curr[\"implementation\"]\n",
    "                time = curr[\"time\"]\n",
    "                gflops = curr[\"gflops\"]\n",
    "                W_avg = curr[\"W_avg\"]\n",
    "                J_estimated = curr[\"J_estimated\"]\n",
    "                inputvaldata_GPU = inputvaldata_GPU.append({'mtx_name' : mtx_name, 'distribution' : distribution, 'placement' : placement, 'seed' : seed, \n",
    "                                                            'm' : m, 'n' : n, 'nz' : nz, 'density' : density, 'A_mem_footprint' : A_mem_footprint, 'mem_range' : mem_range, \n",
    "                                                            'avg_nz_row' : avg_nz_row, 'std_nz_row' : std_nz_row, \n",
    "                                                            'avg_bandwidth' : avg_bandwidth, 'std_bandwidth' : std_bandwidth, 'avg_bandwidth_scaled' : avg_bandwidth_scaled, 'std_bandwidth_scaled' : std_bandwidth_scaled,\n",
    "                                                            'skew_coeff' : skew_coeff, 'avg_num_neighbours' : avg_num_neighbours, 'cross_row_similarity' : cross_row_similarity,\n",
    "                                                            'implementation' : implementation, 'time' : time, 'gflops' : gflops, 'W_avg' : W_avg, 'J_estimated' : J_estimated},\n",
    "                                                           ignore_index=True)\n",
    "        inputvaldata_GPU['System'] = system\n",
    "        inputvaldata_GPU['Arch'] = arch\n",
    "        if(system=='TeslaV100'):\n",
    "            inputvaldata_GPU[\"A_mem_footprint\"] = inputvaldata_GPU.apply(lambda x: modify_footprint(x), axis=1)\n",
    "        return inputvaldata_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read V100 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mtx_name distribution placement seed       m       n      nz   density  \\\n",
      "0  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "1  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "\n",
      "   A_mem_footprint mem_range  ...  skew_coeff  avg_num_neighbours  \\\n",
      "0        13.327614    [8-16]  ...   61.947156            0.803365   \n",
      "1        13.327614    [8-16]  ...   61.947156            0.803365   \n",
      "\n",
      "   cross_row_similarity  implementation      time   gflops    W_avg  \\\n",
      "0              0.633019          CSR5_9  0.000044  44.0416  150.298   \n",
      "1              0.633019          CSR5_9  0.000043  44.7557  144.489   \n",
      "\n",
      "   J_estimated     System Arch  \n",
      "0     0.005961  TeslaV100  GPU  \n",
      "1     0.005720  TeslaV100  GPU  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "    arch, system = 'GPU', 'TeslaV100'\n",
    "    \n",
    "    # fname = \"silver1-TeslaV100_dtype-%s_run_validation_matrices.csv\" % dtype\n",
    "    fname = \"vulcanV100/vulcanV100_dtype-%s_run_validation_matrices.csv\" % dtype\n",
    "    gpu_data = pd.read_csv('../Benchmarks/%s' % fname, names = ['mtx_name','distribution','placement','diagonal_factor','seed',\n",
    "                                                                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                                                                'avg_nz_row','std_nz_row',\n",
    "                                                                'avg_bandwidth','std_bandwidth','avg_scattering','std_scattering',\n",
    "                                                                'implementation','time','gflops','W_avg', 'J_estimated'])\n",
    "\n",
    "    gpu_data = create_complete_gpu_csv(gpu_data, system, arch)\n",
    "    fname2 = fname.replace('.csv', '_modified_features.csv')\n",
    "    gpu_data.to_csv('../Benchmarks/%s' % fname2, header=False, index=False)\n",
    "    print(gpu_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read P100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mtx_name distribution placement seed       m       n      nz   density  \\\n",
      "0  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "1  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "\n",
      "   A_mem_footprint mem_range  ...  skew_coeff  avg_num_neighbours  \\\n",
      "0          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "1          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "\n",
      "   cross_row_similarity   implementation      time   gflops    W_avg  \\\n",
      "0              0.633019  cuSPARSE_hyb9-2  0.000099  19.3100  79.6924   \n",
      "1              0.633019  cuSPARSE_hyb9-2  0.000099  19.3587  79.6451   \n",
      "\n",
      "   J_estimated     System Arch  \n",
      "0     0.007862  TeslaP100  GPU  \n",
      "1     0.007897  TeslaP100  GPU  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "    arch, system = 'GPU', 'TeslaP100'\n",
    "    \n",
    "    fname = \"vulcanP100/vulcanP100_dtype-%s_run_validation_matrices.csv\" % dtype\n",
    "    # it has different data layout @@@ panastas @@@\n",
    "    gpu_data = pd.read_csv('../Benchmarks/%s' % fname, names = ['mtx_name','distribution','placement','seed',\n",
    "                                                                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                                                                'avg_nz_row','std_nz_row',\n",
    "                                                                'avg_bandwidth','std_bandwidth','avg_scattering','std_scattering',\n",
    "                                                                '1','2','3','4','5','6','7',\n",
    "                                                                'implementation','time','gflops','W_avg', 'J_estimated'])\n",
    "    \n",
    "    gpu_data = create_complete_gpu_csv(gpu_data, system, arch)\n",
    "    fname2 = fname.replace('.csv', '_modified_features.csv')\n",
    "    gpu_data.to_csv('../Benchmarks/%s' % fname2, header=False, index=False)\n",
    "    print(gpu_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read CPU Data (dgal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_complete_cpu_csv(cpu_dataframe, system, arch):\n",
    "        vm_features = pd.read_csv(\"../Benchmarks/validation_matrices_features.csv\", sep=\"\\t\")\n",
    "        mtx_names = list(vm_features[\"matrix\"]) # same as : list(set(inputdata_GPU[\"mtx_name\"]))\n",
    "\n",
    "        inputvaldata_CPU = pd.DataFrame(columns=header_names)\n",
    "        \n",
    "        for mtx_name in mtx_names:\n",
    "            for index, curr in cpu_dataframe[cpu_dataframe[\"mtx_name\"] == mtx_name].iterrows():\n",
    "                mtx_name = mtx_name\n",
    "                distribution = \"unused\"\n",
    "                placement = \"unused\"\n",
    "                diagonal_factor = 0\n",
    "                seed = 0\n",
    "                m = curr[\"m\"]\n",
    "                n = curr[\"n\"]\n",
    "                nz = curr[\"nz\"]\n",
    "                density = nz/(m*n)*100.0\n",
    "                A_mem_footprint = curr[\"A_mem_footprint\"]\n",
    "                mem_range = find_class((nz*(64+32)+32*(m+1))/(8*1024*1024))\n",
    "                avg_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-avg\"])[0]\n",
    "                std_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-std\"])[0]\n",
    "                avg_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-avg\"])[0]*n\n",
    "                std_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-std\"])[0]*n\n",
    "                avg_bandwidth_scaled = avg_bandwidth/n\n",
    "                std_bandwidth_scaled = std_bandwidth/n\n",
    "                # avg_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-avg\"])[0]\n",
    "                # std_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-std\"])[0]\n",
    "                # avg_scattering_scaled = avg_scattering*n\n",
    "                # std_scattering_scaled = std_scattering*n\n",
    "                # skew_coeff = (list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-max\"])[0] - avg_nz_row)/avg_nz_row\n",
    "                skew_coeff = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"skew_coeff\"])[0]\n",
    "                avg_num_neighbours = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"neigh-avg\"])[0]\n",
    "                cross_row_similarity = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"cross_row_sim-avg\"])[0]\n",
    "                                \n",
    "                implementation = curr[\"implementation\"]\n",
    "                time = curr[\"time\"]\n",
    "                gflops = curr[\"gflops\"]\n",
    "                W_avg = curr[\"W_avg\"]\n",
    "                J_estimated = curr[\"J_estimated\"]\n",
    "                inputvaldata_CPU = inputvaldata_CPU.append({'mtx_name' : mtx_name, 'distribution' : distribution, 'placement' : placement, 'seed' : seed, \n",
    "                                                              'm' : m, 'n' : n, 'nz' : nz, 'density' : density, 'A_mem_footprint' : A_mem_footprint, 'mem_range' : mem_range, \n",
    "                                                              'avg_nz_row' : avg_nz_row, 'std_nz_row' : std_nz_row, \n",
    "                                                              'avg_bandwidth' : avg_bandwidth, 'std_bandwidth' : std_bandwidth, 'avg_bandwidth_scaled' : avg_bandwidth_scaled, 'std_bandwidth_scaled' : std_bandwidth_scaled,\n",
    "                                                              #'avg_scattering' : avg_scattering, 'std_scattering' : std_scattering, 'avg_scattering_scaled' : avg_scattering_scaled, 'std_scattering_scaled' : std_scattering_scaled,\n",
    "                                                              'skew_coeff' : skew_coeff, 'avg_num_neighbours' : avg_num_neighbours, 'cross_row_similarity' : cross_row_similarity,\n",
    "                                                              'implementation' : implementation, 'time' : time, 'gflops' : gflops, 'W_avg' : W_avg, 'J_estimated' : J_estimated},\n",
    "                                                             ignore_index=True)\n",
    "        inputvaldata_CPU['System'] = system\n",
    "        inputvaldata_CPU['Arch'] = arch\n",
    "        return inputvaldata_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read Hawk data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mtx_name distribution placement seed       m       n      nz   density  \\\n",
      "0  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "1  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "\n",
      "   A_mem_footprint mem_range  ...  skew_coeff  avg_num_neighbours  \\\n",
      "0          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "1          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "\n",
      "   cross_row_similarity  implementation      time   gflops  W_avg  \\\n",
      "0              0.633019            CSR5  0.011017  22.2826      0   \n",
      "1              0.633019            CSR5  0.010817  22.6946      0   \n",
      "\n",
      "   J_estimated       System Arch  \n",
      "0            0  HawkAmdRome  CPU  \n",
      "1            0  HawkAmdRome  CPU  \n",
      "\n",
      "[2 rows x 26 columns]\n",
      "{'CSR5', 'Naive_CSR_CPU', 'MKL_IE', 'MKL_IE_no_hint'}\n"
     ]
    }
   ],
   "source": [
    "    arch, system = 'CPU', 'HawkAmdRome'\n",
    "    fname = \"hawk_validation_matrices_t%d_d.csv\" % Hawk_threads\n",
    "\n",
    "    cpu_data = pd.read_csv('../Benchmarks/%s' % fname, names = ['mtx_name','distribution','placement','seed',\n",
    "                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                'avg_nz_row','std_nz_row',\n",
    "                'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                'avg_scattering','std_scattering','avg_scattering_scaled','std_scattering_scaled',\n",
    "                'skew_coeff',\n",
    "                'implementation','time','gflops','W_avg','J_estimated', 'System'])\n",
    "      \n",
    "    cpu_data = create_complete_cpu_csv(cpu_data, system, arch)\n",
    "    fname2 = fname.replace('.csv', '_modified_features.csv')\n",
    "    \n",
    "    if(fname == \"hawk_validation_matrices_t128_d.csv\"):\n",
    "        cpu_data = cpu_data[cpu_data['implementation'] != 'MKL_IE_no_optimize']\n",
    "        cpu_data = cpu_data[cpu_data['implementation'] != 'Custom_CSR_BV_CPU']\n",
    "        cpu_data = cpu_data[cpu_data['implementation'] != 'Custom_CSR_B_CPU']\n",
    "        # cpu_data = cpu_data[cpu_data['implementation'] != 'MKL_IE_no_hint']\n",
    "        # cpu_data = cpu_data[cpu_data['implementation'] != 'MKL_IE']\n",
    "    \n",
    "    cpu_data.to_csv('../Benchmarks/%s' % fname2, header=False, index=False)\n",
    "    print(cpu_data.head(2))\n",
    "    print(set(cpu_data['implementation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read Arm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mtx_name distribution placement seed       m       n      nz   density  \\\n",
      "0  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "1  scircuit       unused    unused    0  170998  170998  958936  0.003279   \n",
      "\n",
      "   A_mem_footprint mem_range  ...  skew_coeff  avg_num_neighbours  \\\n",
      "0          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "1          11.6265    [8-16]  ...   61.947156            0.803365   \n",
      "\n",
      "   cross_row_similarity  implementation      time   gflops  W_avg  \\\n",
      "0              0.633019   Naive_CSR_CPU  0.013801  17.7871      0   \n",
      "1              0.633019     ARM_library  0.003843  63.8778      0   \n",
      "\n",
      "   J_estimated  System Arch  \n",
      "0            0     Arm  CPU  \n",
      "1            0     Arm  CPU  \n",
      "\n",
      "[2 rows x 26 columns]\n",
      "{'ARM_library', 'Naive_CSR_CPU'}\n"
     ]
    }
   ],
   "source": [
    "    arch, system = 'CPU', 'Arm'\n",
    "    fname = \"arm_validation_matrices_t%d_d.csv\" % Arm_threads\n",
    "\n",
    "    cpu_data_arm = pd.read_csv('../Benchmarks/%s' % fname, names = ['mtx_name','distribution','placement','seed',\n",
    "                'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                'avg_nz_row','std_nz_row',\n",
    "                'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                'avg_scattering','std_scattering','avg_scattering_scaled','std_scattering_scaled',\n",
    "                'skew_coeff',\n",
    "                'implementation','time','gflops','W_avg','J_estimated', 'System'])\n",
    "\n",
    "    cpu_data_arm = create_complete_cpu_csv(cpu_data_arm, system, arch)\n",
    "    fname2 = fname.replace('.csv', '_modified_features.csv')\n",
    "    \n",
    "    cpu_data_arm.to_csv('../Benchmarks/%s' % fname2, header=False, index=False)\n",
    "    print(cpu_data_arm.head(2))\n",
    "    print(set(cpu_data_arm['implementation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read FPGA Data (pmpakos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_complete_fpga_csv(fpga_dataframe, system, arch):\n",
    "        vm_features = pd.read_csv(\"../Benchmarks/validation_matrices_features.csv\", sep=\"\\t\")\n",
    "        mtx_names = list(vm_features[\"matrix\"]) # same as : list(set(inputdata_GPU[\"mtx_name\"]))\n",
    "\n",
    "        inputvaldata_FPGA = pd.DataFrame(columns=header_names)\n",
    "        \n",
    "        for mtx_name in mtx_names:\n",
    "            for index, curr in fpga_dataframe[fpga_dataframe[\"matrix\"] == mtx_name].iterrows():\n",
    "                mtx_name = mtx_name\n",
    "                distribution = \"unused\"\n",
    "                placement = \"unused\"\n",
    "                diagonal_factor = 0\n",
    "                seed = 0\n",
    "                m = curr[\"nr_rows\"]\n",
    "                n = curr[\"nr_cols\"]\n",
    "                nz = curr[\"nr_nnz\"]\n",
    "                density = nz/(m*n)*100.0\n",
    "                # A_mem_footprint = curr[\"mem_footprint\"]\n",
    "                A_mem_footprint = (nz*(64+32)+32*(m+1))/(8*1024*1024)\n",
    "                \n",
    "                mem_range = find_class((nz*(64+32)+32*(m+1))/(8*1024*1024))\n",
    "                avg_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-avg\"])[0]\n",
    "                std_nz_row = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-std\"])[0]\n",
    "                avg_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-avg\"])[0]*n\n",
    "                std_bandwidth = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"bw-std\"])[0]*n\n",
    "                avg_bandwidth_scaled = avg_bandwidth/n\n",
    "                std_bandwidth_scaled = std_bandwidth/n\n",
    "                # avg_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-avg\"])[0]\n",
    "                # std_scattering = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"sc-std\"])[0]\n",
    "                # avg_scattering_scaled = avg_scattering*n\n",
    "                # std_scattering_scaled = std_scattering*n\n",
    "                # skew_coeff = (list(vm_features[vm_features[\"matrix\"]==mtx_name][\"nnz-r-max\"])[0] - avg_nz_row)/avg_nz_row\n",
    "                skew_coeff = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"skew_coeff\"])[0]\n",
    "                avg_num_neighbours = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"neigh-avg\"])[0]\n",
    "                cross_row_similarity = list(vm_features[vm_features[\"matrix\"]==mtx_name][\"cross_row_sim-avg\"])[0]\n",
    "                                \n",
    "                implementation = curr[\"implementation\"]\n",
    "                time = curr[\"runtime_iter\"]\n",
    "                gflops = curr[\"gflops\"]\n",
    "                W_avg = curr[\"W_avg\"]\n",
    "                J_estimated = curr[\"J_estimated\"]\n",
    "                inputvaldata_FPGA = inputvaldata_FPGA.append({'mtx_name' : mtx_name, 'distribution' : distribution, 'placement' : placement, 'seed' : seed, \n",
    "                                                              'm' : m, 'n' : n, 'nz' : nz, 'density' : density, 'A_mem_footprint' : A_mem_footprint, 'mem_range' : mem_range, \n",
    "                                                              'avg_nz_row' : avg_nz_row, 'std_nz_row' : std_nz_row, \n",
    "                                                              'avg_bandwidth' : avg_bandwidth, 'std_bandwidth' : std_bandwidth, 'avg_bandwidth_scaled' : avg_bandwidth_scaled, 'std_bandwidth_scaled' : std_bandwidth_scaled,\n",
    "                                                              #'avg_scattering' : avg_scattering, 'std_scattering' : std_scattering, 'avg_scattering_scaled' : avg_scattering_scaled, 'std_scattering_scaled' : std_scattering_scaled,\n",
    "                                                              'skew_coeff' : skew_coeff, 'avg_num_neighbours' : avg_num_neighbours, 'cross_row_similarity' : cross_row_similarity,\n",
    "                                                              'implementation' : implementation, 'time' : time, 'gflops' : gflops, 'W_avg' : W_avg, 'J_estimated' : J_estimated},\n",
    "                                                             ignore_index=True)\n",
    "        inputvaldata_FPGA['System'] = system\n",
    "        inputvaldata_FPGA['Arch'] = arch\n",
    "        return inputvaldata_FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mtx_name distribution placement seed       m       n       nz  \\\n",
      "0         scircuit       unused    unused    0  170998  170998   958936   \n",
      "1  mac_econ_fwd500       unused    unused    0  206500  206500  1273389   \n",
      "\n",
      "    density  A_mem_footprint mem_range  ...  skew_coeff  avg_num_neighbours  \\\n",
      "0  0.003279        11.626461    [8-16]  ...   61.947156            0.803365   \n",
      "1  0.002986        15.360519    [8-16]  ...    6.135290            0.176686   \n",
      "\n",
      "   cross_row_similarity  implementation      time    gflops  W_avg  \\\n",
      "0              0.633019     Xilinx_SpMV  3.709320   6.05957     33   \n",
      "1              0.330509     Xilinx_SpMV  0.883522  18.40050     33   \n",
      "\n",
      "   J_estimated     System  Arch  \n",
      "0   122.407560  AlveoU280  FPGA  \n",
      "1    29.156226  AlveoU280  FPGA  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "    arch, system = 'FPGA', 'AlveoU280'\n",
    "\n",
    "    fname = \"results_validation_matrices.csv\"\n",
    "    fpga_data = pd.read_csv('../FPGA_stuff/%s' % fname, names = [\"matrix\",\"nr_rows\",\"nr_cols\",\"nr_nnz\",\"density\",\n",
    "                                                                 \"mem_footprint\",\"implementation\",\"runtime_iter\",\n",
    "                                                                 \"gflops\",\"W_avg\",\"J_estimated\"])\n",
    "    \n",
    "    fpga_data = create_complete_fpga_csv(fpga_data, system, arch)\n",
    "    fname2 = \"xilinx_spmv_validation_matrices_dtype-D.csv\"\n",
    "    fpga_data.to_csv('../Benchmarks/%s' % fname2, header=False, index=False)\n",
    "    print(fpga_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ready to read validation matrices complete dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes=['D']\n",
    "\n",
    "for dtype in dtypes:\n",
    "    #Unified read\n",
    "    # fname = \"silver1-TeslaV100_dtype-%s_run_validation_matrices_modified_features.csv\" % dtype\n",
    "    fname = \"vulcanV100/vulcanV100_dtype-%s_run_validation_matrices_modified_features.csv\" % dtype\n",
    "    inputvaldata_GPU_V100 = pd.read_csv('../Benchmarks/%s' % fname, names = header_names,index_col=False)\n",
    "\n",
    "    # fname = \"silver1-TeslaV100_dtype-%s_run_validation_matrices_modified_features.csv\" % dtype\n",
    "    fname = \"vulcanP100/vulcanP100_dtype-%s_run_validation_matrices_modified_features.csv\" % dtype\n",
    "    inputvaldata_GPU_P100 = pd.read_csv('../Benchmarks/%s' % fname, names = header_names,index_col=False)\n",
    "\n",
    "    fname = \"hawk_validation_matrices_t%d_d_modified_features.csv\" % Hawk_threads\n",
    "    inputvaldata_CPU_Hawk = pd.read_csv('../Benchmarks/%s' % fname, names = header_names,index_col=False)\n",
    "    \n",
    "    fname = \"arm_validation_matrices_t%d_d_modified_features.csv\" % Arm_threads\n",
    "    inputvaldata_CPU_Arm = pd.read_csv('../Benchmarks/%s' % fname, names = header_names,index_col=False)\n",
    "    \n",
    "    fname = \"xilinx_spmv_validation_matrices_dtype-%s.csv\" % dtype\n",
    "    inputvaldata_FPGA = pd.read_csv('../Benchmarks/%s' % fname, names = header_names, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 26)\n",
      "{'CSR5_9', 'MKL_IE', 'cuSPARSE_hyb9-2', 'Xilinx_SpMV', 'ARM_library', 'CSR5', 'cuSPARSE_csr11', 'MKL_IE_no_hint', 'Naive_CSR_CPU', 'cuSPARSE_coo11'}\n",
      "(461, 26)\n"
     ]
    }
   ],
   "source": [
    "    # Merge the results\n",
    "    inputvaldata = pd.concat([inputvaldata_GPU_V100, inputvaldata_GPU_P100, \n",
    "                              inputvaldata_CPU_Hawk, inputvaldata_CPU_Arm, \n",
    "                              inputvaldata_FPGA])\n",
    "    print(inputvaldata.shape)\n",
    "    \n",
    "    # Group per reps, take mean\n",
    "    # header_names without 'time','gflops','W_avg','J_estimated'\n",
    "    groupvalreps = inputvaldata.groupby( ['mtx_name','distribution','placement','seed',\n",
    "                                          'm','n','nz','density','A_mem_footprint','mem_range',\n",
    "                                          'avg_nz_row','std_nz_row',\n",
    "                                          'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                                          'skew_coeff','avg_num_neighbours','cross_row_similarity',\n",
    "                                          'implementation','System', 'Arch']).mean().reset_index().reindex(columns=header_names)\n",
    "    \n",
    "    # groupvalreps = groupvalreps[groupvalreps['implementation'] != 'MKL_IE_Optimize']\n",
    "    # groupvalreps = groupvalreps[groupvalreps['implementation'] != 'MKL_IE']\n",
    "    print(set(groupvalreps['implementation']))\n",
    "    # print(groupvalreps[groupvalreps[\"mtx_name\"]==\"circuit5M\"])\n",
    "    print(groupvalreps.shape)\n",
    "    group_val_system_best = groupvalreps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Group by \"best-of\" implementation for each device\n",
    "# skip this step if you want to plot per-format validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 26)\n"
     ]
    }
   ],
   "source": [
    "    # Group per system, take best\n",
    "    # header_names without 'time','gflops','W_avg','J_estimated', 'implementation'\n",
    "    # Curiously, I have to also remove \"A_mem_footprint\", because for CSR5 it reports different mem_footprint\n",
    "    # for the same matrix, leading to a different representation in groupby\n",
    "    groupval_system = groupvalreps.groupby(['mtx_name','distribution','placement','seed',\n",
    "                                            'm','n','nz','density','mem_range',\n",
    "                                            'avg_nz_row','std_nz_row',\n",
    "                                            'avg_bandwidth','std_bandwidth','avg_bandwidth_scaled','std_bandwidth_scaled',\n",
    "                                            'skew_coeff','avg_num_neighbours','cross_row_similarity',\n",
    "                                            'System','Arch'], as_index = False)\n",
    "    reslist = []\n",
    "    \n",
    "    for desc, experiment in groupval_system:\n",
    "        best_format = experiment['implementation'].iloc[experiment['gflops'].argmax()]\n",
    "        outrow = experiment[experiment['implementation'] == best_format]\n",
    "        outrow = outrow[header_names] # reorder column because they are mixed by group-by\n",
    "        reslist.append(outrow.values.tolist()[0])\n",
    "\n",
    "    group_val_system_best = pd.DataFrame(reslist, columns = header_names)\n",
    "    print(group_val_system_best.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin plotting\n",
    "# perhaps figure size needs refinement, you know better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_em_feats(pcg, features, dataframe, row, threshold=1):\n",
    "        low = 1 - pcg*0.01\n",
    "        high = 1 + pcg*0.01\n",
    "        first = True\n",
    "        feature_boolean = True\n",
    "        for i in range(len(features)):\n",
    "            feature = features[i]\n",
    "            feature_boolean_tmp = feature_boolean &\\\n",
    "                                  (dataframe[feature] <= row[feature]*high) &\\\n",
    "                                  (dataframe[feature] >= row[feature]*low)\n",
    "            \n",
    "            isol = dataframe[feature_boolean_tmp]\n",
    "            pcg2 = pcg\n",
    "            # try to find twins only when skew_coeff value is low\n",
    "            if((feature == 'skew_coeff' and row[feature] < 5) or (feature == 'avg_num_neighbours') or (feature == 'cross_row_similarity')):\n",
    "                while(isol.shape[0]<threshold):\n",
    "                    pcg2 = pcg2+1\n",
    "                    if((feature == 'avg_num_neighbours' and pcg2>50) or (feature == 'cross_row_similarity' and pcg2>50) or pcg2>1000):\n",
    "                        break\n",
    "                    low2 = 1 - pcg2*0.01\n",
    "                    high2 = 1 + pcg2*0.01\n",
    "                    feature_boolean_tmp = feature_boolean &\\\n",
    "                                          (dataframe[feature] <= row[feature]*high2) &\\\n",
    "                                          (dataframe[feature] >= row[feature]*low2)\n",
    "                    isol = dataframe[feature_boolean_tmp]\n",
    "\n",
    "#             if(pcg2!=pcg):\n",
    "#                 if(feature=='skew_coeff'):\n",
    "#                     print('\\n',feature, '\\t\\t', pcg,'->', pcg2, '\\t', row['mtx_name'],'\\t', row[feature])\n",
    "#                 else:\n",
    "#                     print('\\n',feature, '\\t', pcg,'->', pcg2, '\\t', row['mtx_name'],'\\t', row[feature])\n",
    "#                 if(feature !='m'):# and feature !='avg_nz_row'):\n",
    "#                     print(row['mtx_name'], features[i], row[feature], isol.shape)\n",
    "#                     print(sorted(set([x for x in isol[feature]])))\n",
    "#                 if(feature !='m'):\n",
    "#                     if(i<len(features)-1):\n",
    "#                         print('\\t', features[i+1], sorted(set([np.round(x,2) for x in isol[features[i+1]]])), '\\n')\n",
    "\n",
    "            feature_boolean = feature_boolean_tmp\n",
    "\n",
    "        similar_synthetic = dataframe[feature_boolean]\n",
    "        return similar_synthetic\n",
    "\n",
    "# used to be like this\n",
    "#         similar_synthetic = group_system_best_part[True \\\n",
    "#     #                                                   & (group_system_best_part['nz'] <= row['nz']*1.3) \\\n",
    "#     #                                                   & (group_system_best_part['nz'] >= row['nz']*0.7) \\\n",
    "#                                                       & (group_system_best_part['m'] <= row['m']*1.3) \\\n",
    "#                                                       & (group_system_best_part['m'] >= row['m']*0.7) \\\n",
    "#                                                       & (group_system_best_part['avg_nz_row'] <= row['avg_nz_row']*1.3) \\\n",
    "#                                                       & (group_system_best_part['avg_nz_row'] >= row['avg_nz_row']*0.7) \\\n",
    "#     #                                                   & (group_system_best_part['std_nz_row'] <= row['std_nz_row']*1.3) \\\n",
    "#     #                                                   & (group_system_best_part['std_nz_row'] >= row['std_nz_row']*0.7) \\\n",
    "#     #                                                   & (group_system_best_part['avg_bandwidth_scaled'] <= row['avg_bandwidth_scaled']*1.3) \\\n",
    "#     #                                                   & (group_system_best_part['avg_bandwidth_scaled'] >= row['avg_bandwidth_scaled']*0.7) \\\n",
    "#                                                       & (group_system_best_part['skew_coeff'] <= row['skew_coeff']*1.3) \\\n",
    "#                                                       & (group_system_best_part['skew_coeff'] >= row['skew_coeff']*0.7) \\\n",
    "#                                                       & (group_system_best_part['avg_num_neighbours'] <= row['avg_num_neighbours']*1.3) \\\n",
    "#                                                       & (group_system_best_part['avg_num_neighbours'] >= row['avg_num_neighbours']*0.7) \\\n",
    "#                                                       & (group_system_best_part['cross_row_similarity'] <= row['cross_row_similarity']*1.3) \\\n",
    "#                                                       & (group_system_best_part['cross_row_similarity'] >= row['cross_row_similarity']*0.7) \\\n",
    "#                                                      ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find at least \"threshold\" twins for each validation matrix\n",
    "## set threshold = -1 to skip trying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # threshold = -1\n",
    "    threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=8\n",
    "plt.rc('font', family='serif', serif='Times', size=font)\n",
    "#plt.rc('text', usetex=True)  \n",
    "plt.rc('xtick', labelsize=font)\n",
    "plt.rc('ytick', labelsize=font)\n",
    "plt.rc('axes', labelsize=font)\n",
    "\n",
    "# width - column as measured in inkscape\n",
    "width = 3.487\n",
    "height = width / 1.618\n",
    "\n",
    "width = 3*width\n",
    "height = 3*height\n",
    "\n",
    "# width - double columnt\n",
    "width_2col = 7.2\n",
    "height_2col = width / 1.618\n",
    "\n",
    "#axs1.get_legend().remove()\n",
    "#axs1.set_xticklabels([])\n",
    "#axs1.set_xlabel('')\n",
    "#axs1.set_ylabel('Relative Normalized Performance')\n",
    "#axs1.set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loop Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    ctr = 0\n",
    "    validation_metadata_systems = []\n",
    "    ranges_dev = [\"TeslaV100\", \"TeslaP100\", \"HawkAmdRome\", \"Arm\", \"AlveoU280\"]\n",
    "    for system in ranges_dev:\n",
    "        plot_x_axis = 'mtx_name'\n",
    "        plot_y_axis = 'gflops'\n",
    "\n",
    "        # when you want to plot overall best format\n",
    "        impl = ''\n",
    "\n",
    "        # when you want to plot specific format\n",
    "        # impl = 'cuSPARSE_coo11'\n",
    "        # impl = 'cuSPARSE_csr11'\n",
    "        # impl = 'cuSPARSE_hyb9-2'\n",
    "        # impl = 'CSR5_9'\n",
    "\n",
    "        select_criterion = ( group_val_system_best['System'] == system )\n",
    "        select_str = 'Validation-'+system+'\\n'+'rows ±30%, avg nonzeros per row ±30%, skew_coeff ±30%,'+'\\n' + 'avg_num_neighbours ±30%, cross_row_similarity ±30%'\n",
    "        if(impl!=''):\n",
    "            select_criterion =  select_criterion & (group_val_system_best['implementation'] == impl)\n",
    "            select_str = impl+\"_\"+ select_str\n",
    "\n",
    "        groupvalreps_select_best = group_val_system_best[select_criterion]\n",
    "\n",
    "        groupvalreps_select_sorted = groupvalreps_select_best.sort_values('A_mem_footprint')\n",
    "        #groupvalreps_select_sorted = groupvalreps_select_best.sort_values('gflops')\n",
    "\n",
    "        group_system_best_part = group_system_best[group_system_best['System'] == system]\n",
    "\n",
    "        friends = True\n",
    "        if(friends != ''):\n",
    "            group_system_best_part = group_system_best_part[group_system_best_part['friends']==friends]\n",
    "            if(impl!=''):\n",
    "                group_system_best_part = group_system_best_part[group_system_best_part['implementation']==impl]\n",
    "\n",
    "        df_empty = True\n",
    "        # exclude_matrices = [\n",
    "        #     \"wikipedia-20051105\",\"scircuit\",\"mac_econ_fwd500\",\"rail4284\",\"circuit5M\",\"conf5_4-8x8-15\",\"rajat31\",\"in-2004\",\"eu-2005\",\"TSOPF_RS_b300_c3\",\"mip1\",\"PR02R\",\"Ga41As41H72\",\"shipsec1\",\"Si41Ge41H72\",\"crankseg_2\",\"TSOPF_RS_b2383\",\n",
    "        #     \"mc2depi\",\"raefsky3\",\"cop20k_A\",\"bbmat\",\"Chebyshev4\",\"rma10\",\"cage15\",\"cant\",\"pdb1HYS\",\"consph\",\"ldoor\",\"pwtk\",\"bone010\" #,\"webbase-1M\"\n",
    "        # ]  \n",
    "        # groupvalreps_select_sorted = groupvalreps_select_sorted[~groupvalreps_select_sorted['mtx_name'].isin(exclude_matrices)]\n",
    "\n",
    "        validation_headers = ['mtx_name', 'val_gflops', 'synth_mean', 'synth_median', 'synth_min', 'synth_max', 'diff_median', 'diff_mean', 'diff_min', 'diff_max']\n",
    "        validation_metadata = pd.DataFrame(columns=validation_headers)\n",
    "        \n",
    "        for index, row in groupvalreps_select_sorted.iterrows():\n",
    "            pd.options.mode.chained_assignment = None  # default='warn'\n",
    "            pcg = 30 # +-30%         \n",
    "            # features to consider too : 'nz', 'std_nz_row', 'avg_bandwidth_scaled'\n",
    "            features = ['m', 'avg_nz_row', 'skew_coeff', 'avg_num_neighbours', 'cross_row_similarity']\n",
    "            similar_synthetic = get_em_feats(pcg, features, group_system_best_part, row, threshold)\n",
    "\n",
    "            if(impl==''):\n",
    "                mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str((row['implementation'])), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "            else:\n",
    "                mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str(round(row['A_mem_footprint'],1)), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "            #similar_synthetic['mtx_name'] = mtx_name_ext Adds Implementation and num of friends in name\n",
    "            similar_synthetic['mtx_name'] = row['mtx_name']\n",
    "            \n",
    "            # box_stats are only useful for \"min\" and \"max\".  (https://www.adamsmith.haus/python/docs/matplotlib.cbook.boxplot_stats)\n",
    "            # for \"mean\" and \"median\", same values as simple queries to dataframe are returned\n",
    "            box_stats = boxplot_stats(similar_synthetic['gflops'])[0]\n",
    "            synth_mean = box_stats['mean'] # similar_synthetic['gflops'].mean()\n",
    "            synth_median = box_stats['med'] # similar_synthetic['gflops'].median()\n",
    "            # these two are the \"whiskers\" of the boxplot, excluding outliers from min and max\n",
    "            synth_min = box_stats['whislo']\n",
    "            synth_max = box_stats['whishi']\n",
    "\n",
    "            if(row['gflops']>0):\n",
    "                diff_mean = (synth_mean - row['gflops'])/row['gflops'] *100\n",
    "                diff_median = (synth_median - row['gflops'])/row['gflops'] *100\n",
    "                diff_min = (synth_min - row['gflops'])/row['gflops'] *100\n",
    "                diff_max = (synth_max - row['gflops'])/row['gflops'] *100\n",
    "            else:\n",
    "                diff_mean, diff_median, diff_min, diff_max = 0,0,0,0\n",
    "\n",
    "            # print(row['mtx_name'], '\\t', row['gflops'])\n",
    "            # print(synth_mean, '\\t', synth_median, '\\t', synth_min, '\\t', synth_max)\n",
    "            # print(diff_mean, '\\t', diff_median, '\\t', diff_min, '\\t', diff_max)\n",
    "\n",
    "            val_md =  [row['mtx_name'], row['gflops'], \n",
    "                       similar_synthetic['gflops'].mean(), similar_synthetic['gflops'].median(), similar_synthetic['gflops'].min(), similar_synthetic['gflops'].max(), \n",
    "                       diff_mean, diff_median, diff_min, diff_max]\n",
    "            \n",
    "            if similar_synthetic.empty:\n",
    "                similar_synthetic = pd.DataFrame([[mtx_name_ext] + [0]*(len(group_system_best_part.columns)-1)], columns = group_system_best_part.columns)\n",
    "            if df_empty:\n",
    "                synthetic_neighbors = similar_synthetic\n",
    "                validation_metadata.loc[0] = val_md\n",
    "                df_empty = False\n",
    "            else:\n",
    "                synthetic_neighbors = pd.concat([synthetic_neighbors, similar_synthetic])\n",
    "                validation_metadata.loc[len(validation_metadata)] = val_md\n",
    "            \n",
    "        select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "        fig, axs = plt.subplots()\n",
    "        fig.subplots_adjust(left=.14, bottom=.25, right=.99, top=.98)\n",
    "\n",
    "        sns_plot = sns.boxplot(data=synthetic_neighbors, x='mtx_name', y=plot_y_axis, ax=axs, fliersize = 0.5, linewidth = 0.7, color = cp6[ctr],\n",
    "                              # showmeans=True,meanprops={\"marker\":\"s\",\"markerfacecolor\":\"green\", \"markeredgecolor\":\"blue\",\"markersize\":\"2\"}\n",
    "                              ) # linewidth is 0\n",
    "        sns_plot = sns.scatterplot(data=groupvalreps_select_sorted, x=plot_x_axis, y=plot_y_axis, ax=axs, s = 10, color = 'k')\n",
    "        #axs.set_title(system)# axs.set_title('Dataset %s' %(select_str))\n",
    "        #axs.get_legend().remove()\n",
    "        \n",
    "        axs.set_ylabel('Performance(Gflops/s)', fontsize = font-1)\n",
    "        axs.set_xticklabels(range(0,len(set(synthetic_neighbors['mtx_name']))), fontsize = font-2)\n",
    "        axs.set_xlabel('Mtx Id', fontsize = font-1)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.set_size_inches(width, height/(3/2))\n",
    "        #fig.savefig('./Paper_plots/%s_x-%s_y-%s.pdf' % (select_str_id, plot_x_axis, plot_y_axis))\n",
    "        fig.savefig('./Paper_plots/Validation_system-%s_x-%s_y-%s.pdf' % (system, plot_x_axis, plot_y_axis))\n",
    "        plt.close()\n",
    "        ctr+=1\n",
    "        \n",
    "        validation_metadata_systems.append(validation_metadata)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"validation_metadata_systems\"  is a list of metadata for each system containing a dataframe with following columns\n",
    "# ['mtx_name', 'val_gflops', 'synth_mean', 'synth_median', 'synth_min', 'synth_max', 'diff_median', 'diff_mean', 'diff_min', 'diff_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mtx_name', 'TeslaV100', 'TeslaP100', 'HawkAmdRome', 'Arm',\n",
      "       'AlveoU280'],\n",
      "      dtype='object')\n",
      "              mtx_name  TeslaV100  TeslaP100  HawkAmdRome         Arm  \\\n",
      "0             scircuit  16.018268  -0.820496    -4.634514  -43.008202   \n",
      "1             raefsky3  -1.812942 -11.331246     3.922816    8.111718   \n",
      "2      mac_econ_fwd500  17.418808  14.289848    -0.611211  -19.224264   \n",
      "3                bbmat  -5.774446  -6.694179    -7.518657  -22.846409   \n",
      "4       conf5_4-8x8-15   4.378294  -1.165336    -2.052222  -11.154162   \n",
      "5              mc2depi  16.479008  14.009579     1.663616   36.861979   \n",
      "6                rma10  -6.893880  -8.181898   -23.122719    0.819272   \n",
      "7             cop20k_A   7.311286  -1.383922    -5.078243   11.693471   \n",
      "8           webbase-1M  10.830550  -0.629433    -7.072658  -33.920665   \n",
      "9                 cant  -0.728692   5.924122    -4.359271    7.055495   \n",
      "10             pdb1HYS   0.272067   0.586142     1.670237    8.139296   \n",
      "11    TSOPF_RS_b300_c3   3.525596   2.866944    -2.632514   10.797992   \n",
      "12          Chebyshev4  13.086098  18.206993     9.103475  -28.907999   \n",
      "13              consph  -6.019618  -7.856024   -11.729573   68.909102   \n",
      "14            shipsec1  -1.320189 -13.570331    -8.885932   48.387132   \n",
      "15               PR02R   2.920104  -9.528125   -10.290946   65.119880   \n",
      "16                pwtk  -2.951522 -13.906022   -22.280974  106.756485   \n",
      "17                mip1   3.825202  -7.023874    -3.227645   13.249912   \n",
      "18          crankseg_2   2.350103  -0.533623   -30.554173  -20.657108   \n",
      "19            rail4284  -9.940574 -13.806649   -19.424764  -32.439156   \n",
      "20         Si41Ge41H72  -1.730470  -8.268614   -27.822570  -15.441706   \n",
      "21      TSOPF_RS_b2383   0.892938  -1.647730   -35.036697   17.111657   \n",
      "22             in-2004  22.687299  19.417586    21.455407  -14.423155   \n",
      "23         Ga41As41H72   1.691894  -3.731464   -26.116838  -20.276883   \n",
      "24             eu-2005   7.272271   3.041929   -10.595064  -12.530590   \n",
      "25  wikipedia-20051105  44.896158   3.664355   -11.616869  -30.036026   \n",
      "26             rajat31  27.498879  11.157007   -23.619367   43.877422   \n",
      "27               ldoor   0.733596 -20.395224   -78.102331   -1.544978   \n",
      "28             bone010  -2.703600 -12.901070   -74.836419   -8.017362   \n",
      "29           circuit5M -32.717134 -30.107156   -72.810255  -49.933782   \n",
      "30              cage15 -26.424885 -34.844955   -77.012023  -29.106432   \n",
      "\n",
      "    AlveoU280  \n",
      "0   35.248605  \n",
      "1    5.027158  \n",
      "2   -9.879755  \n",
      "3   -0.415585  \n",
      "4  -19.724975  \n",
      "5   -7.914541  \n",
      "6    1.807434  \n",
      "7   17.781350  \n",
      "8  -43.065666  \n",
      "9   -8.971847  \n",
      "10   6.506706  \n",
      "11        NaN  \n",
      "12        NaN  \n",
      "13  11.906984  \n",
      "14  -5.069602  \n",
      "15   3.333884  \n",
      "16 -18.115275  \n",
      "17 -23.055290  \n",
      "18  -9.363426  \n",
      "19        NaN  \n",
      "20        NaN  \n",
      "21        NaN  \n",
      "22  71.735322  \n",
      "23 -28.735371  \n",
      "24  26.455899  \n",
      "25        NaN  \n",
      "26  12.728319  \n",
      "27  87.842260  \n",
      "28 -27.079207  \n",
      "29   0.000000  \n",
      "30   0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-311-50629ba25271>:12: FutureWarning: Passing 'suffixes' which cause duplicate columns {'val_gflops_x', 'diff_max_x', 'synth_min_x', 'synth_max_x', 'diff_min_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  tmp_validation_metadata_df = pd.merge(tmp_validation_metadata_df,validation_metadata_systems_backup[i], how='left', on = 'mtx_name')\n"
     ]
    }
   ],
   "source": [
    "def keep_good_stuff(which_column, validation_metadata_systems):\n",
    "    # tmp_validation_metadata_df = pd.DataFrame(columns=validation_headers)\n",
    "    # testing = 'diff_median_'\n",
    "    testing = ''\n",
    "    for i in range(len(ranges_dev)):    \n",
    "        validation_metadata_systems[i].rename(columns={which_column:ranges_dev[i]}, inplace=True)\n",
    "        if(i==0):\n",
    "            tmp_validation_metadata_df = validation_metadata_systems[i]\n",
    "        else:\n",
    "            # validation_metadata_df = pd.concat([validation_metadata_df,validation_metadata_systems[i]], axis=1)\n",
    "            # https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
    "            tmp_validation_metadata_df = pd.merge(tmp_validation_metadata_df,validation_metadata_systems_backup[i], how='left', on = 'mtx_name')\n",
    "    \n",
    "    validation_metadata_df = tmp_validation_metadata_df[['mtx_name']+ [i for i in ranges_dev]]\n",
    "    return validation_metadata_df\n",
    "\n",
    "\n",
    "# keep only \"diff_median\" columns\n",
    "# whichever column is selected, will be the only one printed afterwards\n",
    "which_column = 'diff_median'\n",
    "validation_metadata_df = keep_good_stuff(which_column, validation_metadata_systems)\n",
    "print(validation_metadata_df.columns)\n",
    "print(validation_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    ctr = 0\n",
    "    for system in ['TeslaV100', 'TeslaP100', 'HawkAmdRome', 'Arm','AlveoU280']:\n",
    "        plot_x_axis = 'mtx_name'\n",
    "        plot_y_axis = 'gflops'\n",
    "\n",
    "        # when you want to plot overall best format\n",
    "        impl = ''\n",
    "\n",
    "        # when you want to plot specific format\n",
    "    #     impl = 'cuSPARSE_coo11'\n",
    "    #     impl = 'cuSPARSE_csr11'\n",
    "    #     impl = 'cuSPARSE_hyb9-2'\n",
    "    #     impl = 'CSR5_9'\n",
    "\n",
    "        select_criterion = ( group_val_system_best['System'] == system )\n",
    "        select_str = 'Validation-'+system+'\\n'+'rows ±30%, avg nonzeros per row ±30%, skew_coeff ±30%,'+'\\n' + 'avg_num_neighbours ±30%, cross_row_similarity ±30%'\n",
    "        if(impl!=''):\n",
    "            select_criterion =  select_criterion & (group_val_system_best['implementation'] == impl)\n",
    "            select_str = impl+\"_\"+ select_str\n",
    "\n",
    "        groupvalreps_select_best = group_val_system_best[select_criterion]\n",
    "\n",
    "        groupvalreps_select_sorted = groupvalreps_select_best.sort_values('A_mem_footprint')\n",
    "        #groupvalreps_select_sorted = groupvalreps_select_best.sort_values('gflops')\n",
    "\n",
    "        group_system_best_part = group_system_best[group_system_best['System'] == system]\n",
    "\n",
    "        friends = True\n",
    "        if(friends != ''):\n",
    "            group_system_best_part = group_system_best_part[group_system_best_part['friends']==friends]\n",
    "            if(impl!=''):\n",
    "                group_system_best_part = group_system_best_part[group_system_best_part['implementation']==impl]\n",
    "\n",
    "        df_empty = True\n",
    "\n",
    "    #     exclude_matrices = [\n",
    "    #         \"wikipedia-20051105\",\"scircuit\",\"mac_econ_fwd500\",\"rail4284\",\"circuit5M\",\"conf5_4-8x8-15\",\"rajat31\",\"in-2004\",\"eu-2005\",\"TSOPF_RS_b300_c3\",\"mip1\",\"PR02R\",\"Ga41As41H72\",\"shipsec1\",\"Si41Ge41H72\",\"crankseg_2\",\"TSOPF_RS_b2383\",\n",
    "    #         \"mc2depi\",\"raefsky3\",\"cop20k_A\",\"bbmat\",\"Chebyshev4\",\"rma10\",\"cage15\",\"cant\",\"pdb1HYS\",\"consph\",\"ldoor\",\"pwtk\",\"bone010\" #,\"webbase-1M\"\n",
    "    #     ]  \n",
    "    #     groupvalreps_select_sorted = groupvalreps_select_sorted[~groupvalreps_select_sorted['mtx_name'].isin(exclude_matrices)]\n",
    "\n",
    "        for index, row in groupvalreps_select_sorted.iterrows():\n",
    "            pd.options.mode.chained_assignment = None  # default='warn'\n",
    "            pcg = 30 # +-30%         \n",
    "            # features to consider too : 'nz', 'std_nz_row', 'avg_bandwidth_scaled'\n",
    "            features = ['m', 'avg_nz_row', 'skew_coeff', 'avg_num_neighbours', 'cross_row_similarity']\n",
    "            similar_synthetic = get_em_feats(pcg, features, group_system_best_part, row, threshold)\n",
    "\n",
    "            if(impl==''):\n",
    "                mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str((row['implementation'])), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "            else:\n",
    "                mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str(round(row['A_mem_footprint'],1)), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "            #similar_synthetic['mtx_name'] = mtx_name_ext Adds Implementation and num of friends in name\n",
    "            similar_synthetic['mtx_name'] = row['mtx_name']\n",
    "\n",
    "            if similar_synthetic.empty:\n",
    "                similar_synthetic = pd.DataFrame([[mtx_name_ext] + [0]*(len(group_system_best_part.columns)-1)], columns = group_system_best_part.columns)\n",
    "            if df_empty:\n",
    "                synthetic_neighbors = similar_synthetic\n",
    "                df_empty = False\n",
    "            else:\n",
    "                synthetic_neighbors = pd.concat([synthetic_neighbors, similar_synthetic])\n",
    "\n",
    "        select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "        fig, axs = plt.subplots()\n",
    "        fig.subplots_adjust(left=.14, bottom=.02, right=.99, top=.96)\n",
    "        sns_plot = sns.boxplot(data=synthetic_neighbors, x='mtx_name', y=plot_y_axis, ax=axs, fliersize = 0.5, linewidth = 0., color = cp6[ctr])\n",
    "        sns_plot = sns.scatterplot(data=groupvalreps_select_sorted, x=plot_x_axis, y=plot_y_axis, ax=axs, s = 10, color = 'k')\n",
    "        #axs.set_title(system)# axs.set_title('Dataset %s' %(select_str))\n",
    "        #axs.get_legend().remove()\n",
    "        axs.set_ylabel('Gflops/s', fontsize = font-1)\n",
    "        axs.set_xticklabels([])\n",
    "        axs.set_xticks([])\n",
    "        axs.set_xlabel('')\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.set_size_inches(width, height/(5/3))\n",
    "        #fig.savefig('./Paper_plots/%s_x-%s_y-%s.pdf' % (select_str_id, plot_x_axis, plot_y_axis))\n",
    "        fig.savefig('./Paper_plots/Validation_cropped_system-%s_x-%s_y-%s.pdf' % (system, plot_x_axis, plot_y_axis))\n",
    "        plt.close()\n",
    "        ctr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for FPGA, I have added \"diagonal\" placement too, because not all \"random\" matrices could be created\n",
    "# if needed, remove comment of \"group_system_best_part\" before for loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     arch, system = 'FPGA', 'AlveoU280'\n",
    "    \n",
    "#     plot_x_axis = 'mtx_name'\n",
    "#     plot_y_axis = 'gflops'\n",
    "    \n",
    "#     # when you want to plot overall best format\n",
    "#     impl = ''\n",
    "\n",
    "#     # when you want to plot specific format\n",
    "# #     impl = 'Xilinx_SpMV'\n",
    "    \n",
    "#     select_criterion = ( group_val_system_best['System'] == system )\n",
    "#     select_str = 'Validation-'+system+'\\n'+'rows ±30%, avg nonzeros per row ±30%, skew_coeff ±30%,'+'\\n' + 'avg_num_neighbours ±30%, cross_row_similarity ±30%'\n",
    "#     if(impl!=''):\n",
    "#         select_criterion =  select_criterion & (group_val_system_best['implementation'] == impl)\n",
    "#         select_str = impl+\"_\"+ select_str\n",
    "\n",
    "#     groupvalreps_select_best = group_val_system_best[select_criterion]\n",
    "\n",
    "# #     groupvalreps_select_sorted = groupvalreps_select_best.sort_values('A_mem_footprint')\n",
    "#     groupvalreps_select_sorted = groupvalreps_select_best.sort_values('gflops')\n",
    "    \n",
    "#     fig, axs = plt.subplots()\n",
    "#     fig.subplots_adjust(left=.1, bottom=.32, right=.99, top=.88)\n",
    "#     plt.xticks(rotation=90)\n",
    "    \n",
    "#     group_system_best_part = group_system_best[group_system_best['System'] == system]\n",
    "    \n",
    "#     friends = True\n",
    "#     if(friends != ''):\n",
    "#         group_system_best_part = group_system_best_part[group_system_best_part['friends']==friends]\n",
    "#         if(impl!=''):\n",
    "#             group_system_best_part = group_system_best_part[group_system_best_part['implementation']==impl]\n",
    "    \n",
    "#     # comment to include \"diagonal\" too\n",
    "#     group_system_best_part = group_system_best_part[group_system_best_part['placement']=='random']\n",
    "\n",
    "#     df_empty = True    \n",
    "#     for index, row in groupvalreps_select_sorted.iterrows():\n",
    "#         pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#         pcg = 30 # +-30% \n",
    "#         # features to consider too : 'nz', 'std_nz_row', 'avg_bandwidth_scaled'\n",
    "#         features = ['m', 'avg_nz_row', 'skew_coeff', 'avg_num_neighbours', 'cross_row_similarity']\n",
    "#         similar_synthetic = get_em_feats(pcg, features, group_system_best_part, row, threshold)\n",
    "        \n",
    "#         if(impl==''):\n",
    "#             mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str((row['implementation'])), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "#         else:\n",
    "#             mtx_name_ext = \"\".join([row['mtx_name'],\" (\",str(round(row['A_mem_footprint'],1)), \" - \",str(similar_synthetic.shape[0]), \")\"])\n",
    "#         similar_synthetic['mtx_name'] = mtx_name_ext\n",
    "        \n",
    "#         if similar_synthetic.empty:\n",
    "#             similar_synthetic = pd.DataFrame([[mtx_name_ext] + [0]*(len(group_system_best_part.columns)-1)], columns = group_system_best_part.columns)\n",
    "#         if df_empty:\n",
    "#             synthetic_neighbors = similar_synthetic\n",
    "#             df_empty = False\n",
    "#         else:\n",
    "#             synthetic_neighbors = pd.concat([synthetic_neighbors, similar_synthetic])\n",
    "\n",
    "#     sns_plot = sns.boxplot(data=synthetic_neighbors, x='mtx_name', y=plot_y_axis, ax=axs)\n",
    "#     sns_plot = sns.scatterplot(data=groupvalreps_select_sorted, x=plot_x_axis, y=plot_y_axis, ax=axs, s = 90)\n",
    "    \n",
    "#     axs.set_title('Dataset %s' %(select_str))\n",
    "#     select_str_id = select_str.replace('=', 'eq').replace('<', 'l').replace('>', 'g').replace(', ', '_').replace(',', '_').replace('\\n', '_').replace(' ', '-')\n",
    "#     fig.savefig('./Paper_plots/%s_x-%s_y-%s.pdf' % (select_str_id, plot_x_axis, plot_y_axis))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
